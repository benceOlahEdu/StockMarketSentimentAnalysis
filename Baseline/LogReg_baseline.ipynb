{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogReg_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ygDjIPBVTLl"
      },
      "source": [
        "# **Stock market news feed semantic analysis** *(Baseline LogReg)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kLvL-AJVg3C"
      },
      "source": [
        "Ebben a notebookban az eddigi általam kibányászott, megszerzett adathalmazokat fogom a hagyományos bag of words és logistic regression módszerrel megvizsgálni. Ezek után n-gram modelleket is ki fogok próbálni. Az általa használt források és referenciák az eredményekhez:\r\n",
        "\r\n",
        "\r\n",
        "*   https://colab.research.google.com/drive/1QPrBkh-KwX6qcUtiNWKp9rJoneBfGEVh#scrollTo=bQUJwMjYYN4- *(saját munka - átdolgozott)*\r\n",
        "*   https://colab.research.google.com/drive/1MdpXGCj2fb3g1BI_XfF54OWLkYQCZBBy#scrollTo=LndWT2Kn-UMK *(saját baseline munka)*\r\n",
        "*   https://www.kaggle.com/ndrewgele/omg-nlp-with-the-djia-and-reddit#Basic-Model-Training-and-Testing\r\n",
        "*   https://www.kaggle.com/lseiyjg/use-news-to-predict-stock-markets\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvCnWXPfXgZi"
      },
      "source": [
        "A használt adathalmazok alapján külön fejezeteket készítek és mindenhol jelzem a forrását és a megszerzésének a módját, ha saját bányászás eredménye."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsAeJYBEXzW_"
      },
      "source": [
        "## **A projekt előkészítése**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuHwIVcIX2Zp"
      },
      "source": [
        "A Drive csatlakoztatása a szükséges fájlok későbbi betöltésére. A betöltés közvetlen a használat előtt fogom megtenni."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvU8LOxdKH5-",
<<<<<<< HEAD
        "outputId": "07e952d3-a3ee-494c-db67-a5bb1ca2f445"
=======
        "outputId": "50020d67-e2a4-4c33-f442-d31658b394de"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
<<<<<<< HEAD
      "execution_count": 1,
=======
      "execution_count": 283,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfOuSSouYIb7"
      },
      "source": [
        "A szükséges könyvtárak betöltése a projekthez."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgUBe7_VYLjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "outputId": "d2573bbe-96ae-4ad8-94a7-3f30ccd0bd77"
=======
        "outputId": "75ec6f52-fad3-45f4-9b6f-aa4cd2839855"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import pandas_datareader as web\r\n",
        "from numpy.random import MT19937\r\n",
        "from numpy.random import RandomState, SeedSequence\r\n",
        "import string\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "nltk.download('punkt')\r\n",
        "from nltk.tokenize import word_tokenize  \r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import accuracy_score \r\n",
        "from sklearn.metrics import confusion_matrix"
      ],
<<<<<<< HEAD
      "execution_count": 2,
=======
      "execution_count": 284,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZiFx9dUgBsN"
      },
      "source": [
        "A projektben használt makrók definiálása."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bULVBJPegGcc"
      },
      "source": [
        "# Shuffle cycle number for the dataframe\r\n",
        "SHUFFLE_CYCLE = 500"
      ],
<<<<<<< HEAD
      "execution_count": 3,
=======
      "execution_count": 285,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vfWZE7fZzcF"
      },
      "source": [
        "A reprodukálhatóság miatt definiálok egy seed-et a véletlen szám generátorhoz, amit a továbbiakban használni fogok."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEjH22olZ1L_"
      },
      "source": [
        "# Random seed\r\n",
        "RANDOM_SEED = 1234\r\n",
        "\r\n",
        "# Numpy random seed\r\n",
        "NP_SEED = 1234\r\n",
        "\r\n",
        "# Max iteration for training\r\n",
        "MAX_ITER = 100000\r\n",
        "\r\n",
        "# Train size\r\n",
        "TRAIN_SPLIT = 0.85\r\n",
        "\r\n",
        "# Test size\r\n",
        "TEST_SPLIT = 0.15"
      ],
<<<<<<< HEAD
      "execution_count": 4,
=======
      "execution_count": 286,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw003siyimeD"
      },
      "source": [
<<<<<<< HEAD
        "np.random.seed(NP_SEED)"
      ],
      "execution_count": 5,
=======
        "rs = RandomState(MT19937(SeedSequence(NP_SEED)))\r\n",
        "np.random.seed(NP_SEED)"
      ],
      "execution_count": 287,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoE6btiUYg-a"
      },
      "source": [
        "## **KAG_REDDIT_WRLD_DJIA_DF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2jP3czjYt6c"
      },
      "source": [
        "Ez az adathalmaz a top25 hírt tartalmazza a Reddit World News kategóriából 2008.08.08-2016.07.01 időtartamban. Ez nem általam gyűjtött adathalmaz, a forrása:\r\n",
        "Sun, J. (2016, August). Daily News for Stock Market Prediction, Version 1. Retrieved 2021.02.19. from https://www.kaggle.com/aaron7sun/stocknews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu_wdhA1ZSrt"
      },
      "source": [
        "Az adathalmaz betöltése a csatlakoztatott Drive-omból."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw00CWOBZbeF"
      },
      "source": [
        "# Copy the dataset to the local environment\r\n",
        "!cp \"/content/drive/MyDrive/Combined_News_DJIA.csv\" \"Combined_News_DJIA.csv\"\r\n",
        "\r\n",
        "# Check the copy is succesfull -> good if no assertation error\r\n",
        "read = !ls\r\n",
        "assert read[0].find(\"Combined_News_DJIA.csv\") != -1"
      ],
<<<<<<< HEAD
      "execution_count": 6,
=======
      "execution_count": 336,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W_uQPC2Mt6F"
      },
      "source": [
        "Az eredmények elmentésére és indexelésére az alábbi két tömböt fogom hasnzálni."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ria16HC2MyZa"
      },
      "source": [
        "model_type = [\"Bag of words\", \"1,2 n-gram\", \"2,2 n-gram\", \r\n",
        "              \"1,3 n-gram\", \"2,3 n-gram\", \"3,3 n-gram\"]\r\n",
        "\r\n",
        "result = []              "
      ],
<<<<<<< HEAD
      "execution_count": 7,
=======
      "execution_count": 337,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z73YJGnjYxAz"
      },
      "source": [
        "Makró definiálás."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lMyUJerYzAg"
      },
      "source": [
        "# Number of merged news into one string\r\n",
        "ROWS = 2"
      ],
<<<<<<< HEAD
      "execution_count": 8,
=======
      "execution_count": 338,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1DAhyIob0Bm"
      },
      "source": [
        "### A szöveg előkészítése"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20KSUSX1b4-z"
      },
      "source": [
        "Az adathalmaz betöltése."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "tPmTqk3Gb2Fo",
<<<<<<< HEAD
        "outputId": "d37088db-ab8b-4e33-84c1-e3fcda52c657"
=======
        "outputId": "2801f6cd-7f42-4552-cc4f-88b04df1823a"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "# Load the dataset \r\n",
        "df_combined = pd.read_csv('Combined_News_DJIA.csv', index_col = \"Date\")\r\n",
        "\r\n",
        "# Show the dataframe\r\n",
        "df_combined.head()"
      ],
<<<<<<< HEAD
      "execution_count": 9,
=======
      "execution_count": 339,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Top1</th>\n",
              "      <th>Top2</th>\n",
              "      <th>Top3</th>\n",
              "      <th>Top4</th>\n",
              "      <th>Top5</th>\n",
              "      <th>Top6</th>\n",
              "      <th>Top7</th>\n",
              "      <th>Top8</th>\n",
              "      <th>Top9</th>\n",
              "      <th>Top10</th>\n",
              "      <th>Top11</th>\n",
              "      <th>Top12</th>\n",
              "      <th>Top13</th>\n",
              "      <th>Top14</th>\n",
              "      <th>Top15</th>\n",
              "      <th>Top16</th>\n",
              "      <th>Top17</th>\n",
              "      <th>Top18</th>\n",
              "      <th>Top19</th>\n",
              "      <th>Top20</th>\n",
              "      <th>Top21</th>\n",
              "      <th>Top22</th>\n",
              "      <th>Top23</th>\n",
              "      <th>Top24</th>\n",
              "      <th>Top25</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-08-08</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
              "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
              "      <td>b'Russian tanks are moving towards the capital...</td>\n",
              "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
              "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
              "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
              "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
              "      <td>b'Georgian troops retreat from S. Osettain cap...</td>\n",
              "      <td>b'Did the U.S. Prep Georgia for War with Russia?'</td>\n",
              "      <td>b'Rice Gives Green Light for Israel to Attack ...</td>\n",
              "      <td>b'Announcing:Class Action Lawsuit on Behalf of...</td>\n",
              "      <td>b\"So---Russia and Georgia are at war and the N...</td>\n",
              "      <td>b\"China tells Bush to stay out of other countr...</td>\n",
              "      <td>b'Did World War III start today?'</td>\n",
              "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
              "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
              "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
              "      <td>b'This is a busy day:  The European Union has ...</td>\n",
              "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
              "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
              "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
              "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
              "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
              "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-11</th>\n",
              "      <td>1</td>\n",
              "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
              "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
              "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
              "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
              "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
              "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
              "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
              "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
              "      <td>b'Welcome To World War IV! Now In High Definit...</td>\n",
              "      <td>b\"Georgia's move, a mistake of monumental prop...</td>\n",
              "      <td>b'Russia presses deeper into Georgia; U.S. say...</td>\n",
              "      <td>b'Abhinav Bindra wins first ever Individual Ol...</td>\n",
              "      <td>b' U.S. ship heads for Arctic to define territ...</td>\n",
              "      <td>b'Drivers in a Jerusalem taxi station threaten...</td>\n",
              "      <td>b'The French Team is Stunned by Phelps and the...</td>\n",
              "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
              "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
              "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
              "      <td>b'China to overtake US as largest manufacturer'</td>\n",
              "      <td>b'War in South Ossetia [PICS]'</td>\n",
              "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
              "      <td>b' Russia has just beaten the United States ov...</td>\n",
              "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
              "      <td>b'Russia is so much better at war'</td>\n",
              "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-12</th>\n",
              "      <td>0</td>\n",
              "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
              "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
              "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
              "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
              "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
              "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
              "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
              "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
              "      <td>b\"The US military was surprised by the timing ...</td>\n",
              "      <td>b'U.S. Beats War Drum as Iran Dumps the Dollar'</td>\n",
              "      <td>b'Gorbachev: \"Georgian military attacked the S...</td>\n",
              "      <td>b'CNN use footage of Tskhinvali ruins to cover...</td>\n",
              "      <td>b'Beginning a war as the Olympics were opening...</td>\n",
              "      <td>b'55 pyramids as large as the Luxor stacked in...</td>\n",
              "      <td>b'The 11 Top Party Cities in the World'</td>\n",
              "      <td>b'U.S. troops still in Georgia (did you know t...</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
              "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
              "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
              "      <td>b'War in Georgia: The Israeli connection'</td>\n",
              "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
              "      <td>b'Christopher King argues that the US and NATO...</td>\n",
              "      <td>b'America: The New Mexico?'</td>\n",
              "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-13</th>\n",
              "      <td>0</td>\n",
              "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
              "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
              "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
              "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
              "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
              "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
              "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
              "      <td>b'Russian forces sink Georgian ships '</td>\n",
              "      <td>b\"The commander of a Navy air reconnaissance s...</td>\n",
              "      <td>b\"92% of CNN readers: Russia's actions in Geor...</td>\n",
              "      <td>b'USA to send fleet into Black Sea to help Geo...</td>\n",
              "      <td>b\"US warns against Israeli plan to strike agai...</td>\n",
              "      <td>b\"In an intriguing cyberalliance, two Estonian...</td>\n",
              "      <td>b'The CNN Effect: Georgia Schools Russia in In...</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Elephants extinct by 2020?'</td>\n",
              "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
              "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
              "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
              "      <td>b'Israeli defence minister: US against strike ...</td>\n",
              "      <td>b'Gorbachev: We Had No Choice'</td>\n",
              "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
              "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
              "      <td>b'Georgian president  says US military will ta...</td>\n",
              "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-14</th>\n",
              "      <td>1</td>\n",
              "      <td>b'All the experts admit that we should legalis...</td>\n",
              "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
              "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
              "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
              "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
              "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
              "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
              "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
              "      <td>b'Russia exaggerating South Ossetian death tol...</td>\n",
              "      <td>b' Musharraf expected to resign rather than fa...</td>\n",
              "      <td>b'Moscow Made Plans Months Ago to Invade Georgia'</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Nigeria has handed over the potentially oil-...</td>\n",
              "      <td>b'The US and Poland have agreed a preliminary ...</td>\n",
              "      <td>b'Russia apparently is sabotaging infrastructu...</td>\n",
              "      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n",
              "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
              "      <td>b'War in the Caucasus is as much the product o...</td>\n",
              "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
              "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
              "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
              "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
              "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
              "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
              "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Label  ...                                              Top25\n",
              "Date               ...                                                   \n",
              "2008-08-08      0  ...           b\"No Help for Mexico's Kidnapping Surge\"\n",
              "2008-08-11      1  ...  b\"So this is what it's come to: trading sex fo...\n",
              "2008-08-12      0  ...  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...\n",
              "2008-08-13      0  ...  b'2006: Nobel laureate Aleksander Solzhenitsyn...\n",
              "2008-08-14      1  ...  b'Philippines : Peace Advocate say Muslims nee...\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 9
=======
          "execution_count": 339
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdvD8SIQcPB6"
      },
      "source": [
        "Érdekességképpen a következőkben megvizsgálom, hogy az adathalmaz címkéi megfelelőek. A forrás szerint a címke 1, ha nőtt vagy azonos maradt az érték azon a napon, illetve 0, ha csökkent. (Adj Close adott napi értéke az előző napihoz viszonyítva)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "oj26KF2ncgji",
<<<<<<< HEAD
        "outputId": "02819d9a-167f-498a-a70a-e9afdcb65902"
=======
        "outputId": "719ce00d-c37b-404e-c81b-37e17b19362d"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "# Load the stock data\r\n",
        "df_stock = web.DataReader(\"DJIA\", data_source=\"yahoo\", start=\"2008-08-08\", \r\n",
        "                          end=\"2016-07-01\")\r\n",
        " \r\n",
        "# Show the stock data\r\n",
        "df_stock.head()"
      ],
<<<<<<< HEAD
      "execution_count": 10,
=======
      "execution_count": 340,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-08-08</th>\n",
              "      <td>11808.490234</td>\n",
              "      <td>11344.230469</td>\n",
              "      <td>11432.089844</td>\n",
              "      <td>11734.320312</td>\n",
              "      <td>4966810000</td>\n",
              "      <td>11734.320312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-11</th>\n",
              "      <td>11933.549805</td>\n",
              "      <td>11580.190430</td>\n",
              "      <td>11729.669922</td>\n",
              "      <td>11782.349609</td>\n",
              "      <td>5067310000</td>\n",
              "      <td>11782.349609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-12</th>\n",
              "      <td>11830.389648</td>\n",
              "      <td>11541.429688</td>\n",
              "      <td>11781.700195</td>\n",
              "      <td>11642.469727</td>\n",
              "      <td>4711290000</td>\n",
              "      <td>11642.469727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-13</th>\n",
              "      <td>11689.049805</td>\n",
              "      <td>11377.370117</td>\n",
              "      <td>11632.809570</td>\n",
              "      <td>11532.959961</td>\n",
              "      <td>4787600000</td>\n",
              "      <td>11532.959961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-14</th>\n",
              "      <td>11744.330078</td>\n",
              "      <td>11399.839844</td>\n",
              "      <td>11532.070312</td>\n",
              "      <td>11615.929688</td>\n",
              "      <td>4064000000</td>\n",
              "      <td>11615.929688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    High           Low  ...      Volume     Adj Close\n",
              "Date                                    ...                          \n",
              "2008-08-08  11808.490234  11344.230469  ...  4966810000  11734.320312\n",
              "2008-08-11  11933.549805  11580.190430  ...  5067310000  11782.349609\n",
              "2008-08-12  11830.389648  11541.429688  ...  4711290000  11642.469727\n",
              "2008-08-13  11689.049805  11377.370117  ...  4787600000  11532.959961\n",
              "2008-08-14  11744.330078  11399.839844  ...  4064000000  11615.929688\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 10
=======
          "execution_count": 340
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9UbGo05jACh"
      },
      "source": [
        "Az dátumok formátumát egységesre hozom az összehasonlítás érdekében."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "J6UkTz6Vg23F",
<<<<<<< HEAD
        "outputId": "47ceff82-4e42-491b-82df-a0559f6c62ba"
=======
        "outputId": "1a43c1a2-0bd9-4e0a-c700-972c92615ff2"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "temp_day = []\r\n",
        "\r\n",
        "for day in range(len(df_stock)):\r\n",
        "    temp_day.append(df_stock.index[day].date())\r\n",
        "\r\n",
        "df_stock.index = temp_day\r\n",
        "\r\n",
        "# Show the stock data\r\n",
        "df_stock.head()"
      ],
<<<<<<< HEAD
      "execution_count": 11,
=======
      "execution_count": 341,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-08-08</th>\n",
              "      <td>11808.490234</td>\n",
              "      <td>11344.230469</td>\n",
              "      <td>11432.089844</td>\n",
              "      <td>11734.320312</td>\n",
              "      <td>4966810000</td>\n",
              "      <td>11734.320312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-11</th>\n",
              "      <td>11933.549805</td>\n",
              "      <td>11580.190430</td>\n",
              "      <td>11729.669922</td>\n",
              "      <td>11782.349609</td>\n",
              "      <td>5067310000</td>\n",
              "      <td>11782.349609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-12</th>\n",
              "      <td>11830.389648</td>\n",
              "      <td>11541.429688</td>\n",
              "      <td>11781.700195</td>\n",
              "      <td>11642.469727</td>\n",
              "      <td>4711290000</td>\n",
              "      <td>11642.469727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-13</th>\n",
              "      <td>11689.049805</td>\n",
              "      <td>11377.370117</td>\n",
              "      <td>11632.809570</td>\n",
              "      <td>11532.959961</td>\n",
              "      <td>4787600000</td>\n",
              "      <td>11532.959961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-14</th>\n",
              "      <td>11744.330078</td>\n",
              "      <td>11399.839844</td>\n",
              "      <td>11532.070312</td>\n",
              "      <td>11615.929688</td>\n",
              "      <td>4064000000</td>\n",
              "      <td>11615.929688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    High           Low  ...      Volume     Adj Close\n",
              "2008-08-08  11808.490234  11344.230469  ...  4966810000  11734.320312\n",
              "2008-08-11  11933.549805  11580.190430  ...  5067310000  11782.349609\n",
              "2008-08-12  11830.389648  11541.429688  ...  4711290000  11642.469727\n",
              "2008-08-13  11689.049805  11377.370117  ...  4787600000  11532.959961\n",
              "2008-08-14  11744.330078  11399.839844  ...  4064000000  11615.929688\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 11
=======
          "execution_count": 341
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWWYe1PpdCK3"
      },
      "source": [
        "Először a dátumok ellenőzöm, hogy megegyeznek-e."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77SDqWWGdF31",
<<<<<<< HEAD
        "outputId": "adafdadb-5c52-4620-a031-d004d8ade315"
=======
        "outputId": "60099718-3aa1-46e4-9f19-81fd76857ded"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "difference = []\r\n",
        "\r\n",
        "if len(df_combined) == len(df_stock):\r\n",
        "    print(\"The lengths are the same!\")\r\n",
        "\r\n",
        "for day in range(max(len(df_combined), len(df_stock))):\r\n",
        "    if str(df_combined.index[day]) != str(df_stock.index[day]):\r\n",
        "        print(\"There is difference at: \" + str(day) + \" index\")\r\n",
        "        print(\"News: \" + str(df_combined.index[day]) + \"\\tStock: \" + str(df_stock.index[day]))\r\n",
        "        difference.append(day)\r\n",
        "\r\n",
        "if len(difference) is 0:\r\n",
        "    print(\"The dates matched!\")"
      ],
<<<<<<< HEAD
      "execution_count": 12,
=======
      "execution_count": 342,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The lengths are the same!\n",
            "The dates matched!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJogdlwsjJm3"
      },
      "source": [
        "A labelek ellenőrzése."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyySRYjNjLwt",
<<<<<<< HEAD
        "outputId": "7c6b5c01-043c-42cf-e8de-ce55376ab71c"
=======
        "outputId": "827a7967-f81e-4976-89e2-07bf0a3838ca"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "difference = []\r\n",
        "\r\n",
        "for day in range(len(df_stock)):\r\n",
        "    # label should be 1 -> rise\r\n",
        "    if int(df_stock[\"Adj Close\"][day]) >= int(df_stock[\"Adj Close\"][day - 1]):\r\n",
        "        if df_combined[\"Label\"][day] != 1:\r\n",
        "            difference.append(str(df_stock.index[day]))\r\n",
        "            print(\"Problem at day \" + str(df_stock.index[day]))\r\n",
        "            print(\"Today: \" + str(df_stock[\"Adj Close\"][day]) +\"\\t\\tYesterday: \" + str(df_stock[\"Adj Close\"][day - 1]) + \"\\t\\tLabel: \" + str(df_combined[\"Label\"][day]) + \"\\n\")\r\n",
        "\r\n",
        "    # label should be 0 -> fall\r\n",
        "    if int(df_stock[\"Adj Close\"][day]) < int(df_stock[\"Adj Close\"][day - 1]):\r\n",
        "        if df_combined[\"Label\"][day] != 0:\r\n",
        "            difference.append(str(df_stock.index[day]))\r\n",
        "            print(\"Problem at day \" + str(df_stock.index[day]))\r\n",
        "            print(\"Today: \" + str(df_stock[\"Adj Close\"][day]) +\"\\t\\tYesterday: \" + str(df_stock[\"Adj Close\"][day - 1]) + \"\\t\\tLabel: \" + str(df_combined[\"Label\"][day]) + \"\\n\")\r\n",
        "\r\n",
        "print(\"All differences: \" + str(len(difference)))      "
      ],
<<<<<<< HEAD
      "execution_count": 13,
=======
      "execution_count": 343,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Problem at day 2010-10-14\n",
            "Today: 11096.919921875\t\tYesterday: 11096.080078125\t\tLabel: 0\n",
            "\n",
            "Problem at day 2012-11-12\n",
            "Today: 12815.080078125\t\tYesterday: 12815.3896484375\t\tLabel: 0\n",
            "\n",
            "Problem at day 2012-11-15\n",
            "Today: 12570.9501953125\t\tYesterday: 12570.9501953125\t\tLabel: 0\n",
            "\n",
            "Problem at day 2013-04-12\n",
            "Today: 14865.0595703125\t\tYesterday: 14865.1396484375\t\tLabel: 0\n",
            "\n",
            "Problem at day 2014-04-24\n",
            "Today: 16501.650390625\t\tYesterday: 16501.650390625\t\tLabel: 0\n",
            "\n",
            "Problem at day 2015-08-12\n",
            "Today: 17402.509765625\t\tYesterday: 17402.83984375\t\tLabel: 0\n",
            "\n",
            "Problem at day 2015-11-27\n",
            "Today: 17813.390625\t\tYesterday: 17813.390625\t\tLabel: 0\n",
            "\n",
            "All differences: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOI1OZJPU6Wh"
      },
      "source": [
        "Látható, hogy rossz a label pár helyen. Egy kis kutakodás után megtaláltam, hogy maga az árfolyam lekérdezésük volt hibás pár nap esetében, ezért ezeket javítom, majd elmentem a drive-omon a javítottat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHvqT2FRtBkW",
<<<<<<< HEAD
        "outputId": "99e26b32-cecd-4876-9756-9db311ee00c2"
=======
        "outputId": "8c166236-01c4-4972-f443-83a456f76639"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "# correct the wrong labels\r\n",
        "for row in difference:\r\n",
        "    if df_combined.loc[row, \"Label\"] == 0:\r\n",
        "        df_combined.loc[row, \"Label\"] = 1\r\n",
        "    else:\r\n",
        "        df_combined.loc[row, \"Label\"] = 0\r\n",
        "\r\n",
        "# check them\r\n",
        "for row in difference:\r\n",
        "    print(str(row) + \"\\t\\t\" + str(df_combined.loc[row, \"Label\"]))"
      ],
<<<<<<< HEAD
      "execution_count": 14,
=======
      "execution_count": 344,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2010-10-14\t\t1\n",
            "2012-11-12\t\t1\n",
            "2012-11-15\t\t1\n",
            "2013-04-12\t\t1\n",
            "2014-04-24\t\t1\n",
            "2015-08-12\t\t1\n",
            "2015-11-27\t\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTIqNqucuiBO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
<<<<<<< HEAD
        "outputId": "ad8dc421-33e7-448c-910f-9448911bc9df"
=======
        "outputId": "b512d283-69e4-493b-8dce-78347223e734"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "# save to drive\r\n",
        "df_combined.to_csv('drive/MyDrive/Kaggle dataset/Reddit Top 25 DJIA/KAG_REDDIT_WRLD_DJIA_DF_corrected.csv')\r\n",
        "\r\n",
        "# Show the dataset\r\n",
        "df_combined.head()"
      ],
<<<<<<< HEAD
      "execution_count": 15,
=======
      "execution_count": 345,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Top1</th>\n",
              "      <th>Top2</th>\n",
              "      <th>Top3</th>\n",
              "      <th>Top4</th>\n",
              "      <th>Top5</th>\n",
              "      <th>Top6</th>\n",
              "      <th>Top7</th>\n",
              "      <th>Top8</th>\n",
              "      <th>Top9</th>\n",
              "      <th>Top10</th>\n",
              "      <th>Top11</th>\n",
              "      <th>Top12</th>\n",
              "      <th>Top13</th>\n",
              "      <th>Top14</th>\n",
              "      <th>Top15</th>\n",
              "      <th>Top16</th>\n",
              "      <th>Top17</th>\n",
              "      <th>Top18</th>\n",
              "      <th>Top19</th>\n",
              "      <th>Top20</th>\n",
              "      <th>Top21</th>\n",
              "      <th>Top22</th>\n",
              "      <th>Top23</th>\n",
              "      <th>Top24</th>\n",
              "      <th>Top25</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-08-08</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
              "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
              "      <td>b'Russian tanks are moving towards the capital...</td>\n",
              "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
              "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
              "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
              "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
              "      <td>b'Georgian troops retreat from S. Osettain cap...</td>\n",
              "      <td>b'Did the U.S. Prep Georgia for War with Russia?'</td>\n",
              "      <td>b'Rice Gives Green Light for Israel to Attack ...</td>\n",
              "      <td>b'Announcing:Class Action Lawsuit on Behalf of...</td>\n",
              "      <td>b\"So---Russia and Georgia are at war and the N...</td>\n",
              "      <td>b\"China tells Bush to stay out of other countr...</td>\n",
              "      <td>b'Did World War III start today?'</td>\n",
              "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
              "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
              "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
              "      <td>b'This is a busy day:  The European Union has ...</td>\n",
              "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
              "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
              "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
              "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
              "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
              "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-11</th>\n",
              "      <td>1</td>\n",
              "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
              "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
              "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
              "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
              "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
              "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
              "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
              "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
              "      <td>b'Welcome To World War IV! Now In High Definit...</td>\n",
              "      <td>b\"Georgia's move, a mistake of monumental prop...</td>\n",
              "      <td>b'Russia presses deeper into Georgia; U.S. say...</td>\n",
              "      <td>b'Abhinav Bindra wins first ever Individual Ol...</td>\n",
              "      <td>b' U.S. ship heads for Arctic to define territ...</td>\n",
              "      <td>b'Drivers in a Jerusalem taxi station threaten...</td>\n",
              "      <td>b'The French Team is Stunned by Phelps and the...</td>\n",
              "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
              "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
              "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
              "      <td>b'China to overtake US as largest manufacturer'</td>\n",
              "      <td>b'War in South Ossetia [PICS]'</td>\n",
              "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
              "      <td>b' Russia has just beaten the United States ov...</td>\n",
              "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
              "      <td>b'Russia is so much better at war'</td>\n",
              "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-12</th>\n",
              "      <td>0</td>\n",
              "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
              "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
              "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
              "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
              "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
              "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
              "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
              "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
              "      <td>b\"The US military was surprised by the timing ...</td>\n",
              "      <td>b'U.S. Beats War Drum as Iran Dumps the Dollar'</td>\n",
              "      <td>b'Gorbachev: \"Georgian military attacked the S...</td>\n",
              "      <td>b'CNN use footage of Tskhinvali ruins to cover...</td>\n",
              "      <td>b'Beginning a war as the Olympics were opening...</td>\n",
              "      <td>b'55 pyramids as large as the Luxor stacked in...</td>\n",
              "      <td>b'The 11 Top Party Cities in the World'</td>\n",
              "      <td>b'U.S. troops still in Georgia (did you know t...</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
              "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
              "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
              "      <td>b'War in Georgia: The Israeli connection'</td>\n",
              "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
              "      <td>b'Christopher King argues that the US and NATO...</td>\n",
              "      <td>b'America: The New Mexico?'</td>\n",
              "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-13</th>\n",
              "      <td>0</td>\n",
              "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
              "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
              "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
              "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
              "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
              "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
              "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
              "      <td>b'Russian forces sink Georgian ships '</td>\n",
              "      <td>b\"The commander of a Navy air reconnaissance s...</td>\n",
              "      <td>b\"92% of CNN readers: Russia's actions in Geor...</td>\n",
              "      <td>b'USA to send fleet into Black Sea to help Geo...</td>\n",
              "      <td>b\"US warns against Israeli plan to strike agai...</td>\n",
              "      <td>b\"In an intriguing cyberalliance, two Estonian...</td>\n",
              "      <td>b'The CNN Effect: Georgia Schools Russia in In...</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Elephants extinct by 2020?'</td>\n",
              "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
              "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
              "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
              "      <td>b'Israeli defence minister: US against strike ...</td>\n",
              "      <td>b'Gorbachev: We Had No Choice'</td>\n",
              "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
              "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
              "      <td>b'Georgian president  says US military will ta...</td>\n",
              "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-14</th>\n",
              "      <td>1</td>\n",
              "      <td>b'All the experts admit that we should legalis...</td>\n",
              "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
              "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
              "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
              "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
              "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
              "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
              "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
              "      <td>b'Russia exaggerating South Ossetian death tol...</td>\n",
              "      <td>b' Musharraf expected to resign rather than fa...</td>\n",
              "      <td>b'Moscow Made Plans Months Ago to Invade Georgia'</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Nigeria has handed over the potentially oil-...</td>\n",
              "      <td>b'The US and Poland have agreed a preliminary ...</td>\n",
              "      <td>b'Russia apparently is sabotaging infrastructu...</td>\n",
              "      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n",
              "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
              "      <td>b'War in the Caucasus is as much the product o...</td>\n",
              "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
              "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
              "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
              "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
              "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
              "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
              "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Label  ...                                              Top25\n",
              "Date               ...                                                   \n",
              "2008-08-08      0  ...           b\"No Help for Mexico's Kidnapping Surge\"\n",
              "2008-08-11      1  ...  b\"So this is what it's come to: trading sex fo...\n",
              "2008-08-12      0  ...  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...\n",
              "2008-08-13      0  ...  b'2006: Nobel laureate Aleksander Solzhenitsyn...\n",
              "2008-08-14      1  ...  b'Philippines : Peace Advocate say Muslims nee...\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 15
=======
          "execution_count": 345
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAhg7d5Xj2kt"
      },
      "source": [
        "A következőkben az esetleges adat nélküli napokat, illetve cellákat keresem meg és helyettesítem őket egy üres sztringgel. Ez a későbbi szövegfeldolgozás hibamentességéhez szükséges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrFufwo6j5_H"
      },
      "source": [
        "# Find the cells with NaN and after the rows for them\r\n",
        "is_NaN = df_combined.isnull()\r\n",
        "row_has_NaN = is_NaN.any(axis = 1)\r\n",
        "rows_with_NaN = df_combined[row_has_NaN]\r\n",
        "\r\n",
        "# Replace them\r\n",
        "df_combined = df_combined.replace(np.nan, \" \")\r\n",
        "\r\n",
        "# Check the process\r\n",
        "is_NaN = df_combined.isnull()\r\n",
        "row_has_NaN = is_NaN.any(axis = 1)\r\n",
        "rows_with_NaN = df_combined[row_has_NaN]\r\n",
        "\r\n",
        "assert len(rows_with_NaN) is 0"
      ],
<<<<<<< HEAD
      "execution_count": 16,
=======
      "execution_count": 346,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxCOud0ki5M-"
      },
      "source": [
        "Ezek után az egy naphoz tartozó híreket közös sztringekbe fűzöm. Az egy sztringbe tartozó hírek számát makróval definiálom:\r\n",
        "\r\n",
        "\r\n",
        "*   ROWS - egymásba fűzött hírek száma\r\n",
        "\r\n",
        "Itt megtalálható már az első előkészítő algoritmusom, méghozzá a sztringek elején található b karakter eltávolítása."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqv3bDcAi6Bf",
<<<<<<< HEAD
        "outputId": "a023fbfb-ecd2-4767-bcf1-1d84d98d10d2"
=======
        "outputId": "614472e1-7951-494a-d165-4ff12ed12bfa"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "# Get column names\r\n",
        "combined_column_names = []\r\n",
        "for column in df_combined.columns:\r\n",
        "  combined_column_names.append(column)\r\n",
        "\r\n",
        "# 2D array creation for the news based on macros\r\n",
        "COLUMNS = len(df_combined)\r\n",
        "news_sum = [[0 for i in range(COLUMNS)] for j in range(int((len(combined_column_names) - 1) / ROWS))]  \r\n",
        "\r\n",
        "# Show the column names\r\n",
        "print(\"Column names of the dataset:\") \r\n",
        "print(combined_column_names)\r\n",
        "\r\n",
        "# Merge the news\r\n",
        "for row in range(len(df_combined)):\r\n",
        "  for column in range(int((len(combined_column_names) - 1) / ROWS)):\r\n",
        "    temp = \"\"\r\n",
        "    news = \"\"\r\n",
        "    for word in range(ROWS):\r\n",
        "      news = df_combined[combined_column_names[(column * ROWS) + (word + 1)]][row]\r\n",
        "      # Remove the b character at the begining of the string\r\n",
        "      if news[0] is \"b\":\r\n",
        "        news = \" \" + news[1:]\r\n",
        "      temp = temp + news\r\n",
        "    news_sum[column][row] = temp\r\n",
        "\r\n",
        "# Show the first day second package of the news\r\n",
        "print(\"\\nThe first day second package of the news:\")\r\n",
        "print(news_sum[1][0])"
      ],
<<<<<<< HEAD
      "execution_count": 17,
=======
      "execution_count": 347,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column names of the dataset:\n",
            "['Label', 'Top1', 'Top2', 'Top3', 'Top4', 'Top5', 'Top6', 'Top7', 'Top8', 'Top9', 'Top10', 'Top11', 'Top12', 'Top13', 'Top14', 'Top15', 'Top16', 'Top17', 'Top18', 'Top19', 'Top20', 'Top21', 'Top22', 'Top23', 'Top24', 'Top25']\n",
            "\n",
            "The first day second package of the news:\n",
            " 'Russia Today: Columns of troops roll into South Ossetia; footage from fighting (YouTube)' 'Russian tanks are moving towards the capital of South Ossetia, which has reportedly been completely destroyed by Georgian artillery fire'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvOqG6vckIcF"
      },
      "source": [
        "Ezek után a korábbi oszlopokat(Top1, Top2...) kicserélem a csoportosításnak megfelelő számú oszlopokra és nevekre (News_1, News_2...), majd feltöltöm őket az összevont hírcsomagokkal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "xljXPUwmkKrZ",
<<<<<<< HEAD
        "outputId": "b35c4a7d-8356-4b15-be32-afe9c1842432"
=======
        "outputId": "312e082f-5715-4fba-b33c-902018f8944b"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "# Drop the old columns\r\n",
        "for column in range(len(combined_column_names) - 1):\r\n",
        "  df_combined.drop(combined_column_names[column + 1], axis = 1, inplace = True)\r\n",
        "\r\n",
        "# Create the new columns with the merged news\r\n",
        "for column in range(int((len(combined_column_names) - 1) / ROWS)):\r\n",
        "  colum_name = \"News_\" + str(column + 1)\r\n",
        "  df_combined[colum_name] = news_sum[column]\r\n",
        "\r\n",
        "# Show the DataFrame\r\n",
        "df_combined.head()"
      ],
<<<<<<< HEAD
      "execution_count": 18,
=======
      "execution_count": 348,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News_1</th>\n",
              "      <th>News_2</th>\n",
              "      <th>News_3</th>\n",
              "      <th>News_4</th>\n",
              "      <th>News_5</th>\n",
              "      <th>News_6</th>\n",
              "      <th>News_7</th>\n",
              "      <th>News_8</th>\n",
              "      <th>News_9</th>\n",
              "      <th>News_10</th>\n",
              "      <th>News_11</th>\n",
              "      <th>News_12</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-08-08</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "      <td>'Russia Today: Columns of troops roll into So...</td>\n",
              "      <td>\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
              "      <td>\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
              "      <td>'Georgian troops retreat from S. Osettain cap...</td>\n",
              "      <td>'Rice Gives Green Light for Israel to Attack ...</td>\n",
              "      <td>\"So---Russia and Georgia are at war and the N...</td>\n",
              "      <td>'Did World War III start today?' 'Georgia Inv...</td>\n",
              "      <td>'Al-Qaeda Faces Islamist Backlash' 'Condoleez...</td>\n",
              "      <td>'This is a busy day:  The European Union has ...</td>\n",
              "      <td>'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
              "      <td>'Indian shoe manufactory  - And again in a se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-11</th>\n",
              "      <td>1</td>\n",
              "      <td>'Why wont America and Nato help us? If they w...</td>\n",
              "      <td>\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
              "      <td>\"Olympic opening ceremony fireworks 'faked'\" ...</td>\n",
              "      <td>'Russia angered by Israeli military sale to G...</td>\n",
              "      <td>'Welcome To World War IV! Now In High Definit...</td>\n",
              "      <td>'Russia presses deeper into Georgia; U.S. say...</td>\n",
              "      <td>' U.S. ship heads for Arctic to define territ...</td>\n",
              "      <td>'The French Team is Stunned by Phelps and the...</td>\n",
              "      <td>'\"Do not believe TV, neither Russian nor Geor...</td>\n",
              "      <td>'China to overtake US as largest manufacturer...</td>\n",
              "      <td>'Israeli Physicians Group Condemns State Tort...</td>\n",
              "      <td>'Perhaps *the* question about the Georgia - R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-12</th>\n",
              "      <td>0</td>\n",
              "      <td>'Remember that adorable 9-year-old who sang a...</td>\n",
              "      <td>'\"If we had no sexual harassment we would hav...</td>\n",
              "      <td>'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
              "      <td>'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
              "      <td>\"The US military was surprised by the timing ...</td>\n",
              "      <td>'Gorbachev: \"Georgian military attacked the S...</td>\n",
              "      <td>'Beginning a war as the Olympics were opening...</td>\n",
              "      <td>'The 11 Top Party Cities in the World' 'U.S. ...</td>\n",
              "      <td>'Why Russias response to Georgia was right' '...</td>\n",
              "      <td>'Russia, Georgia, and NATO: Cold War Two' 'Re...</td>\n",
              "      <td>'War in Georgia: The Israeli connection' 'All...</td>\n",
              "      <td>'Christopher King argues that the US and NATO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-13</th>\n",
              "      <td>0</td>\n",
              "      <td>' U.S. refuses Israel weapons to attack Iran:...</td>\n",
              "      <td>' Israel clears troops who killed Reuters cam...</td>\n",
              "      <td>'Body of 14 year old found in trunk; Latest (...</td>\n",
              "      <td>\"Bush announces Operation Get All Up In Russi...</td>\n",
              "      <td>\"The commander of a Navy air reconnaissance s...</td>\n",
              "      <td>'USA to send fleet into Black Sea to help Geo...</td>\n",
              "      <td>\"In an intriguing cyberalliance, two Estonian...</td>\n",
              "      <td>'Why Russias response to Georgia was right' '...</td>\n",
              "      <td>'US humanitarian missions soon in Georgia - i...</td>\n",
              "      <td>'Russian convoy heads into Georgia, violating...</td>\n",
              "      <td>'Gorbachev: We Had No Choice' 'Witness: Russi...</td>\n",
              "      <td>' Quarter of Russians blame U.S. for conflict...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-14</th>\n",
              "      <td>1</td>\n",
              "      <td>'All the experts admit that we should legalis...</td>\n",
              "      <td>'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
              "      <td>'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
              "      <td>'Poland and US agree to missle defense deal. ...</td>\n",
              "      <td>'Russia exaggerating South Ossetian death tol...</td>\n",
              "      <td>'Moscow Made Plans Months Ago to Invade Georg...</td>\n",
              "      <td>'Nigeria has handed over the potentially oil-...</td>\n",
              "      <td>'Russia apparently is sabotaging infrastructu...</td>\n",
              "      <td>\"Georgia confict could set back Russia's US r...</td>\n",
              "      <td>'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
              "      <td>'Saudi Arabia: Mother moves to block child ma...</td>\n",
              "      <td>'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Label  ...                                            News_12\n",
              "Date               ...                                                   \n",
              "2008-08-08      0  ...   'Indian shoe manufactory  - And again in a se...\n",
              "2008-08-11      1  ...   'Perhaps *the* question about the Georgia - R...\n",
              "2008-08-12      0  ...   'Christopher King argues that the US and NATO...\n",
              "2008-08-13      0  ...   ' Quarter of Russians blame U.S. for conflict...\n",
              "2008-08-14      1  ...   'Russia: World  \"can forget about\" Georgia\\'s...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 18
=======
          "execution_count": 348
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Gmqmlpkqhm"
      },
      "source": [
        "Egy új dataframebe újracsoportosítom a hír blokkokat a címkéjükkel, már a dátumok nélkül."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "YoeoCzPekrN2",
<<<<<<< HEAD
        "outputId": "7555295f-1f14-462b-aeb7-cfe09be4c354"
=======
        "outputId": "7a95ed55-bdb4-43ab-b2bb-ab79a89a8746"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "# The label column \r\n",
        "LABEL_COLUMN = 0\r\n",
        "\r\n",
        "news_sum = []\r\n",
        "label_sum = []\r\n",
        "\r\n",
        "# Get the column names\r\n",
        "combined_column_names = []\r\n",
        "for column in df_combined.columns:\r\n",
        "  combined_column_names.append(column)\r\n",
        "\r\n",
        "# Write out the column names \r\n",
        "print(combined_column_names)\r\n",
        "print(\"\\n\")\r\n",
        "\r\n",
        "# Connect the merged news with the labels\r\n",
        "for column in range(len(df_combined)):\r\n",
        "  for row in range(len(combined_column_names) - 1):\r\n",
        "    news_sum.append(df_combined[combined_column_names[row + 1]][column])\r\n",
        "    label_sum.append(df_combined[combined_column_names[LABEL_COLUMN]][column])\r\n",
        "\r\n",
        "# Create the new DataFrame\r\n",
        "df_sum_news_labels = pd.DataFrame(data = label_sum, index = None, columns = [\"Label\"])\r\n",
        "df_sum_news_labels[\"News\"] = news_sum\r\n",
        "\r\n",
        "# Show it\r\n",
        "df_sum_news_labels.head()"
      ],
<<<<<<< HEAD
      "execution_count": 19,
=======
      "execution_count": 349,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Label', 'News_1', 'News_2', 'News_3', 'News_4', 'News_5', 'News_6', 'News_7', 'News_8', 'News_9', 'News_10', 'News_11', 'News_12']\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>'Russia Today: Columns of troops roll into So...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>'Georgian troops retreat from S. Osettain cap...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label                                               News\n",
              "0      0   \"Georgia 'downs two Russian warplanes' as cou...\n",
              "1      0   'Russia Today: Columns of troops roll into So...\n",
              "2      0   \"Afghan children raped with 'impunity,' U.N. ...\n",
              "3      0   \"Breaking: Georgia invades South Ossetia, Rus...\n",
              "4      0   'Georgian troops retreat from S. Osettain cap..."
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 19
=======
          "execution_count": 349
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYQSgwmslqkO"
      },
      "source": [
        "Először a szövegek előfeldolgozásával kezdem: írásjelek eltávolítása, számok eltávolítása, felesleges szóközök eltávolítása, aztán minden szót kis kezdőbetűjü szóvá konvertálom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "YJT565FZlsgZ",
<<<<<<< HEAD
        "outputId": "aa611e9f-9ee1-4b55-bd9f-3893e08a3b89"
=======
        "outputId": "11b3808c-d8db-41c0-faa1-63320e7ac4ee"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "# Removing punctuations\r\n",
        "temp_news = []\r\n",
        "for line in news_sum:\r\n",
        "  temp_attach = \"\"\r\n",
        "  for word in line:\r\n",
        "    temp = \" \"\r\n",
        "    if word not in string.punctuation:\r\n",
        "      temp = word\r\n",
        "    temp_attach = temp_attach + \"\".join(temp)\r\n",
        "  temp_news.append(temp_attach)\r\n",
        "\r\n",
        "news_sum = temp_news\r\n",
        "temp_news = []\r\n",
        "\r\n",
        "# Remove numbers\r\n",
        "for line in news_sum:\r\n",
        "  temp_attach = \"\"\r\n",
        "  for word in line:\r\n",
        "    temp = \" \"\r\n",
        "    if not word.isdigit():\r\n",
        "      temp = word\r\n",
        "    temp_attach = temp_attach + \"\".join(temp)\r\n",
        "  temp_news.append(temp_attach)\r\n",
        "\r\n",
        "# Remove space\r\n",
        "for line in range(len(temp_news)):    \r\n",
        "  temp_news[line] = \" \".join(temp_news[line].split())\r\n",
        "\r\n",
        "# Converting headlines to lower case\r\n",
        "for line in range(len(temp_news)): \r\n",
        "    temp_news[line] = temp_news[line].lower()\r\n",
        "\r\n",
        "# Update the data frame\r\n",
        "df_sum_news_labels[\"News\"] = temp_news\r\n",
        "\r\n",
        "# Show it\r\n",
        "df_sum_news_labels.head()"
      ],
<<<<<<< HEAD
      "execution_count": 20,
=======
      "execution_count": 350,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>georgia downs two russian warplanes as countri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>russia today columns of troops roll into south...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>afghan children raped with impunity u n offici...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>breaking georgia invades south ossetia russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>georgian troops retreat from s osettain capita...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label                                               News\n",
              "0      0  georgia downs two russian warplanes as countri...\n",
              "1      0  russia today columns of troops roll into south...\n",
              "2      0  afghan children raped with impunity u n offici...\n",
              "3      0  breaking georgia invades south ossetia russia ...\n",
              "4      0  georgian troops retreat from s osettain capita..."
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 20
=======
          "execution_count": 350
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkCvCsvel989"
      },
      "source": [
        "A következőkben az úgy nevezett töltelék szavakat (stop words) fogom eltávolítani."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "k3WjnHkAmA4e",
<<<<<<< HEAD
        "outputId": "47bf7110-3acd-41c2-a7dd-86249275c428"
=======
        "outputId": "01ebf7ec-8374-4175-8ed3-5b8e39b8ff5f"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "# Load the stop words\r\n",
        "stop_words = set(stopwords.words('english'))\r\n",
        "\r\n",
        "filtered_sentence = []\r\n",
        "news_sum = df_sum_news_labels[\"News\"]\r\n",
        "\r\n",
        "# Remove stop words\r\n",
        "for line in news_sum:\r\n",
        "  word_tokens = word_tokenize(line)\r\n",
        "  temp_attach = \"\"\r\n",
        "  for word in word_tokens:\r\n",
        "    temp = \" \"\r\n",
        "    if not word in stop_words:\r\n",
        "      temp = temp + word\r\n",
        "    temp_attach = temp_attach + \"\".join(temp)\r\n",
        "  filtered_sentence.append(temp_attach)\r\n",
        "\r\n",
        "# Remove space\r\n",
        "for line in range(len(filtered_sentence)):    \r\n",
        "  filtered_sentence[line] = \" \".join(filtered_sentence[line].split())\r\n",
        "\r\n",
        "# Update the data frame\r\n",
        "df_sum_news_labels[\"News\"] = filtered_sentence\r\n",
        "\r\n",
        "# Show the DataFrame\r\n",
        "df_sum_news_labels.head()"
      ],
<<<<<<< HEAD
      "execution_count": 21,
=======
      "execution_count": 351,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>georgia downs two russian warplanes countries ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>russia today columns troops roll south ossetia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>afghan children raped impunity u n official sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>breaking georgia invades south ossetia russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>georgian troops retreat osettain capital presu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label                                               News\n",
              "0      0  georgia downs two russian warplanes countries ...\n",
              "1      0  russia today columns troops roll south ossetia...\n",
              "2      0  afghan children raped impunity u n official sa...\n",
              "3      0  breaking georgia invades south ossetia russia ...\n",
              "4      0  georgian troops retreat osettain capital presu..."
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 21
=======
          "execution_count": 351
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1DHwHi3mbDn"
      },
      "source": [
        "Az adathalmazban lévő nulla hosszú sztring csomagok megkeresése és a hozzájuk tartozó cellák törlése következik."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUqfwAe1mbqM",
<<<<<<< HEAD
        "outputId": "dbb379d0-f50c-472e-f1fa-d88c5f25779f"
=======
        "outputId": "a0a824bf-7828-4eed-b1c2-699f5de44ef7"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "news_sum = df_sum_news_labels[\"News\"]\r\n",
        "null_indexes = []\r\n",
        "index = 0\r\n",
        "\r\n",
        "for line in news_sum:\r\n",
        "  if line is \"\":\r\n",
        "    null_indexes.append(index)\r\n",
        "  index = index + 1\r\n",
        "\r\n",
        "print(null_indexes)\r\n",
        "\r\n",
        "for row in null_indexes:\r\n",
        "  df_sum_news_labels = df_sum_news_labels.drop(row)\r\n",
        "\r\n",
        "news_sum = df_sum_news_labels[\"News\"]\r\n",
        "null_indexes = []\r\n",
        "index = 0\r\n",
        "\r\n",
        "for line in news_sum:\r\n",
        "  if line is \"\":\r\n",
        "    null_indexes.append(index)\r\n",
        "  index = index + 1\r\n",
        "  \r\n",
        "assert len(null_indexes) is 0"
      ],
<<<<<<< HEAD
      "execution_count": 22,
=======
      "execution_count": 352,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3335]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UW_rMpOmlSH"
      },
      "source": [
        "Az adathalmaz véletlenszerű sorbarendezése."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "FwdW_tECmlxs",
<<<<<<< HEAD
        "outputId": "5f0ace63-f84f-4dbf-f59a-51947444c56f"
=======
        "outputId": "3266b199-c0d6-473c-8c69-3fd387b10f2d"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "# Do the shuffle\r\n",
        "for i in range(SHUFFLE_CYCLE):\r\n",
<<<<<<< HEAD
        "  df_sum_news_labels = shuffle(df_sum_news_labels, random_state = RANDOM_SEED)\r\n",
=======
        "  df_sum_news_labels = shuffle(df_sum_news_labels, random_state = rs)\r\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "\r\n",
        "# Reset the index\r\n",
        "df_sum_news_labels.reset_index(inplace=True, drop=True)\r\n",
        "\r\n",
        "# Show the data frame\r\n",
        "df_sum_news_labels.head()"
      ],
<<<<<<< HEAD
      "execution_count": 23,
=======
      "execution_count": 353,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
<<<<<<< HEAD
              "      <td>uk form promoted sir ian blair demands public ...</td>\n",
=======
              "      <td>israel stole b palestinian workers israeli eco...</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
<<<<<<< HEAD
              "      <td>ebola crisis west africa deepenspakistan man a...</td>\n",
=======
              "      <td>sec state john kerry russia lying face troops ...</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
<<<<<<< HEAD
              "      <td>killing whales let agree disagree says japanve...</td>\n",
=======
              "      <td>mining company idemitsu australia resources ad...</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
<<<<<<< HEAD
              "      <td>two week nobel prize winners talk destruction ...</td>\n",
=======
              "      <td>pirate party fires broadside german political ...</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
<<<<<<< HEAD
              "      <td>bus carrying foreign journalists north korea t...</td>\n",
=======
              "      <td>cairo court gives death penalty egyptian chris...</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label                                               News\n",
<<<<<<< HEAD
              "0      0  uk form promoted sir ian blair demands public ...\n",
              "1      1  ebola crisis west africa deepenspakistan man a...\n",
              "2      0  killing whales let agree disagree says japanve...\n",
              "3      0  two week nobel prize winners talk destruction ...\n",
              "4      1  bus carrying foreign journalists north korea t..."
=======
              "0      0  israel stole b palestinian workers israeli eco...\n",
              "1      1  sec state john kerry russia lying face troops ...\n",
              "2      0  mining company idemitsu australia resources ad...\n",
              "3      0  pirate party fires broadside german political ...\n",
              "4      1  cairo court gives death penalty egyptian chris..."
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 23
=======
          "execution_count": 353
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9cUBq_WnJbH"
      },
      "source": [
        "Az adathalmaz szétbontása tanító és validáló/tesztelő adathalmazokra, majd a szétbontás ellenőrzése mérettel és első elem kiíratásával."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-Mg2z7LnKH1",
<<<<<<< HEAD
        "outputId": "714b5e24-7e09-4791-f1f1-b6aa6750caac"
=======
        "outputId": "dfc2c9d8-ab9f-4c35-9bce-a08a8b6398ea"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "INPUT_SIZE = len(df_sum_news_labels)\r\n",
        "TRAIN_SIZE = int(TRAIN_SPLIT * INPUT_SIZE) \r\n",
        "TEST_SIZE = int(TEST_SPLIT * INPUT_SIZE)\r\n",
        "\r\n",
        "# Split the dataset\r\n",
        "train = df_sum_news_labels[:TRAIN_SIZE] \r\n",
        "test = df_sum_news_labels[TRAIN_SIZE:]\r\n",
        "\r\n",
        "# Print out the length\r\n",
        "print(\"Train data set length: \" + str(len(train)))\r\n",
        "print(\"Test data set length: \" + str(len(test)))\r\n",
        "print(\"Split summa: \" + str(len(train) + len(test)))\r\n",
        "print(\"Dataset summa before split: \" + str(len(df_sum_news_labels)))\r\n",
        "\r\n",
        "# check\r\n",
        "split_sum = len(train) + len(test)\r\n",
        "sum = len(df_sum_news_labels)\r\n",
        "assert split_sum == sum"
      ],
<<<<<<< HEAD
      "execution_count": 24,
=======
      "execution_count": 354,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data set length: 20286\n",
            "Test data set length: 3581\n",
            "Split summa: 23867\n",
            "Dataset summa before split: 23867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "s03PFsFQsgpS",
<<<<<<< HEAD
        "outputId": "f327c9e2-e36f-4be9-cbe5-be52e0e0d8f6"
=======
        "outputId": "f3ba4742-2cbc-43fc-ed40-27ed20ae30f6"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "train.tail(1)"
      ],
<<<<<<< HEAD
      "execution_count": 25,
=======
      "execution_count": 355,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20285</th>\n",
<<<<<<< HEAD
              "      <td>0</td>\n",
              "      <td>taiwan writes un womens rights convention dome...</td>\n",
=======
              "      <td>1</td>\n",
              "      <td>special forces raid bp moscow officespakistani...</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Label                                               News\n",
<<<<<<< HEAD
              "20285      0  taiwan writes un womens rights convention dome..."
=======
              "20285      1  special forces raid bp moscow officespakistani..."
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 25
=======
          "execution_count": 355
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "Au3VLLVzsh0U",
<<<<<<< HEAD
        "outputId": "6ca3d4e5-c2c8-40d7-ce77-f9ac31ef31c6"
=======
        "outputId": "417b5313-df97-4597-d6bb-ae3c4f045aa1"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "test.head(1)"
      ],
<<<<<<< HEAD
      "execution_count": 26,
=======
      "execution_count": 356,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20286</th>\n",
              "      <td>1</td>\n",
<<<<<<< HEAD
              "      <td>putin backs ukraine election russia putin says...</td>\n",
=======
              "      <td>charlie hebdo pakistani legislators chant deat...</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Label                                               News\n",
<<<<<<< HEAD
              "20286      1  putin backs ukraine election russia putin says..."
=======
              "20286      1  charlie hebdo pakistani legislators chant deat..."
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 26
=======
          "execution_count": 356
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
<<<<<<< HEAD
=======
        "id": "C0H2KEdmsNJA"
      },
      "source": [
        "Ezek lementése."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVLjLPzzsRs4"
      },
      "source": [
        "# save to drive\r\n",
        "train.to_csv('drive/MyDrive/Kaggle dataset/Reddit Top 25 DJIA/train.csv')\r\n",
        "test.to_csv('drive/MyDrive/Kaggle dataset/Reddit Top 25 DJIA/test.csv')"
      ],
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "id": "tRgA6S5muPbE"
      },
      "source": [
        "### Bag of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsDa53wcxRdG"
      },
      "source": [
        "Először a tanító adathalmaz híreit fűzöm össze egy tömbbe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "5RhOIEt3wmHn",
<<<<<<< HEAD
        "outputId": "54528920-b0e8-4576-9c31-05ed486eadd3"
=======
        "outputId": "5634ba26-413b-40a5-e35f-56144eb1f18d"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "train_headlines = []\r\n",
        "\r\n",
        "for row in range(0, len(train.index)):\r\n",
        "    train_headlines.append(train.iloc[row, 1])\r\n",
        "\r\n",
        "# show the first\r\n",
        "train_headlines[0]"
      ],
<<<<<<< HEAD
      "execution_count": 27,
=======
      "execution_count": 358,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
<<<<<<< HEAD
              "'uk form promoted sir ian blair demands public venues define ethnicity audience russia face massive social unrest russian industrial towns might face social unrest violence companies plan massive layoffs russian sociologist says'"
=======
              "'israel stole b palestinian workers israeli economists revealed generose lay bleeding near husbands corpse soldiers cut amputated leg cooked pieces ordered children eat mothers flesh one son refused kill kill told soldiers mother remembers eat part mother'"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 27
=======
          "execution_count": 358
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83MuhLlOxYK5"
      },
      "source": [
        "Ezek után vektorizálom őket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N3hIvbQxgr6",
<<<<<<< HEAD
        "outputId": "3d0dd4a2-7c71-447e-f211-b5f378937766"
=======
        "outputId": "199bdffa-bcb0-4e14-a950-591381af356b"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "bow_vectorizer = CountVectorizer()\r\n",
        "bow_train = bow_vectorizer.fit_transform(train_headlines)\r\n",
        "print(bow_train.shape)"
      ],
<<<<<<< HEAD
      "execution_count": 28,
=======
      "execution_count": 359,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "(20286, 38597)\n"
=======
            "(20286, 38607)\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExOpaN_Ix3r_"
      },
      "source": [
        "Egy logistic regression modellt fogok erre a tanító halmazra betanítani."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D36NSmICyOCC"
      },
      "source": [
        "bow_model = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "bow_model = bow_model.fit(bow_train, train[\"Label\"])"
      ],
<<<<<<< HEAD
      "execution_count": 29,
=======
      "execution_count": 360,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7EYr5_yygsr"
      },
      "source": [
        "A teszt adathalmaz előkészítése, majd becslés a modell segítségével a következő lépés."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkxsor9uygSa"
      },
      "source": [
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "bow_test = bow_vectorizer.transform(test_headlines)\r\n",
        "bow_predictions = bow_model.predict(bow_test)"
      ],
<<<<<<< HEAD
      "execution_count": 30,
=======
      "execution_count": 361,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFBYXRil2nS2"
      },
      "source": [
        "Az eredmények megjelenítése egy táblázatban."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "Vfgw4P9-2rkL",
<<<<<<< HEAD
        "outputId": "fbb9d5bb-6224-4600-9872-1445491338c9"
=======
        "outputId": "bc36858d-ade3-4fd3-f656-d55f932215fe"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "pd.crosstab(test[\"Label\"], bow_predictions, rownames=[\"Actual\"], colnames=[\"Predicted\"])"
      ],
<<<<<<< HEAD
      "execution_count": 31,
=======
      "execution_count": 362,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
<<<<<<< HEAD
              "      <td>698</td>\n",
              "      <td>964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>810</td>\n",
              "      <td>1109</td>\n",
=======
              "      <td>722</td>\n",
              "      <td>895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>856</td>\n",
              "      <td>1108</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted    0     1\n",
              "Actual              \n",
<<<<<<< HEAD
              "0          698   964\n",
              "1          810  1109"
=======
              "0          722   895\n",
              "1          856  1108"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 31
=======
          "execution_count": 362
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9uWaAGm3E_J"
      },
      "source": [
        "A pontossága a modellnek."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHxtBIe23HqK",
<<<<<<< HEAD
        "outputId": "d6856ee7-77ac-4fae-9eda-9e9acdba8b6d"
=======
        "outputId": "b00d79a7-971a-4b94-d2d2-51f4a8a18d86"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "print (classification_report(test[\"Label\"], bow_predictions))\r\n",
        "print (accuracy_score(test[\"Label\"], bow_predictions))\r\n",
        "\r\n",
        "result.append(accuracy_score(test[\"Label\"], bow_predictions))"
      ],
<<<<<<< HEAD
      "execution_count": 32,
=======
      "execution_count": 363,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
<<<<<<< HEAD
            "           0       0.46      0.42      0.44      1662\n",
            "           1       0.53      0.58      0.56      1919\n",
            "\n",
            "    accuracy                           0.50      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.50      0.50      0.50      3581\n",
            "\n",
            "0.5046076514939961\n"
=======
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQZQqPar4Im8"
      },
      "source": [
        "A következőkben a top 10 legbefolyásolóbb sztringet jelenítem meg mind pozítiv és mind negatív irányba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "oveqbdwt4Q-9",
<<<<<<< HEAD
        "outputId": "d53fc4f2-3e71-4f24-8d1e-d7a6a254e204"
=======
        "outputId": "05246602-c5e4-4f34-d5ff-58a014a27f6d"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "bow_words = bow_vectorizer.get_feature_names()\r\n",
        "bow_coeffs = bow_model.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : bow_words, \r\n",
        "                        'Coefficient' : bow_coeffs})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "coeffdf.head(10)"
      ],
<<<<<<< HEAD
      "execution_count": 33,
=======
      "execution_count": 364,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <th>29152</th>\n",
              "      <td>riyadh</td>\n",
              "      <td>1.652154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34468</th>\n",
              "      <td>thriving</td>\n",
              "      <td>1.606117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18845</th>\n",
              "      <td>landing</td>\n",
              "      <td>1.598721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16996</th>\n",
              "      <td>intercept</td>\n",
              "      <td>1.592312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29752</th>\n",
              "      <td>sanaa</td>\n",
              "      <td>1.558651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1493</th>\n",
              "      <td>anyway</td>\n",
              "      <td>1.461035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35585</th>\n",
              "      <td>ugandan</td>\n",
              "      <td>1.432039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10943</th>\n",
              "      <td>enemies</td>\n",
              "      <td>1.406581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35048</th>\n",
              "      <td>transition</td>\n",
              "      <td>1.404805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26713</th>\n",
              "      <td>proposals</td>\n",
              "      <td>1.401941</td>\n",
=======
              "      <th>37860</th>\n",
              "      <td>wolves</td>\n",
              "      <td>1.575139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34454</th>\n",
              "      <td>thriving</td>\n",
              "      <td>1.555963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18822</th>\n",
              "      <td>landing</td>\n",
              "      <td>1.423610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29746</th>\n",
              "      <td>sanaa</td>\n",
              "      <td>1.413760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29141</th>\n",
              "      <td>riyadh</td>\n",
              "      <td>1.389342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9779</th>\n",
              "      <td>division</td>\n",
              "      <td>1.387358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6402</th>\n",
              "      <td>collection</td>\n",
              "      <td>1.378622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20284</th>\n",
              "      <td>manipulate</td>\n",
              "      <td>1.356852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21932</th>\n",
              "      <td>movies</td>\n",
              "      <td>1.354048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6072</th>\n",
              "      <td>clashed</td>\n",
              "      <td>1.340151</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Word  Coefficient\n",
<<<<<<< HEAD
              "29152      riyadh     1.652154\n",
              "34468    thriving     1.606117\n",
              "18845     landing     1.598721\n",
              "16996   intercept     1.592312\n",
              "29752       sanaa     1.558651\n",
              "1493       anyway     1.461035\n",
              "35585     ugandan     1.432039\n",
              "10943     enemies     1.406581\n",
              "35048  transition     1.404805\n",
              "26713   proposals     1.401941"
=======
              "37860      wolves     1.575139\n",
              "34454    thriving     1.555963\n",
              "18822     landing     1.423610\n",
              "29746       sanaa     1.413760\n",
              "29141      riyadh     1.389342\n",
              "9779     division     1.387358\n",
              "6402   collection     1.378622\n",
              "20284  manipulate     1.356852\n",
              "21932      movies     1.354048\n",
              "6072      clashed     1.340151"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 33
=======
          "execution_count": 364
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "EKPketqV4uVw",
<<<<<<< HEAD
        "outputId": "cbf093fd-c895-4afa-91c8-79905f334f0f"
=======
        "outputId": "a018ff0c-d158-433c-df3c-77b039254f42"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "coeffdf.tail(10)"
      ],
<<<<<<< HEAD
      "execution_count": 34,
=======
      "execution_count": 365,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <th>882</th>\n",
              "      <td>airways</td>\n",
              "      <td>-1.356654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19181</th>\n",
              "      <td>lecture</td>\n",
              "      <td>-1.386058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34105</th>\n",
              "      <td>temporary</td>\n",
              "      <td>-1.388032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26593</th>\n",
              "      <td>profound</td>\n",
              "      <td>-1.398332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5828</th>\n",
              "      <td>choppers</td>\n",
              "      <td>-1.457017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32757</th>\n",
              "      <td>stranded</td>\n",
              "      <td>-1.513365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30598</th>\n",
              "      <td>separation</td>\n",
              "      <td>-1.515334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5353</th>\n",
              "      <td>census</td>\n",
              "      <td>-1.517089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10587</th>\n",
              "      <td>egypts</td>\n",
              "      <td>-1.522416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811</th>\n",
              "      <td>barclays</td>\n",
              "      <td>-1.691836</td>\n",
=======
              "      <th>15686</th>\n",
              "      <td>horns</td>\n",
              "      <td>-1.304928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25589</th>\n",
              "      <td>player</td>\n",
              "      <td>-1.329162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32153</th>\n",
              "      <td>spilled</td>\n",
              "      <td>-1.333695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25317</th>\n",
              "      <td>picked</td>\n",
              "      <td>-1.342825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5847</th>\n",
              "      <td>choppers</td>\n",
              "      <td>-1.347697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7215</th>\n",
              "      <td>contributed</td>\n",
              "      <td>-1.354432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3140</th>\n",
              "      <td>begging</td>\n",
              "      <td>-1.359860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15680</th>\n",
              "      <td>hormuz</td>\n",
              "      <td>-1.365731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20925</th>\n",
              "      <td>merchant</td>\n",
              "      <td>-1.407644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>census</td>\n",
              "      <td>-1.428086</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
<<<<<<< HEAD
              "             Word  Coefficient\n",
              "882       airways    -1.356654\n",
              "19181     lecture    -1.386058\n",
              "34105   temporary    -1.388032\n",
              "26593    profound    -1.398332\n",
              "5828     choppers    -1.457017\n",
              "32757    stranded    -1.513365\n",
              "30598  separation    -1.515334\n",
              "5353       census    -1.517089\n",
              "10587      egypts    -1.522416\n",
              "2811     barclays    -1.691836"
=======
              "              Word  Coefficient\n",
              "15686        horns    -1.304928\n",
              "25589       player    -1.329162\n",
              "32153      spilled    -1.333695\n",
              "25317       picked    -1.342825\n",
              "5847      choppers    -1.347697\n",
              "7215   contributed    -1.354432\n",
              "3140       begging    -1.359860\n",
              "15680       hormuz    -1.365731\n",
              "20925     merchant    -1.407644\n",
              "5372        census    -1.428086"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 34
=======
          "execution_count": 365
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytoEWvZ_48_x"
      },
      "source": [
        "### 2-gram modell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_11F44gu5TdJ"
      },
      "source": [
        "Hasonlóan az eddigiekhez vektorizálom a tanító adathalmazom, logistic regression modellt illesztek rá, becslést hajtok végre majd kiértékelem az eredményeket. Először a (1,2) n-gram modellel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1reDgLAU5jQd",
<<<<<<< HEAD
        "outputId": "4ef480e5-3f6c-4f6b-c36e-f00468b9ecd5"
=======
        "outputId": "a14a35f8-4e7e-42fa-dbf7-f3b6f750035e"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "gram_vectorizer_12 = CountVectorizer(ngram_range=(1,2))\r\n",
        "train_vectorizer_12 = gram_vectorizer_12.fit_transform(train_headlines)\r\n",
        "\r\n",
        "print(train_vectorizer_12.shape)\r\n",
        "\r\n",
        "gram_model_12 = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "gram_model_12 = gram_model_12.fit(train_vectorizer_12, train[\"Label\"])\r\n",
        "\r\n",
<<<<<<< HEAD
        "gram_test_12 = gram_vectorizer_12.transform(test_headlines)\r\n",
        "gram_predictions_12 = gram_model_12.predict(gram_test_12)\r\n",
        "\r\n",
=======
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "gram_test_12 = gram_vectorizer_12.transform(test_headlines)\r\n",
        "gram_predictions_12 = gram_model_12.predict(gram_test_12)\r\n",
        "\r\n",
        "pd.crosstab(test[\"Label\"], gram_predictions_12, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "print (classification_report(test[\"Label\"], gram_predictions_12))\r\n",
        "print (accuracy_score(test[\"Label\"], gram_predictions_12))\r\n",
        "\r\n",
        "result.append(accuracy_score(test[\"Label\"], gram_predictions_12))"
      ],
<<<<<<< HEAD
      "execution_count": 35,
=======
      "execution_count": 366,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "(20286, 387666)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.39      0.43      1662\n",
            "           1       0.55      0.64      0.59      1919\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5230382574699804\n"
=======
            "(20286, 387915)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "t_JxbXWM7wss",
<<<<<<< HEAD
        "outputId": "144e8818-a7bd-4d91-bcf6-66b12bd5c278"
=======
        "outputId": "3f55fd4f-ea30-4c87-98b8-cbd6b1d50a13"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "gram_words_12 = gram_vectorizer_12.get_feature_names()\r\n",
        "gram_coeffs_12 = gram_model_12.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : gram_words_12, \r\n",
        "                        'Coefficient' : gram_coeffs_12})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "coeffdf.head(10)"
      ],
<<<<<<< HEAD
      "execution_count": 36,
=======
      "execution_count": 367,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <th>189133</th>\n",
              "      <td>landing</td>\n",
              "      <td>0.965702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108882</th>\n",
              "      <td>enemies</td>\n",
              "      <td>0.961186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167531</th>\n",
              "      <td>influence</td>\n",
              "      <td>0.952113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162036</th>\n",
              "      <td>identified</td>\n",
              "      <td>0.948218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169960</th>\n",
              "      <td>intercept</td>\n",
              "      <td>0.904252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305149</th>\n",
              "      <td>seize</td>\n",
              "      <td>0.900881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>abroad</td>\n",
              "      <td>0.846290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312974</th>\n",
              "      <td>significant</td>\n",
              "      <td>0.829626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37258</th>\n",
              "      <td>blackout</td>\n",
              "      <td>0.824972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146721</th>\n",
              "      <td>green</td>\n",
              "      <td>0.820125</td>\n",
=======
              "      <th>189169</th>\n",
              "      <td>landing</td>\n",
              "      <td>0.985440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304143</th>\n",
              "      <td>security council</td>\n",
              "      <td>0.930576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222340</th>\n",
              "      <td>mumbai</td>\n",
              "      <td>0.868996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379692</th>\n",
              "      <td>wolves</td>\n",
              "      <td>0.841094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308844</th>\n",
              "      <td>sexual violence</td>\n",
              "      <td>0.835806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341463</th>\n",
              "      <td>terror attack</td>\n",
              "      <td>0.826805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202341</th>\n",
              "      <td>luxury</td>\n",
              "      <td>0.812963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305226</th>\n",
              "      <td>seize</td>\n",
              "      <td>0.812070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45967</th>\n",
              "      <td>buildings</td>\n",
              "      <td>0.791482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>abroad</td>\n",
              "      <td>0.788123</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
<<<<<<< HEAD
              "               Word  Coefficient\n",
              "189133      landing     0.965702\n",
              "108882      enemies     0.961186\n",
              "167531    influence     0.952113\n",
              "162036   identified     0.948218\n",
              "169960    intercept     0.904252\n",
              "305149        seize     0.900881\n",
              "796          abroad     0.846290\n",
              "312974  significant     0.829626\n",
              "37258      blackout     0.824972\n",
              "146721        green     0.820125"
=======
              "                    Word  Coefficient\n",
              "189169           landing     0.985440\n",
              "304143  security council     0.930576\n",
              "222340            mumbai     0.868996\n",
              "379692            wolves     0.841094\n",
              "308844   sexual violence     0.835806\n",
              "341463     terror attack     0.826805\n",
              "202341            luxury     0.812963\n",
              "305226             seize     0.812070\n",
              "45967          buildings     0.791482\n",
              "817               abroad     0.788123"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 36
=======
          "execution_count": 367
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "g96l9WK57xMH",
<<<<<<< HEAD
        "outputId": "df60ea5f-c15e-41ba-a0e0-dd34af06a1df"
=======
        "outputId": "aadf87b1-4ba9-4f0d-ec7c-2c40fc9f23eb"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "coeffdf.tail(10)"
      ],
<<<<<<< HEAD
      "execution_count": 37,
=======
      "execution_count": 368,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <th>74623</th>\n",
              "      <td>cooperation</td>\n",
              "      <td>-0.823124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201708</th>\n",
              "      <td>low</td>\n",
              "      <td>-0.833886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105743</th>\n",
              "      <td>egypts</td>\n",
              "      <td>-0.880279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227415</th>\n",
              "      <td>nepal</td>\n",
              "      <td>-0.931394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30566</th>\n",
              "      <td>barclays</td>\n",
              "      <td>-0.933883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327481</th>\n",
              "      <td>stranded</td>\n",
              "      <td>-0.936199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55120</th>\n",
              "      <td>census</td>\n",
              "      <td>-0.936524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297907</th>\n",
              "      <td>saudi king</td>\n",
              "      <td>-0.942706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378793</th>\n",
              "      <td>withdraw</td>\n",
              "      <td>-0.967675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318224</th>\n",
              "      <td>somalia</td>\n",
              "      <td>-0.985485</td>\n",
=======
              "      <th>33163</th>\n",
              "      <td>begin</td>\n",
              "      <td>-0.780491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327730</th>\n",
              "      <td>stranded</td>\n",
              "      <td>-0.785083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325355</th>\n",
              "      <td>statistics</td>\n",
              "      <td>-0.797791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158709</th>\n",
              "      <td>hormuz</td>\n",
              "      <td>-0.809017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201819</th>\n",
              "      <td>low</td>\n",
              "      <td>-0.814543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55167</th>\n",
              "      <td>census</td>\n",
              "      <td>-0.841566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17177</th>\n",
              "      <td>appeal</td>\n",
              "      <td>-0.855236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227465</th>\n",
              "      <td>nepal</td>\n",
              "      <td>-0.893965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318316</th>\n",
              "      <td>somalia</td>\n",
              "      <td>-0.973756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362365</th>\n",
              "      <td>us army</td>\n",
              "      <td>-1.024815</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
<<<<<<< HEAD
              "               Word  Coefficient\n",
              "74623   cooperation    -0.823124\n",
              "201708          low    -0.833886\n",
              "105743       egypts    -0.880279\n",
              "227415        nepal    -0.931394\n",
              "30566      barclays    -0.933883\n",
              "327481     stranded    -0.936199\n",
              "55120        census    -0.936524\n",
              "297907   saudi king    -0.942706\n",
              "378793     withdraw    -0.967675\n",
              "318224      somalia    -0.985485"
=======
              "              Word  Coefficient\n",
              "33163        begin    -0.780491\n",
              "327730    stranded    -0.785083\n",
              "325355  statistics    -0.797791\n",
              "158709      hormuz    -0.809017\n",
              "201819         low    -0.814543\n",
              "55167       census    -0.841566\n",
              "17177       appeal    -0.855236\n",
              "227465       nepal    -0.893965\n",
              "318316     somalia    -0.973756\n",
              "362365     us army    -1.024815"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 37
=======
          "execution_count": 368
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFrdv3Um9CoD"
      },
      "source": [
        "Másodjára a (2,2) n-gram modellel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IdZdzJl9Ftm",
<<<<<<< HEAD
        "outputId": "b29a3558-e18a-4721-d1d5-79cc9e0b9321"
=======
        "outputId": "7fb628ee-c85f-41c4-edfc-9ab9dcd06f65"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "gram_vectorizer_22 = CountVectorizer(ngram_range=(2,2))\r\n",
        "train_vectorizer_22 = gram_vectorizer_22.fit_transform(train_headlines)\r\n",
        "\r\n",
        "print(train_vectorizer_22.shape)\r\n",
        "\r\n",
        "gram_model_22 = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "gram_model_22 = gram_model_22.fit(train_vectorizer_22, train[\"Label\"])\r\n",
        "\r\n",
<<<<<<< HEAD
=======
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "gram_test_22 = gram_vectorizer_22.transform(test_headlines)\r\n",
        "gram_predictions_22 = gram_model_22.predict(gram_test_22)\r\n",
        "\r\n",
        "pd.crosstab(test[\"Label\"], gram_predictions_22, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "print (classification_report(test[\"Label\"], gram_predictions_22))\r\n",
        "print (accuracy_score(test[\"Label\"], gram_predictions_22))\r\n",
        "\r\n",
        "result.append(accuracy_score(test[\"Label\"], gram_predictions_22))"
      ],
<<<<<<< HEAD
      "execution_count": 38,
=======
      "execution_count": 369,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "(20286, 349069)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.30      0.38      1662\n",
            "           1       0.55      0.74      0.63      1919\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.52      0.50      3581\n",
            "weighted avg       0.53      0.54      0.51      3581\n",
            "\n",
            "0.5356045797263335\n"
=======
            "(20286, 349308)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "snpLViV79GlO",
<<<<<<< HEAD
        "outputId": "2acc2b43-1cb2-4dba-b02c-9367f43eb49b"
=======
        "outputId": "40b78be5-e3d4-4acd-a88e-bad247bb4fe8"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "gram_words_22 = gram_vectorizer_22.get_feature_names()\r\n",
        "gram_coeffs_22 = gram_model_22.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : gram_words_22, \r\n",
        "                        'Coefficient' : gram_coeffs_22})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "coeffdf.head(10)"
      ],
<<<<<<< HEAD
      "execution_count": 39,
=======
      "execution_count": 370,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <th>161653</th>\n",
              "      <td>jazeera english</td>\n",
              "      <td>0.869494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278036</th>\n",
              "      <td>sexual violence</td>\n",
              "      <td>0.822566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121295</th>\n",
              "      <td>french president</td>\n",
              "      <td>0.798240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152664</th>\n",
              "      <td>intelligence agencies</td>\n",
              "      <td>0.771891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343669</th>\n",
              "      <td>world cup</td>\n",
              "      <td>0.755882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285350</th>\n",
              "      <td>social media</td>\n",
              "      <td>0.753069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124460</th>\n",
              "      <td>gaza border</td>\n",
              "      <td>0.751969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134717</th>\n",
              "      <td>gunmen kill</td>\n",
              "      <td>0.749832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32016</th>\n",
              "      <td>big brother</td>\n",
              "      <td>0.743814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8029</th>\n",
              "      <td>air pollution</td>\n",
              "      <td>0.742354</td>\n",
=======
              "      <th>273713</th>\n",
              "      <td>security council</td>\n",
              "      <td>0.931506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261036</th>\n",
              "      <td>rights watch</td>\n",
              "      <td>0.907768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278130</th>\n",
              "      <td>sexual violence</td>\n",
              "      <td>0.873731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326960</th>\n",
              "      <td>us spying</td>\n",
              "      <td>0.796756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8109</th>\n",
              "      <td>air pollution</td>\n",
              "      <td>0.772872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1787</th>\n",
              "      <td>according new</td>\n",
              "      <td>0.771510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223688</th>\n",
              "      <td>peace deal</td>\n",
              "      <td>0.764626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209611</th>\n",
              "      <td>nuclear strike</td>\n",
              "      <td>0.755552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93315</th>\n",
              "      <td>eastern ukraine</td>\n",
              "      <td>0.727508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311763</th>\n",
              "      <td>time since</td>\n",
              "      <td>0.725524</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
<<<<<<< HEAD
              "                         Word  Coefficient\n",
              "161653        jazeera english     0.869494\n",
              "278036        sexual violence     0.822566\n",
              "121295       french president     0.798240\n",
              "152664  intelligence agencies     0.771891\n",
              "343669              world cup     0.755882\n",
              "285350           social media     0.753069\n",
              "124460            gaza border     0.751969\n",
              "134717            gunmen kill     0.749832\n",
              "32016             big brother     0.743814\n",
              "8029            air pollution     0.742354"
=======
              "                    Word  Coefficient\n",
              "273713  security council     0.931506\n",
              "261036      rights watch     0.907768\n",
              "278130   sexual violence     0.873731\n",
              "326960         us spying     0.796756\n",
              "8109       air pollution     0.772872\n",
              "1787       according new     0.771510\n",
              "223688        peace deal     0.764626\n",
              "209611    nuclear strike     0.755552\n",
              "93315    eastern ukraine     0.727508\n",
              "311763        time since     0.725524"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 39
=======
          "execution_count": 370
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "uiSp21nl9Gai",
<<<<<<< HEAD
        "outputId": "07f715ef-f29e-4c04-87c1-be6ed8cfd6f1"
=======
        "outputId": "82f27292-4c61-45b0-c632-d1a7b3ea4875"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "coeffdf.tail(10)"
      ],
<<<<<<< HEAD
      "execution_count": 40,
=======
      "execution_count": 371,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <th>54792</th>\n",
              "      <td>chinese officials</td>\n",
              "      <td>-0.781498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80759</th>\n",
              "      <td>defense system</td>\n",
              "      <td>-0.793795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220105</th>\n",
              "      <td>panama papers</td>\n",
              "      <td>-0.801892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322400</th>\n",
              "      <td>un chief</td>\n",
              "      <td>-0.808713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285687</th>\n",
              "      <td>solar system</td>\n",
              "      <td>-0.813581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325952</th>\n",
              "      <td>us army</td>\n",
              "      <td>-0.820279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293542</th>\n",
              "      <td>stock market</td>\n",
              "      <td>-0.847732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135426</th>\n",
              "      <td>haiti earthquake</td>\n",
              "      <td>-0.866586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192802</th>\n",
              "      <td>military bases</td>\n",
              "      <td>-0.873164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268028</th>\n",
              "      <td>saudi king</td>\n",
              "      <td>-1.150206</td>\n",
=======
              "      <th>299371</th>\n",
              "      <td>support israel</td>\n",
              "      <td>-0.746145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285792</th>\n",
              "      <td>solar system</td>\n",
              "      <td>-0.774426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293773</th>\n",
              "      <td>stock market</td>\n",
              "      <td>-0.774850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294959</th>\n",
              "      <td>strait hormuz</td>\n",
              "      <td>-0.783698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54807</th>\n",
              "      <td>chinese officials</td>\n",
              "      <td>-0.787793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220259</th>\n",
              "      <td>panama papers</td>\n",
              "      <td>-0.852689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192889</th>\n",
              "      <td>military bases</td>\n",
              "      <td>-0.904961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268109</th>\n",
              "      <td>saudi king</td>\n",
              "      <td>-0.922218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334265</th>\n",
              "      <td>war iran</td>\n",
              "      <td>-0.940277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326071</th>\n",
              "      <td>us army</td>\n",
              "      <td>-1.035989</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Word  Coefficient\n",
<<<<<<< HEAD
              "54792   chinese officials    -0.781498\n",
              "80759      defense system    -0.793795\n",
              "220105      panama papers    -0.801892\n",
              "322400           un chief    -0.808713\n",
              "285687       solar system    -0.813581\n",
              "325952            us army    -0.820279\n",
              "293542       stock market    -0.847732\n",
              "135426   haiti earthquake    -0.866586\n",
              "192802     military bases    -0.873164\n",
              "268028         saudi king    -1.150206"
=======
              "299371     support israel    -0.746145\n",
              "285792       solar system    -0.774426\n",
              "293773       stock market    -0.774850\n",
              "294959      strait hormuz    -0.783698\n",
              "54807   chinese officials    -0.787793\n",
              "220259      panama papers    -0.852689\n",
              "192889     military bases    -0.904961\n",
              "268109         saudi king    -0.922218\n",
              "334265           war iran    -0.940277\n",
              "326071            us army    -1.035989"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 40
=======
          "execution_count": 371
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUxZOqjo5Eg7"
      },
      "source": [
        "### 3-gram modell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX7vV_715ckj"
      },
      "source": [
        "Hasonlóan az eddigiekhez vektorizálom a tanító adathalmazom, logistic regression modellt illesztek rá, becslést hajtok végre majd kiértékelem az eredményeket. Először a (1,3) n-gram modellel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRNHw3tAMSjp",
<<<<<<< HEAD
        "outputId": "3b2f9386-5a88-42d8-f4d1-48101ad2d5ac"
=======
        "outputId": "6b21a676-3abe-4fd8-81df-6295cc3a48f9"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "gram_vectorizer_13 = CountVectorizer(ngram_range=(1,3))\r\n",
        "train_vectorizer_13 = gram_vectorizer_13.fit_transform(train_headlines)\r\n",
        "\r\n",
        "print(train_vectorizer_13.shape)\r\n",
        "\r\n",
        "gram_model_13 = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "gram_model_13 = gram_model_13.fit(train_vectorizer_13, train[\"Label\"])\r\n",
        "\r\n",
<<<<<<< HEAD
        "gram_test_13 = gram_vectorizer_13.transform(test_headlines)\r\n",
        "gram_predictions_13 = gram_model_13.predict(gram_test_13)\r\n",
        "\r\n",
=======
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "gram_test_13 = gram_vectorizer_13.transform(test_headlines)\r\n",
        "gram_predictions_13 = gram_model_13.predict(gram_test_13)\r\n",
        "\r\n",
        "pd.crosstab(test[\"Label\"], gram_predictions_13, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "print (classification_report(test[\"Label\"], gram_predictions_13))\r\n",
        "print (accuracy_score(test[\"Label\"], gram_predictions_13))\r\n",
        "\r\n",
        "result.append(accuracy_score(test[\"Label\"], gram_predictions_13))"
      ],
<<<<<<< HEAD
      "execution_count": 41,
=======
      "execution_count": 372,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "(20286, 801460)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.39      0.44      1662\n",
            "           1       0.55      0.66      0.60      1919\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.53      0.52      0.52      3581\n",
            "weighted avg       0.53      0.53      0.52      3581\n",
            "\n",
            "0.5330913152750628\n"
=======
            "(20286, 802274)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "AG-xubCYMiFF",
<<<<<<< HEAD
        "outputId": "91fb02bc-1214-4a8f-c5c6-9bdfd4932b1c"
=======
        "outputId": "e1a95aaa-e7cd-446c-d427-c5ef149d2d2a"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "gram_words_13 = gram_vectorizer_13.get_feature_names()\r\n",
        "gram_coeffs_13 = gram_model_13.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : gram_words_13, \r\n",
        "                        'Coefficient' : gram_coeffs_13})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "coeffdf.head(10)"
      ],
<<<<<<< HEAD
      "execution_count": 42,
=======
      "execution_count": 373,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <th>629547</th>\n",
              "      <td>seize</td>\n",
              "      <td>0.775658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331944</th>\n",
              "      <td>identified</td>\n",
              "      <td>0.767014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342761</th>\n",
              "      <td>influence</td>\n",
              "      <td>0.750768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300949</th>\n",
              "      <td>green</td>\n",
              "      <td>0.748597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388540</th>\n",
              "      <td>landing</td>\n",
              "      <td>0.727010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221817</th>\n",
              "      <td>enemies</td>\n",
              "      <td>0.713953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761392</th>\n",
              "      <td>volcano</td>\n",
              "      <td>0.712706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456849</th>\n",
              "      <td>mumbai</td>\n",
              "      <td>0.683135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568956</th>\n",
              "      <td>rate</td>\n",
              "      <td>0.680255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347439</th>\n",
              "      <td>intercept</td>\n",
              "      <td>0.672334</td>\n",
=======
              "      <th>457197</th>\n",
              "      <td>mumbai</td>\n",
              "      <td>0.798173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388804</th>\n",
              "      <td>landing</td>\n",
              "      <td>0.754990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629974</th>\n",
              "      <td>seize</td>\n",
              "      <td>0.702728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627639</th>\n",
              "      <td>security council</td>\n",
              "      <td>0.698021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391604</th>\n",
              "      <td>latest</td>\n",
              "      <td>0.686259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14397</th>\n",
              "      <td>agencies</td>\n",
              "      <td>0.672385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>679261</th>\n",
              "      <td>struggle</td>\n",
              "      <td>0.670076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761964</th>\n",
              "      <td>volcano</td>\n",
              "      <td>0.664893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415963</th>\n",
              "      <td>luxury</td>\n",
              "      <td>0.635630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94259</th>\n",
              "      <td>buildings</td>\n",
              "      <td>0.632831</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
<<<<<<< HEAD
              "              Word  Coefficient\n",
              "629547       seize     0.775658\n",
              "331944  identified     0.767014\n",
              "342761   influence     0.750768\n",
              "300949       green     0.748597\n",
              "388540     landing     0.727010\n",
              "221817     enemies     0.713953\n",
              "761392     volcano     0.712706\n",
              "456849      mumbai     0.683135\n",
              "568956        rate     0.680255\n",
              "347439   intercept     0.672334"
=======
              "                    Word  Coefficient\n",
              "457197            mumbai     0.798173\n",
              "388804           landing     0.754990\n",
              "629974             seize     0.702728\n",
              "627639  security council     0.698021\n",
              "391604            latest     0.686259\n",
              "14397           agencies     0.672385\n",
              "679261          struggle     0.670076\n",
              "761964           volcano     0.664893\n",
              "415963            luxury     0.635630\n",
              "94259          buildings     0.632831"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 42
=======
          "execution_count": 373
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "DequuzvFMmH3",
<<<<<<< HEAD
        "outputId": "de7bfb17-9248-4172-df0b-a3c2f56499d3"
=======
        "outputId": "71b27243-eaae-4e33-8988-f659294ea6f3"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "coeffdf.tail(10)"
      ],
<<<<<<< HEAD
      "execution_count": 43,
=======
      "execution_count": 374,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <th>62917</th>\n",
              "      <td>barclays</td>\n",
              "      <td>-0.676459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175268</th>\n",
              "      <td>de</td>\n",
              "      <td>-0.685886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614141</th>\n",
              "      <td>saudi king</td>\n",
              "      <td>-0.690781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69078</th>\n",
              "      <td>beijing</td>\n",
              "      <td>-0.690905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>675482</th>\n",
              "      <td>stranded</td>\n",
              "      <td>-0.708413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112590</th>\n",
              "      <td>census</td>\n",
              "      <td>-0.724191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414630</th>\n",
              "      <td>low</td>\n",
              "      <td>-0.764888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467471</th>\n",
              "      <td>nepal</td>\n",
              "      <td>-0.769765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781768</th>\n",
              "      <td>withdraw</td>\n",
              "      <td>-0.781474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>656218</th>\n",
              "      <td>somalia</td>\n",
              "      <td>-0.930461</td>\n",
=======
              "      <th>112761</th>\n",
              "      <td>census</td>\n",
              "      <td>-0.641643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594601</th>\n",
              "      <td>revolt</td>\n",
              "      <td>-0.642421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723238</th>\n",
              "      <td>trafficking</td>\n",
              "      <td>-0.659209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68214</th>\n",
              "      <td>begin</td>\n",
              "      <td>-0.661095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35574</th>\n",
              "      <td>appeal</td>\n",
              "      <td>-0.738186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693724</th>\n",
              "      <td>system</td>\n",
              "      <td>-0.740079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747588</th>\n",
              "      <td>us army</td>\n",
              "      <td>-0.748473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467784</th>\n",
              "      <td>nepal</td>\n",
              "      <td>-0.749290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414991</th>\n",
              "      <td>low</td>\n",
              "      <td>-0.756724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>656691</th>\n",
              "      <td>somalia</td>\n",
              "      <td>-0.922395</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
<<<<<<< HEAD
              "              Word  Coefficient\n",
              "62917     barclays    -0.676459\n",
              "175268          de    -0.685886\n",
              "614141  saudi king    -0.690781\n",
              "69078      beijing    -0.690905\n",
              "675482    stranded    -0.708413\n",
              "112590      census    -0.724191\n",
              "414630         low    -0.764888\n",
              "467471       nepal    -0.769765\n",
              "781768    withdraw    -0.781474\n",
              "656218     somalia    -0.930461"
=======
              "               Word  Coefficient\n",
              "112761       census    -0.641643\n",
              "594601       revolt    -0.642421\n",
              "723238  trafficking    -0.659209\n",
              "68214         begin    -0.661095\n",
              "35574        appeal    -0.738186\n",
              "693724       system    -0.740079\n",
              "747588      us army    -0.748473\n",
              "467784        nepal    -0.749290\n",
              "414991          low    -0.756724\n",
              "656691      somalia    -0.922395"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 43
=======
          "execution_count": 374
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHmKu3djMS14"
      },
      "source": [
        "Hasonlóan az eddigiekhez vektorizálom a tanító adathalmazom, logistic regression modellt illesztek rá, becslést hajtok végre majd kiértékelem az eredményeket. Először a (2,3) n-gram modellel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Etgz8IAjMUE3",
<<<<<<< HEAD
        "outputId": "701615e2-88e4-4128-a25d-e544d2ffa082"
=======
        "outputId": "c8605f33-479c-42ef-a037-3155d4e7bb98"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "gram_vectorizer_23 = CountVectorizer(ngram_range=(2,3))\r\n",
        "train_vectorizer_23 = gram_vectorizer_23.fit_transform(train_headlines)\r\n",
        "\r\n",
        "print(train_vectorizer_23.shape)\r\n",
        "\r\n",
        "gram_model_23 = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "gram_model_23 = gram_model_23.fit(train_vectorizer_23, train[\"Label\"])\r\n",
        "\r\n",
<<<<<<< HEAD
=======
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "gram_test_23 = gram_vectorizer_23.transform(test_headlines)\r\n",
        "gram_predictions_23 = gram_model_23.predict(gram_test_23)\r\n",
        "\r\n",
        "pd.crosstab(test[\"Label\"], gram_predictions_23, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "print (classification_report(test[\"Label\"], gram_predictions_23))\r\n",
        "print (accuracy_score(test[\"Label\"], gram_predictions_23))\r\n",
        "\r\n",
        "result.append(accuracy_score(test[\"Label\"], gram_predictions_23))"
      ],
<<<<<<< HEAD
      "execution_count": 44,
=======
      "execution_count": 375,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "(20286, 762863)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.23      0.32      1662\n",
            "           1       0.55      0.80      0.65      1919\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.52      0.48      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.5358838313320302\n"
=======
            "(20286, 763667)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "uVN0l54FMi1-",
<<<<<<< HEAD
        "outputId": "f59ff87e-b9c5-484e-c4ad-6312d0b1205c"
=======
        "outputId": "f4eaacac-8ac7-4560-ff21-a7862e6ed470"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "gram_words_23 = gram_vectorizer_23.get_feature_names()\r\n",
        "gram_coeffs_23 = gram_model_23.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : gram_words_23, \r\n",
        "                        'Coefficient' : gram_coeffs_23})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "coeffdf.head(10)"
      ],
<<<<<<< HEAD
      "execution_count": 45,
=======
      "execution_count": 376,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <th>749964</th>\n",
              "      <td>world cup</td>\n",
              "      <td>0.721431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261750</th>\n",
              "      <td>french president</td>\n",
              "      <td>0.648438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622045</th>\n",
              "      <td>social media</td>\n",
              "      <td>0.618966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606600</th>\n",
              "      <td>sexual violence</td>\n",
              "      <td>0.588408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596777</th>\n",
              "      <td>security council</td>\n",
              "      <td>0.572161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750600</th>\n",
              "      <td>world largest</td>\n",
              "      <td>0.571545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350540</th>\n",
              "      <td>jazeera english</td>\n",
              "      <td>0.554738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665801</th>\n",
              "      <td>tear gas</td>\n",
              "      <td>0.549425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69207</th>\n",
              "      <td>big brother</td>\n",
              "      <td>0.548341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291509</th>\n",
              "      <td>gunmen kill</td>\n",
              "      <td>0.548241</td>\n",
=======
              "      <th>597209</th>\n",
              "      <td>security council</td>\n",
              "      <td>0.724715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607058</th>\n",
              "      <td>sexual violence</td>\n",
              "      <td>0.636324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153212</th>\n",
              "      <td>court rules</td>\n",
              "      <td>0.616613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201062</th>\n",
              "      <td>eastern ukraine</td>\n",
              "      <td>0.601972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17359</th>\n",
              "      <td>air pollution</td>\n",
              "      <td>0.599077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568778</th>\n",
              "      <td>rights watch</td>\n",
              "      <td>0.585935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3769</th>\n",
              "      <td>according new</td>\n",
              "      <td>0.571407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622533</th>\n",
              "      <td>social media</td>\n",
              "      <td>0.569983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713767</th>\n",
              "      <td>us spying</td>\n",
              "      <td>0.560623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751370</th>\n",
              "      <td>world largest</td>\n",
              "      <td>0.556218</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Word  Coefficient\n",
<<<<<<< HEAD
              "749964         world cup     0.721431\n",
              "261750  french president     0.648438\n",
              "622045      social media     0.618966\n",
              "606600   sexual violence     0.588408\n",
              "596777  security council     0.572161\n",
              "750600     world largest     0.571545\n",
              "350540   jazeera english     0.554738\n",
              "665801          tear gas     0.549425\n",
              "69207        big brother     0.548341\n",
              "291509       gunmen kill     0.548241"
=======
              "597209  security council     0.724715\n",
              "607058   sexual violence     0.636324\n",
              "153212       court rules     0.616613\n",
              "201062   eastern ukraine     0.601972\n",
              "17359      air pollution     0.599077\n",
              "568778      rights watch     0.585935\n",
              "3769       according new     0.571407\n",
              "622533      social media     0.569983\n",
              "713767         us spying     0.560623\n",
              "751370     world largest     0.556218"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 45
=======
          "execution_count": 376
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "pIO9FkYuMnNb",
<<<<<<< HEAD
        "outputId": "33d15392-1812-4a9b-8304-38c7b5a6afb1"
=======
        "outputId": "502fbe0b-416f-4409-deb3-4e6522204bef"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "coeffdf.tail(10)"
      ],
<<<<<<< HEAD
      "execution_count": 46,
=======
      "execution_count": 377,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <th>606423</th>\n",
              "      <td>sexual abuse</td>\n",
              "      <td>-0.556075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119956</th>\n",
              "      <td>christopher hitchens</td>\n",
              "      <td>-0.556145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>702952</th>\n",
              "      <td>un chief</td>\n",
              "      <td>-0.568781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308331</th>\n",
              "      <td>hong kong</td>\n",
              "      <td>-0.588145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710756</th>\n",
              "      <td>us army</td>\n",
              "      <td>-0.595496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292977</th>\n",
              "      <td>haiti earthquake</td>\n",
              "      <td>-0.631009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418677</th>\n",
              "      <td>military bases</td>\n",
              "      <td>-0.633480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>640245</th>\n",
              "      <td>stock market</td>\n",
              "      <td>-0.651543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480324</th>\n",
              "      <td>panama papers</td>\n",
              "      <td>-0.670802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584262</th>\n",
              "      <td>saudi king</td>\n",
              "      <td>-0.849692</td>\n",
=======
              "      <th>548009</th>\n",
              "      <td>red cross</td>\n",
              "      <td>-0.576519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>640979</th>\n",
              "      <td>stock market</td>\n",
              "      <td>-0.582220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39938</th>\n",
              "      <td>around world</td>\n",
              "      <td>-0.592300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449734</th>\n",
              "      <td>news international</td>\n",
              "      <td>-0.611127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650490</th>\n",
              "      <td>suicide bomber</td>\n",
              "      <td>-0.660796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419034</th>\n",
              "      <td>military bases</td>\n",
              "      <td>-0.663339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729640</th>\n",
              "      <td>war iran</td>\n",
              "      <td>-0.688157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584685</th>\n",
              "      <td>saudi king</td>\n",
              "      <td>-0.693207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480834</th>\n",
              "      <td>panama papers</td>\n",
              "      <td>-0.703129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711294</th>\n",
              "      <td>us army</td>\n",
              "      <td>-0.758311</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
<<<<<<< HEAD
              "                        Word  Coefficient\n",
              "606423          sexual abuse    -0.556075\n",
              "119956  christopher hitchens    -0.556145\n",
              "702952              un chief    -0.568781\n",
              "308331             hong kong    -0.588145\n",
              "710756               us army    -0.595496\n",
              "292977      haiti earthquake    -0.631009\n",
              "418677        military bases    -0.633480\n",
              "640245          stock market    -0.651543\n",
              "480324         panama papers    -0.670802\n",
              "584262            saudi king    -0.849692"
=======
              "                      Word  Coefficient\n",
              "548009           red cross    -0.576519\n",
              "640979        stock market    -0.582220\n",
              "39938         around world    -0.592300\n",
              "449734  news international    -0.611127\n",
              "650490      suicide bomber    -0.660796\n",
              "419034      military bases    -0.663339\n",
              "729640            war iran    -0.688157\n",
              "584685          saudi king    -0.693207\n",
              "480834       panama papers    -0.703129\n",
              "711294             us army    -0.758311"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 46
=======
          "execution_count": 377
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tftajhXMMUUs"
      },
      "source": [
        "Hasonlóan az eddigiekhez vektorizálom a tanító adathalmazom, logistic regression modellt illesztek rá, becslést hajtok végre majd kiértékelem az eredményeket. Először a (3,3) n-gram modellel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T-9458xMaJq",
<<<<<<< HEAD
        "outputId": "864ecefc-a186-490d-e212-9d4cd3441f1f"
=======
        "outputId": "6fe87015-8b62-4903-a399-03d4c5774895"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "gram_vectorizer_33 = CountVectorizer(ngram_range=(3,3))\r\n",
        "train_vectorizer_33 = gram_vectorizer_33.fit_transform(train_headlines)\r\n",
        "\r\n",
        "print(train_vectorizer_33.shape)\r\n",
        "\r\n",
        "gram_model_33 = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "gram_model_33 = gram_model_33.fit(train_vectorizer_33, train[\"Label\"])\r\n",
        "\r\n",
<<<<<<< HEAD
=======
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "gram_test_33 = gram_vectorizer_33.transform(test_headlines)\r\n",
        "gram_predictions_33 = gram_model_33.predict(gram_test_33)\r\n",
        "\r\n",
        "pd.crosstab(test[\"Label\"], gram_predictions_33, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "print (classification_report(test[\"Label\"], gram_predictions_33))\r\n",
        "print (accuracy_score(test[\"Label\"], gram_predictions_33))\r\n",
        "\r\n",
        "result.append(accuracy_score(test[\"Label\"], gram_predictions_33))"
      ],
<<<<<<< HEAD
      "execution_count": 47,
=======
      "execution_count": 378,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "(20286, 413794)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.07      0.12      1662\n",
            "           1       0.54      0.95      0.69      1919\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.53      0.51      0.40      3581\n",
            "weighted avg       0.53      0.54      0.42      3581\n",
            "\n",
            "0.5389555989946943\n"
=======
            "(20286, 414359)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "Z7_f6ay_MjhC",
<<<<<<< HEAD
        "outputId": "fd9e226f-aa8e-4284-d5fa-d5a3280af6cd"
=======
        "outputId": "0701cc62-3ee0-4623-8df9-7228dd0e8096"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "gram_words_33 = gram_vectorizer_33.get_feature_names()\r\n",
        "gram_coeffs_33 = gram_model_33.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : gram_words_33, \r\n",
        "                        'Coefficient' : gram_coeffs_33})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "coeffdf.head(10)"
      ],
<<<<<<< HEAD
      "execution_count": 48,
=======
      "execution_count": 379,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <th>9936</th>\n",
              "      <td>al jazeera english</td>\n",
              "      <td>0.907694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131932</th>\n",
              "      <td>first time since</td>\n",
              "      <td>0.876802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168145</th>\n",
              "      <td>human rights watch</td>\n",
              "      <td>0.587147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380974</th>\n",
              "      <td>un security council</td>\n",
              "      <td>0.550488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279659</th>\n",
              "      <td>president hosni mubarak</td>\n",
              "      <td>0.543829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244545</th>\n",
              "      <td>nobel peace prize</td>\n",
              "      <td>0.525923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140471</th>\n",
              "      <td>french president sarkozy</td>\n",
              "      <td>0.500517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17085</th>\n",
              "      <td>anti gay bill</td>\n",
              "      <td>0.494161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144626</th>\n",
              "      <td>gaza war crimes</td>\n",
              "      <td>0.480407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104918</th>\n",
              "      <td>drug decriminalization portugal</td>\n",
              "      <td>0.470565</td>\n",
=======
              "      <th>132267</th>\n",
              "      <td>first time since</td>\n",
              "      <td>0.916949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381429</th>\n",
              "      <td>un security council</td>\n",
              "      <td>0.755421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168514</th>\n",
              "      <td>human rights watch</td>\n",
              "      <td>0.694514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10082</th>\n",
              "      <td>al jazeera english</td>\n",
              "      <td>0.683763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280085</th>\n",
              "      <td>president hosni mubarak</td>\n",
              "      <td>0.623580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381127</th>\n",
              "      <td>un general assembly</td>\n",
              "      <td>0.533258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283226</th>\n",
              "      <td>pro russian separatists</td>\n",
              "      <td>0.515341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410908</th>\n",
              "      <td>year old man</td>\n",
              "      <td>0.508897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402301</th>\n",
              "      <td>wikileaks julian assange</td>\n",
              "      <td>0.505865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140822</th>\n",
              "      <td>french president sarkozy</td>\n",
              "      <td>0.503710</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
<<<<<<< HEAD
              "                                   Word  Coefficient\n",
              "9936                 al jazeera english     0.907694\n",
              "131932                 first time since     0.876802\n",
              "168145               human rights watch     0.587147\n",
              "380974              un security council     0.550488\n",
              "279659          president hosni mubarak     0.543829\n",
              "244545                nobel peace prize     0.525923\n",
              "140471         french president sarkozy     0.500517\n",
              "17085                     anti gay bill     0.494161\n",
              "144626                  gaza war crimes     0.480407\n",
              "104918  drug decriminalization portugal     0.470565"
=======
              "                            Word  Coefficient\n",
              "132267          first time since     0.916949\n",
              "381429       un security council     0.755421\n",
              "168514        human rights watch     0.694514\n",
              "10082         al jazeera english     0.683763\n",
              "280085   president hosni mubarak     0.623580\n",
              "381127       un general assembly     0.533258\n",
              "283226   pro russian separatists     0.515341\n",
              "410908              year old man     0.508897\n",
              "402301  wikileaks julian assange     0.505865\n",
              "140822  french president sarkozy     0.503710"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 48
=======
          "execution_count": 379
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "KNFCAZ2pMpCY",
<<<<<<< HEAD
        "outputId": "6ef7214b-24d5-407e-84f5-cd32f7d076c8"
=======
        "outputId": "34231d96-9660-4f68-b938-6d92c5100c85"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "coeffdf.tail(10)"
      ],
<<<<<<< HEAD
      "execution_count": 49,
=======
      "execution_count": 380,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <th>325883</th>\n",
              "      <td>sentenced death stoning</td>\n",
              "      <td>-0.499194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252868</th>\n",
              "      <td>one child policy</td>\n",
              "      <td>-0.509422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183448</th>\n",
              "      <td>islamic state iraq</td>\n",
              "      <td>-0.513419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123345</th>\n",
              "      <td>faces years jail</td>\n",
              "      <td>-0.516090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339623</th>\n",
              "      <td>sovereign wealth fund</td>\n",
              "      <td>-0.526752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400074</th>\n",
              "      <td>west bank settlement</td>\n",
              "      <td>-0.529796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9228</th>\n",
              "      <td>air strikes syria</td>\n",
              "      <td>-0.587244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58451</th>\n",
              "      <td>chancellor angela merkel</td>\n",
              "      <td>-0.594006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26442</th>\n",
              "      <td>aung san suu</td>\n",
              "      <td>-0.607714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229191</th>\n",
              "      <td>missile defense system</td>\n",
              "      <td>-0.759526</td>\n",
=======
              "      <th>148251</th>\n",
              "      <td>girl gang raped</td>\n",
              "      <td>-0.515230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26624</th>\n",
              "      <td>aung san suu</td>\n",
              "      <td>-0.526697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178458</th>\n",
              "      <td>international space station</td>\n",
              "      <td>-0.526701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326323</th>\n",
              "      <td>sentenced years prison</td>\n",
              "      <td>-0.549481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165697</th>\n",
              "      <td>homes east jerusalem</td>\n",
              "      <td>-0.554131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109678</th>\n",
              "      <td>egypt muslim brotherhood</td>\n",
              "      <td>-0.560240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357226</th>\n",
              "      <td>syrian security forces</td>\n",
              "      <td>-0.603754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229484</th>\n",
              "      <td>missile defense system</td>\n",
              "      <td>-0.661560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58597</th>\n",
              "      <td>chancellor angela merkel</td>\n",
              "      <td>-0.701318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123670</th>\n",
              "      <td>faces years jail</td>\n",
              "      <td>-0.717956</td>\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
<<<<<<< HEAD
              "                            Word  Coefficient\n",
              "325883   sentenced death stoning    -0.499194\n",
              "252868          one child policy    -0.509422\n",
              "183448        islamic state iraq    -0.513419\n",
              "123345          faces years jail    -0.516090\n",
              "339623     sovereign wealth fund    -0.526752\n",
              "400074      west bank settlement    -0.529796\n",
              "9228           air strikes syria    -0.587244\n",
              "58451   chancellor angela merkel    -0.594006\n",
              "26442               aung san suu    -0.607714\n",
              "229191    missile defense system    -0.759526"
=======
              "                               Word  Coefficient\n",
              "148251              girl gang raped    -0.515230\n",
              "26624                  aung san suu    -0.526697\n",
              "178458  international space station    -0.526701\n",
              "326323       sentenced years prison    -0.549481\n",
              "165697         homes east jerusalem    -0.554131\n",
              "109678     egypt muslim brotherhood    -0.560240\n",
              "357226       syrian security forces    -0.603754\n",
              "229484       missile defense system    -0.661560\n",
              "58597      chancellor angela merkel    -0.701318\n",
              "123670             faces years jail    -0.717956"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 49
=======
          "execution_count": 380
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKpZIe-RTmk_"
      },
      "source": [
        "### 4-gram modell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y75LfFJBTtrz"
      },
      "source": [
        "Ebben a fejezetben már egy ciklusban vizsgálom meg a bizonyos modelleket és mentem le az eredményeiket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PabhGwFWUZrZ",
<<<<<<< HEAD
        "outputId": "985ce0d4-d483-49d2-d87e-24ac896be529"
=======
        "outputId": "d5b64c23-8a92-4948-894e-5266932868f3"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "for n in range(1,5):\r\n",
        "    print(\"--------------------------------------------\\n\\nStart of the \" \r\n",
        "          + str(n) + \",4 gram model\\n\")\r\n",
        "\r\n",
        "    _gram_vectorizer_ = CountVectorizer(ngram_range=(n,4))\r\n",
        "    _train_vectorizer_ = _gram_vectorizer_.fit_transform(train_headlines)\r\n",
        "\r\n",
        "    print(\"The shape is: \" + str(_train_vectorizer_.shape) + \"\\n\")\r\n",
        "\r\n",
        "    _gram_model_ = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "    _gram_model_ = _gram_model_.fit(_train_vectorizer_, train[\"Label\"])\r\n",
        "\r\n",
<<<<<<< HEAD
        "    _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "    _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
=======
        "    test_headlines = []\r\n",
        "\r\n",
        "    for row in range(0,len(test.index)):\r\n",
        "        test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "    _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "    _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
        "    pd.crosstab(test[\"Label\"], _gram_predictions_, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "    print (classification_report(test[\"Label\"], _gram_predictions_))\r\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "    print (accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "    model_type.append(str(n) + \",4 n-gram\")\r\n",
        "    result.append(accuracy_score(test[\"Label\"], _gram_predictions_))"
      ],
<<<<<<< HEAD
      "execution_count": 50,
=======
      "execution_count": 381,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 1205402)\n",
            "\n",
            "0.5316950572465792\n",
=======
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 1166805)\n",
            "\n",
            "0.5375593409662106\n",
=======
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 817736)\n",
            "\n",
            "0.541189611840268\n",
=======
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 403942)\n",
            "\n",
            "0.5356045797263335\n"
=======
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omkP2pSAV6Qm"
      },
      "source": [
        "### 5-gram modell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Y4HliaV-rg"
      },
      "source": [
        "Ebben a fejezetben már egy ciklusban vizsgálom meg a bizonyos modelleket és mentem le az eredményeiket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8hdr8A-WBRq",
<<<<<<< HEAD
        "outputId": "d19ad6f5-567c-453f-e15c-d896fb6df4e4"
=======
        "outputId": "de60392b-eb33-45ef-d99c-1e28098b7b91"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "MODEL_TYPE = 5\r\n",
        "\r\n",
        "for n in range(1,MODEL_TYPE+1):\r\n",
        "    print(\"--------------------------------------------\\n\\nStart of the \" \r\n",
        "          + str(n) + \",\" + str(MODEL_TYPE) + \" gram model\\n\")\r\n",
        "\r\n",
        "    _gram_vectorizer_ = CountVectorizer(ngram_range=(n,MODEL_TYPE))\r\n",
        "    _train_vectorizer_ = _gram_vectorizer_.fit_transform(train_headlines)\r\n",
        "\r\n",
        "    print(\"The shape is: \" + str(_train_vectorizer_.shape) + \"\\n\")\r\n",
        "\r\n",
        "    _gram_model_ = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "    _gram_model_ = _gram_model_.fit(_train_vectorizer_, train[\"Label\"])\r\n",
        "\r\n",
<<<<<<< HEAD
        "    _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "    _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
=======
        "    test_headlines = []\r\n",
        "\r\n",
        "    for row in range(0,len(test.index)):\r\n",
        "        test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "    _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "    _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
        "    pd.crosstab(test[\"Label\"], _gram_predictions_, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "    print (classification_report(test[\"Label\"], _gram_predictions_))\r\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "    print (accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "    model_type.append(str(n) + \",\" + str(MODEL_TYPE) + \" n-gram\")\r\n",
        "    result.append(accuracy_score(test[\"Label\"], _gram_predictions_))"
      ],
<<<<<<< HEAD
      "execution_count": 51,
=======
      "execution_count": 382,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 1590717)\n",
            "\n",
            "0.5314158056408824\n",
=======
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 1552120)\n",
            "\n",
            "0.5361630829377269\n",
=======
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 1203051)\n",
            "\n",
            "0.5370008377548171\n",
=======
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 789257)\n",
            "\n",
            "0.5356045797263335\n",
=======
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 385315)\n",
            "\n",
            "0.5367215861491204\n"
=======
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgRyRExGWvFN"
      },
      "source": [
        "### 6-gram modell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv2plcaDWy8V"
      },
      "source": [
        "Ebben a fejezetben már egy ciklusban vizsgálom meg a bizonyos modelleket és mentem le az eredményeiket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-9kyXKFW1KI",
<<<<<<< HEAD
        "outputId": "ba5799fe-6016-498d-a37c-cd0eb5933612"
=======
        "outputId": "716d0c9f-7ad0-42af-e64c-b318593a3ccd"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "MODEL_TYPE = 6\r\n",
        "\r\n",
        "for n in range(1,MODEL_TYPE+1):\r\n",
        "    print(\"--------------------------------------------\\n\\nStart of the \" \r\n",
        "          + str(n) + \",\" + str(MODEL_TYPE) + \" gram model\\n\")\r\n",
        "\r\n",
        "    _gram_vectorizer_ = CountVectorizer(ngram_range=(n,MODEL_TYPE))\r\n",
        "    _train_vectorizer_ = _gram_vectorizer_.fit_transform(train_headlines)\r\n",
        "\r\n",
        "    print(\"The shape is: \" + str(_train_vectorizer_.shape) + \"\\n\")\r\n",
        "\r\n",
        "    _gram_model_ = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "    _gram_model_ = _gram_model_.fit(_train_vectorizer_, train[\"Label\"])\r\n",
        "\r\n",
<<<<<<< HEAD
        "    _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "    _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
=======
        "    test_headlines = []\r\n",
        "\r\n",
        "    for row in range(0,len(test.index)):\r\n",
        "        test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "    _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "    _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
        "    pd.crosstab(test[\"Label\"], _gram_predictions_, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "    print (classification_report(test[\"Label\"], _gram_predictions_))\r\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "    print (accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "    model_type.append(str(n) + \",\" + str(MODEL_TYPE) + \" n-gram\")\r\n",
        "    result.append(accuracy_score(test[\"Label\"], _gram_predictions_))"
      ],
<<<<<<< HEAD
      "execution_count": 52,
=======
      "execution_count": 383,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 1956147)\n",
            "\n",
            "0.5305780508237923\n",
=======
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 1917550)\n",
            "\n",
            "0.5370008377548171\n",
=======
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 1568481)\n",
            "\n",
            "0.5364423345434236\n",
=======
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 1154687)\n",
            "\n",
            "0.5372800893605139\n",
=======
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 750745)\n",
            "\n",
            "0.5364423345434236\n",
=======
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (20286, 365430)\n",
            "\n",
            "0.5370008377548171\n"
=======
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh7BcurhRaGe"
      },
      "source": [
        "### Eredmények összegzése"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr2NAOefRc1j"
      },
      "source": [
        "Az eredmények kiíratása, a legjobbat kiemelve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykPdalGBRgeL",
<<<<<<< HEAD
        "outputId": "9e1c38d5-0076-47fd-b371-3c223be0b2b6"
=======
        "outputId": "b81e540b-eeaf-4f52-af0d-4ff30d9d5256"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "best_model = 0\r\n",
        "\r\n",
        "for model in range(len(model_type)):\r\n",
        "    print(str(model_type[model]) + \":\\t\\t\\t\\t\\t\" + str(result[model]))\r\n",
        "\r\n",
        "    if result[model] > best_model:\r\n",
        "        best_model = result[model]\r\n",
        "        best_model_index = model\r\n",
        "\r\n",
        "print(\"--------------------------------------------\\nBest model:\\n\" \r\n",
        "      + str(model_type[best_model_index]) + \"\\t\\t\\t\\t\\t\" + \r\n",
        "      str(result[best_model_index]))\r\n"
      ],
<<<<<<< HEAD
      "execution_count": 53,
=======
      "execution_count": 384,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "Bag of words:\t\t\t\t\t0.5046076514939961\n",
            "1,2 n-gram:\t\t\t\t\t0.5230382574699804\n",
            "2,2 n-gram:\t\t\t\t\t0.5356045797263335\n",
            "1,3 n-gram:\t\t\t\t\t0.5330913152750628\n",
            "2,3 n-gram:\t\t\t\t\t0.5358838313320302\n",
            "3,3 n-gram:\t\t\t\t\t0.5389555989946943\n",
            "1,4 n-gram:\t\t\t\t\t0.5316950572465792\n",
            "2,4 n-gram:\t\t\t\t\t0.5375593409662106\n",
            "3,4 n-gram:\t\t\t\t\t0.541189611840268\n",
            "4,4 n-gram:\t\t\t\t\t0.5356045797263335\n",
            "1,5 n-gram:\t\t\t\t\t0.5314158056408824\n",
            "2,5 n-gram:\t\t\t\t\t0.5361630829377269\n",
            "3,5 n-gram:\t\t\t\t\t0.5370008377548171\n",
            "4,5 n-gram:\t\t\t\t\t0.5356045797263335\n",
            "5,5 n-gram:\t\t\t\t\t0.5367215861491204\n",
            "1,6 n-gram:\t\t\t\t\t0.5305780508237923\n",
            "2,6 n-gram:\t\t\t\t\t0.5370008377548171\n",
            "3,6 n-gram:\t\t\t\t\t0.5364423345434236\n",
            "4,6 n-gram:\t\t\t\t\t0.5372800893605139\n",
            "5,6 n-gram:\t\t\t\t\t0.5364423345434236\n",
            "6,6 n-gram:\t\t\t\t\t0.5370008377548171\n",
            "--------------------------------------------\n",
            "Best model:\n",
            "3,4 n-gram\t\t\t\t\t0.541189611840268\n"
=======
            "Bag of words:\t\t\t\t\t0.5110304384250209\n",
            "1,2 n-gram:\t\t\t\t\t0.5110304384250209\n",
            "2,2 n-gram:\t\t\t\t\t0.5283440379782184\n",
            "1,3 n-gram:\t\t\t\t\t0.5227590058642837\n",
            "2,3 n-gram:\t\t\t\t\t0.5403518570231779\n",
            "3,3 n-gram:\t\t\t\t\t0.5495671600111701\n",
            "1,4 n-gram:\t\t\t\t\t0.5196872382016197\n",
            "2,4 n-gram:\t\t\t\t\t0.542306618263055\n",
            "3,4 n-gram:\t\t\t\t\t0.5520804244624407\n",
            "4,4 n-gram:\t\t\t\t\t0.5498464116168668\n",
            "1,5 n-gram:\t\t\t\t\t0.5210834962301033\n",
            "2,5 n-gram:\t\t\t\t\t0.5420273666573583\n",
            "3,5 n-gram:\t\t\t\t\t0.5490086567997766\n",
            "4,5 n-gram:\t\t\t\t\t0.5504049148282603\n",
            "5,5 n-gram:\t\t\t\t\t0.5495671600111701\n",
            "1,6 n-gram:\t\t\t\t\t0.5205249930187098\n",
            "2,6 n-gram:\t\t\t\t\t0.542306618263055\n",
            "3,6 n-gram:\t\t\t\t\t0.5481709019826864\n",
            "4,6 n-gram:\t\t\t\t\t0.550684166433957\n",
            "5,6 n-gram:\t\t\t\t\t0.5495671600111701\n",
            "6,6 n-gram:\t\t\t\t\t0.5490086567997766\n",
            "--------------------------------------------\n",
            "Best model:\n",
            "3,4 n-gram\t\t\t\t\t0.5520804244624407\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnuJNnfVYu04"
      },
      "source": [
        "### ROWS makró optimalizálás"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG3gtt_TY80k"
      },
      "source": [
        "Ebben a fejezetben a különböző ROWS értékekre (mennyi napi hírt fűzünk egybe) futtatom végig egy automatizált bag of words -> 6,6 gram modell tanítást és becslést és állapítom meg, hogy melyik a legpontosabb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUJCC_EiZo63"
      },
      "source": [
        "A tesztelendő paraméterek megadása."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KUt-wbZZO1i",
<<<<<<< HEAD
        "outputId": "a41d37d0-6545-46d8-8ab7-7af5f7896560"
=======
        "outputId": "37bd36bb-cf7e-4712-b873-28bb272311e6"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "# Number of merged news into one string: 1...12, 25 \r\n",
        "rows_values = []\r\n",
        "for value in range(1,13):\r\n",
        "    rows_values.append(value)\r\n",
        "\r\n",
        "rows_values.append(25)\r\n",
        "\r\n",
        "rows_values"
      ],
<<<<<<< HEAD
      "execution_count": 66,
=======
      "execution_count": 387,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 25]"
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 66
=======
          "execution_count": 387
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHIHq8mVcNvZ"
      },
      "source": [
        "A modell típusok összegyűjtése az automatizált tanításhoz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U4xwuVXcRsp",
<<<<<<< HEAD
        "outputId": "0b22ab1b-9d5e-4487-e917-cf095886e8d5"
=======
        "outputId": "6afd6281-b04a-4b38-ce1c-674ec5db5dd1"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      },
      "source": [
        "model_type_values = []\r\n",
        "for value in range(1,7):\r\n",
        "    model_type_values.append(value)\r\n",
        "\r\n",
        "model_type_values"
      ],
<<<<<<< HEAD
      "execution_count": 67,
=======
      "execution_count": 389,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 67
=======
          "execution_count": 389
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu9UswHzer9O"
      },
      "source": [
        "A paraméterhez tartozó eredmények tárolására létrehozom az alábbi tömböket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRcPzJ-1exEu"
      },
      "source": [
        "rows_summary_value = []\r\n",
        "rows_summary_accuraccy = []"
      ],
<<<<<<< HEAD
      "execution_count": 68,
=======
      "execution_count": 1,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0_5e2otZsMM"
      },
      "source": [
        "Automatizált tanítás és mentések."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "ypJXKkcqGPBZ"
      },
      "source": [
        "def preprocess():\r\n",
        "    df_combined = pd.read_csv('drive/MyDrive/Kaggle dataset/Reddit Top 25 DJIA/KAG_REDDIT_WRLD_DJIA_DF_corrected.csv', \r\n",
        "                            index_col = \"Date\")\r\n",
        "\r\n",
        "    # Find the cells with NaN and after the rows for them\r\n",
        "    is_NaN = df_combined.isnull()\r\n",
        "    row_has_NaN = is_NaN.any(axis = 1)\r\n",
        "    rows_with_NaN = df_combined[row_has_NaN]\r\n",
        "\r\n",
        "    # Replace them\r\n",
        "    df_combined = df_combined.replace(np.nan, \" \")\r\n",
        "\r\n",
        "    # Check the process\r\n",
        "    is_NaN = df_combined.isnull()\r\n",
        "    row_has_NaN = is_NaN.any(axis = 1)\r\n",
        "    rows_with_NaN = df_combined[row_has_NaN]\r\n",
        "\r\n",
        "    assert len(rows_with_NaN) is 0\r\n",
        "\r\n",
        "    # Get column names\r\n",
        "    combined_column_names = []\r\n",
        "    for column in df_combined.columns:\r\n",
        "      combined_column_names.append(column)\r\n",
        "\r\n",
        "    # 2D array creation for the news based on macros\r\n",
        "    COLUMNS = len(df_combined)\r\n",
        "    news_sum = []\r\n",
        "    news_sum = [[0 for i in range(COLUMNS)] for j in range(int((len(combined_column_names) - 1) / ROWS))]  \r\n",
        "\r\n",
        "    # Merge the news\r\n",
        "    for row in range(len(df_combined)):\r\n",
        "      for column in range(int((len(combined_column_names) - 1) / ROWS)):\r\n",
        "        temp = \"\"\r\n",
        "        news = \"\"\r\n",
        "        for word in range(ROWS):\r\n",
        "          news = df_combined[combined_column_names[(column * ROWS) + (word + 1)]][row]\r\n",
        "          # Remove the b character at the begining of the string\r\n",
        "          if news[0] is \"b\":\r\n",
        "            news = \" \" + news[1:]\r\n",
        "          temp = temp + news\r\n",
        "        news_sum[column][row] = temp\r\n",
        "\r\n",
        "    # Drop the old columns\r\n",
        "    for column in range(len(combined_column_names) - 1):\r\n",
        "      df_combined.drop(combined_column_names[column + 1], axis = 1, inplace = True)\r\n",
        "\r\n",
        "    # Create the new columns with the merged news\r\n",
        "    for column in range(int((len(combined_column_names) - 1) / ROWS)):\r\n",
        "      colum_name = \"News_\" + str(column + 1)\r\n",
        "      df_combined[colum_name] = news_sum[column]          \r\n",
        "\r\n",
        "    # The label column \r\n",
        "    LABEL_COLUMN = 0\r\n",
        "\r\n",
        "    news_sum = []\r\n",
        "    label_sum = []\r\n",
        "\r\n",
        "    # Get the column names\r\n",
        "    combined_column_names = []\r\n",
        "    for column in df_combined.columns:\r\n",
        "      combined_column_names.append(column)\r\n",
        "\r\n",
        "    # Connect the merged news with the labels\r\n",
        "    for column in range(len(df_combined)):\r\n",
        "      for row in range(len(combined_column_names) - 1):\r\n",
        "        news_sum.append(df_combined[combined_column_names[row + 1]][column])\r\n",
        "        label_sum.append(df_combined[combined_column_names[LABEL_COLUMN]][column])\r\n",
        "\r\n",
        "    # Create the new DataFrame\r\n",
        "    df_sum_news_labels = pd.DataFrame(data = label_sum, index = None, columns = [\"Label\"])\r\n",
        "    df_sum_news_labels[\"News\"] = news_sum\r\n",
        "\r\n",
        "    # Removing punctuations\r\n",
        "    temp_news = []\r\n",
        "    for line in news_sum:\r\n",
        "      temp_attach = \"\"\r\n",
        "      for word in line:\r\n",
        "        temp = \" \"\r\n",
        "        if word not in string.punctuation:\r\n",
        "          temp = word\r\n",
        "        temp_attach = temp_attach + \"\".join(temp)\r\n",
        "      temp_news.append(temp_attach)\r\n",
        "\r\n",
        "    news_sum = temp_news\r\n",
        "    temp_news = []\r\n",
        "\r\n",
        "    # Remove numbers\r\n",
        "    for line in news_sum:\r\n",
        "      temp_attach = \"\"\r\n",
        "      for word in line:\r\n",
        "        temp = \" \"\r\n",
        "        if not word.isdigit():\r\n",
        "          temp = word\r\n",
        "        temp_attach = temp_attach + \"\".join(temp)\r\n",
        "      temp_news.append(temp_attach)\r\n",
        "\r\n",
        "    # Remove space\r\n",
        "    for line in range(len(temp_news)):    \r\n",
        "      temp_news[line] = \" \".join(temp_news[line].split())\r\n",
        "\r\n",
        "    # Converting headlines to lower case\r\n",
        "    for line in range(len(temp_news)): \r\n",
        "        temp_news[line] = temp_news[line].lower()\r\n",
        "\r\n",
        "    # Update the data frame\r\n",
        "    df_sum_news_labels[\"News\"] = temp_news\r\n",
        "\r\n",
        "    # Load the stop words\r\n",
        "    stop_words = set(stopwords.words('english'))\r\n",
        "\r\n",
        "    filtered_sentence = []\r\n",
        "    news_sum = df_sum_news_labels[\"News\"]\r\n",
        "\r\n",
        "    # Remove stop words\r\n",
        "    for line in news_sum:\r\n",
        "      word_tokens = word_tokenize(line)\r\n",
        "      temp_attach = \"\"\r\n",
        "      for word in word_tokens:\r\n",
        "        temp = \" \"\r\n",
        "        if not word in stop_words:\r\n",
        "          temp = temp + word\r\n",
        "        temp_attach = temp_attach + \"\".join(temp)\r\n",
        "      filtered_sentence.append(temp_attach)\r\n",
        "\r\n",
        "    # Remove space\r\n",
        "    for line in range(len(filtered_sentence)):    \r\n",
        "      filtered_sentence[line] = \" \".join(filtered_sentence[line].split())\r\n",
        "\r\n",
        "    # Update the data frame\r\n",
        "    df_sum_news_labels[\"News\"] = filtered_sentence\r\n",
        "\r\n",
        "    news_sum = df_sum_news_labels[\"News\"]\r\n",
        "    null_indexes = []\r\n",
        "    index = 0\r\n",
        "\r\n",
        "    for line in news_sum:\r\n",
        "      if line is \"\":\r\n",
        "        null_indexes.append(index)\r\n",
        "      index = index + 1\r\n",
        "\r\n",
        "    for row in null_indexes:\r\n",
        "      df_sum_news_labels = df_sum_news_labels.drop(row)\r\n",
        "\r\n",
        "    news_sum = df_sum_news_labels[\"News\"]\r\n",
        "    null_indexes = []\r\n",
        "    index = 0\r\n",
        "\r\n",
        "    for line in news_sum:\r\n",
        "      if line is \"\":\r\n",
        "        null_indexes.append(index)\r\n",
        "      index = index + 1\r\n",
        "      \r\n",
        "    assert len(null_indexes) is 0\r\n",
        "\r\n",
        "    # Do the shuffle\r\n",
        "    for i in range(SHUFFLE_CYCLE):\r\n",
        "      df_sum_news_labels = shuffle(df_sum_news_labels, random_state = RANDOM_SEED)\r\n",
        "\r\n",
        "    # Reset the index\r\n",
        "    df_sum_news_labels.reset_index(inplace=True, drop=True)\r\n",
        "\r\n",
        "    return df_sum_news_labels"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9zgMLtiLx6e"
      },
      "source": [
        "def split_to_train():\r\n",
        "    INPUT_SIZE = len(df_sum_news_labels)\r\n",
        "    TRAIN_SIZE = int(TRAIN_SPLIT * INPUT_SIZE) \r\n",
        "\r\n",
        "    # Split the dataset\r\n",
        "    train = df_sum_news_labels[:TRAIN_SIZE] \r\n",
        "\r\n",
        "    return train"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC1lgt7dMBol"
      },
      "source": [
        "def split_to_test():\r\n",
        "    INPUT_SIZE = len(df_sum_news_labels)\r\n",
        "    TRAIN_SIZE = int(TRAIN_SPLIT * INPUT_SIZE) \r\n",
        "\r\n",
        "    # Split the dataset\r\n",
        "    test = df_sum_news_labels[TRAIN_SIZE:]\r\n",
        "\r\n",
        "    return test"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
=======
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq0Oo4iHZufG",
<<<<<<< HEAD
        "outputId": "e8d1a00f-e7f2-466d-e6f4-d57bd2807bbc"
      },
      "source": [
        "for ROWS in rows_values:\r\n",
        "  \r\n",
=======
        "outputId": "a2656491-65f4-4b49-f1df-a5a15ca5a201"
      },
      "source": [
        "for ROWS in rows_values:\r\n",
        "\r\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "    print(\"--------------------------------------------\\n\\nStart of the ROWS = \" \r\n",
        "      + str(ROWS) + \" sequence\\n\\n--------------------------------------------\\n\")\r\n",
        "    \r\n",
        "    model_type = []\r\n",
        "    result = []\r\n",
        "\r\n",
<<<<<<< HEAD
        "    df_sum_news_labels = preprocess()\r\n",
        "    train = split_to_train()\r\n",
        "    test = split_to_test()\r\n",
        "\r\n",
        "    # check\r\n",
        "    split_sum = len(train) + len(test)\r\n",
        "    sum = len(df_sum_news_labels)\r\n",
        "    assert split_sum == sum    \r\n",
        "\r\n",
        "    train_headlines = []\r\n",
        "    test_headlines = []\r\n",
        "\r\n",
        "    for row in range(0, len(train.index)):\r\n",
        "        train_headlines.append(train.iloc[row, 1])\r\n",
        "\r\n",
        "    for row in range(0,len(test.index)):\r\n",
        "        test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "    # show the first\r\n",
        "    print(train_headlines[0])\r\n",
        "\r\n",
=======
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "    for MODEL_TYPE in model_type_values:\r\n",
        "\r\n",
        "        for n in range(1,MODEL_TYPE+1):\r\n",
        "            print(\"--------------------------------------------\\n\\nStart of the \" \r\n",
        "                  + str(n) + \",\" + str(MODEL_TYPE) + \" gram model\\n\")\r\n",
        "\r\n",
        "            _gram_vectorizer_ = CountVectorizer(ngram_range=(n,MODEL_TYPE))\r\n",
        "            _train_vectorizer_ = _gram_vectorizer_.fit_transform(train_headlines)\r\n",
        "\r\n",
        "            print(\"The shape is: \" + str(_train_vectorizer_.shape) + \"\\n\")\r\n",
        "\r\n",
        "            _gram_model_ = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "            _gram_model_ = _gram_model_.fit(_train_vectorizer_, train[\"Label\"])\r\n",
        "\r\n",
<<<<<<< HEAD
        "            _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "            _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
=======
        "            test_headlines = []\r\n",
        "\r\n",
        "            for row in range(0,len(test.index)):\r\n",
        "                test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "            _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "            _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
        "            pd.crosstab(test[\"Label\"], _gram_predictions_, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "            print (classification_report(test[\"Label\"], _gram_predictions_))\r\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
        "            print (accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "            model_type.append(str(n) + \",\" + str(MODEL_TYPE) + \" n-gram\")\r\n",
        "            result.append(accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "    rows_summary_value.append(ROWS)\r\n",
        "\r\n",
        "    # save the best\r\n",
<<<<<<< HEAD
        "    best_model_rows = 0\r\n",
        "\r\n",
        "    for model in range(len(model_type)):\r\n",
        "        if result[model] > best_model_rows:\r\n",
        "            best_model_rows = result[model]\r\n",
        "\r\n",
        "    rows_summary_accuraccy.append(best_model_rows)"
      ],
      "execution_count": 72,
=======
        "    best_model = 0\r\n",
        "\r\n",
        "    for model in range(len(model_type)):\r\n",
        "        if result[model] > best_model:\r\n",
        "            best_model = result[model]\r\n",
        "            best_model_index = model\r\n",
        "\r\n",
        "    rows_summary_accuraccy.append(best_model)"
      ],
      "execution_count": 395,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 1 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
<<<<<<< HEAD
            "talk like stupid sharia law uk\n",
=======
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (42259, 30936)\n",
            "\n",
            "0.5178331992491284\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (42259, 371855)\n",
            "\n",
            "0.5197103781174578\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (42259, 340919)\n",
            "\n",
            "0.5262805041566103\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (42259, 765293)\n",
            "\n",
            "0.5225261464199518\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (42259, 734357)\n",
            "\n",
            "0.532046124966479\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (42259, 393438)\n",
            "\n",
            "0.5442477876106194\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (42259, 1128854)\n",
            "\n",
            "0.5217216411906678\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (42259, 1097918)\n",
            "\n",
            "0.5311075355323143\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (42259, 756999)\n",
            "\n",
            "0.5380799141861089\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (42259, 363561)\n",
            "\n",
            "0.5396889246446769\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (42259, 1452711)\n",
            "\n",
            "0.5210512201662644\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (42259, 1421775)\n",
            "\n",
            "0.532448377581121\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (42259, 1080856)\n",
            "\n",
            "0.5386162510056315\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (42259, 687418)\n",
            "\n",
            "0.5403593456690802\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (42259, 323857)\n",
            "\n",
            "0.5404934298739609\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (42259, 1736824)\n",
            "\n",
            "0.5223920622150711\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (42259, 1705888)\n",
            "\n",
            "0.532046124966479\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (42259, 1364969)\n",
            "\n",
            "0.5386162510056315\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (42259, 971531)\n",
            "\n",
            "0.5407615982837222\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (42259, 607970)\n",
            "\n",
            "0.5407615982837222\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (42259, 284113)\n",
            "\n",
            "0.5406275140788415\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 2 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "uk form promoted sir ian blair demands public venues define ethnicity audience russia face massive social unrest russian industrial towns might face social unrest violence companies plan massive layoffs russian sociologist says\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38597)\n",
            "\n",
            "0.5046076514939961\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387666)\n",
            "\n",
            "0.5230382574699804\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349069)\n",
            "\n",
            "0.5356045797263335\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 801460)\n",
            "\n",
            "0.5330913152750628\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 762863)\n",
            "\n",
            "0.5358838313320302\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 413794)\n",
            "\n",
            "0.5389555989946943\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1205402)\n",
            "\n",
            "0.5316950572465792\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1166805)\n",
            "\n",
            "0.5375593409662106\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 817736)\n",
            "\n",
            "0.541189611840268\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 403942)\n",
            "\n",
            "0.5356045797263335\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1590717)\n",
            "\n",
            "0.5314158056408824\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1552120)\n",
            "\n",
            "0.5361630829377269\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1203051)\n",
            "\n",
            "0.5370008377548171\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 789257)\n",
            "\n",
            "0.5356045797263335\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385315)\n",
            "\n",
            "0.5367215861491204\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1956147)\n",
            "\n",
            "0.5305780508237923\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1917550)\n",
            "\n",
            "0.5370008377548171\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1568481)\n",
            "\n",
            "0.5364423345434236\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1154687)\n",
            "\n",
            "0.5372800893605139\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 750745)\n",
            "\n",
            "0.5364423345434236\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365430)\n",
            "\n",
            "0.5370008377548171\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 3 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "russia says france must fulfil mistral contract return money agencysecret flight linking israel uae reveals open secret collaboration private jet covertly flying tel aviv abu dhabi said engaging high level trade security sectorukraine temporarily cuts power supplies crimea\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (13525, 41354)\n",
            "\n",
            "0.5190615835777126\n",
=======
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 2 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (13525, 396258)\n",
            "\n",
            "0.5198994553833264\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (13525, 354904)\n",
            "\n",
            "0.5362379555927943\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (13525, 821029)\n",
            "\n",
            "0.5228320067029745\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (13525, 779675)\n",
            "\n",
            "0.5458734813573524\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (13525, 424771)\n",
            "\n",
            "0.5525764558022622\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (13525, 1242349)\n",
            "\n",
            "0.5266024298282362\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (13525, 1200995)\n",
            "\n",
            "0.5462924172601592\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (13525, 846091)\n",
            "\n",
            "0.5517385839966485\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (13525, 421320)\n",
            "\n",
            "0.5475492249685798\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (13525, 1651726)\n",
            "\n",
            "0.5266024298282362\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (13525, 1610372)\n",
            "\n",
            "0.5454545454545454\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (13525, 1255468)\n",
            "\n",
            "0.5496439044826141\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (13525, 830697)\n",
            "\n",
            "0.5475492249685798\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (13525, 409377)\n",
            "\n",
            "0.547130289065773\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (13525, 2047962)\n",
            "\n",
            "0.5261834939254294\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (13525, 2006608)\n",
            "\n",
            "0.5492249685798073\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (13525, 1651704)\n",
            "\n",
            "0.5479681608713867\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (13525, 1226933)\n",
            "\n",
            "0.547130289065773\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (13525, 805613)\n",
            "\n",
            "0.547130289065773\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (13525, 396236)\n",
            "\n",
            "0.546711353162966\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 4 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "former archbishop canterbury christians britain us claim persecuted grow exaggerate amounts feeling mildly uncomfortable europes marijuana capital isnt amsterdam outlaw albanian village built fortune cultivation cannabis worth much half countrys gdp limits police edward snowden says media misled situation earthquake hits wellington new zealand\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (10143, 42515)\n",
            "\n",
            "0.5125628140703518\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (10143, 401132)\n",
            "\n",
            "0.5164712451144612\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (10143, 358617)\n",
            "\n",
            "0.5270798436627583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (10143, 832448)\n",
            "\n",
            "0.5203796761585706\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (10143, 789933)\n",
            "\n",
            "0.5304299274148521\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (10143, 431316)\n",
            "\n",
            "0.5371300949190396\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (10143, 1263483)\n",
            "\n",
            "0.5248464544946957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (10143, 1220968)\n",
            "\n",
            "0.5309882747068677\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (10143, 862351)\n",
            "\n",
            "0.5388051367950866\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (10143, 431035)\n",
            "\n",
            "0.5348967057509771\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (10143, 1685935)\n",
            "\n",
            "0.52428810720268\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (10143, 1643420)\n",
            "\n",
            "0.5404801786711334\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (10143, 1284803)\n",
            "\n",
            "0.5360134003350083\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (10143, 853487)\n",
            "\n",
            "0.5337800111669458\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (10143, 422452)\n",
            "\n",
            "0.5343383584589615\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (10143, 2098611)\n",
            "\n",
            "0.5226130653266332\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (10143, 2056096)\n",
            "\n",
            "0.5371300949190396\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (10143, 1697479)\n",
            "\n",
            "0.5354550530429928\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (10143, 1266163)\n",
            "\n",
            "0.5343383584589615\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (10143, 835128)\n",
            "\n",
            "0.5343383584589615\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (10143, 412676)\n",
            "\n",
            "0.5343383584589615\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 5 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "saudi prince threatens military action without american support iranoutdoor cinema homeless people opens moscow throughout summer russian capital invisible population able watch soviet comedies enjoy hot meals air strike kills al qaeda leader syria pentagongreenland glaciers flowing ocean grounded deeper sea level previously measured allowing intruding ocean water badly undercut glacier faces process raise sea levels around world much faster currently estimatedscientists find first drug appears slow alzheimer disease\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (8453, 44483)\n",
            "\n",
            "0.5140750670241286\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (8453, 417177)\n",
            "\n",
            "0.5221179624664879\n",
=======
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 3 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (8453, 372694)\n",
            "\n",
            "0.5281501340482574\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (8453, 867964)\n",
            "\n",
            "0.5214477211796247\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (8453, 823481)\n",
            "\n",
            "0.5355227882037533\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (8453, 450787)\n",
            "\n",
            "0.5361930294906166\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (8453, 1320619)\n",
            "\n",
            "0.5187667560321716\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (8453, 1276136)\n",
            "\n",
            "0.5308310991957105\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (8453, 903442)\n",
            "\n",
            "0.5368632707774799\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (8453, 452655)\n",
            "\n",
            "0.5348525469168901\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (8453, 1766455)\n",
            "\n",
            "0.5227882037533512\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (8453, 1721972)\n",
            "\n",
            "0.5361930294906166\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (8453, 1349278)\n",
            "\n",
            "0.5368632707774799\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (8453, 898491)\n",
            "\n",
            "0.5348525469168901\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (8453, 445836)\n",
            "\n",
            "0.5335120643431636\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (8453, 2204217)\n",
            "\n",
            "0.5160857908847185\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (8453, 2159734)\n",
            "\n",
            "0.5388739946380697\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (8453, 1787040)\n",
            "\n",
            "0.5348525469168901\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (8453, 1336253)\n",
            "\n",
            "0.5341823056300268\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (8453, 883598)\n",
            "\n",
            "0.5328418230563002\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (8453, 437762)\n",
            "\n",
            "0.5328418230563002\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 6 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "shots fired french magazine hq bibi netanyahus campaign funds u isis behead street magician entertaining crowds syria tricksdenmark sets new world record renewable energy production covering country total electricity consumption wind power isis closes schools syria leaving children without education unthe european union wants turkey explain human traffickers could taken two cargo ships filled migrants country towards eu without authorities noticing\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (6762, 43981)\n",
            "\n",
            "0.5100502512562815\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (6762, 405615)\n",
            "\n",
            "0.5050251256281407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (6762, 361634)\n",
            "\n",
            "0.5159128978224455\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (6762, 842497)\n",
            "\n",
            "0.5159128978224455\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (6762, 798516)\n",
            "\n",
            "0.5209380234505863\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (6762, 436882)\n",
            "\n",
            "0.533500837520938\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (6762, 1282285)\n",
            "\n",
            "0.5134003350083752\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (6762, 1238304)\n",
            "\n",
            "0.5376884422110553\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (6762, 876670)\n",
            "\n",
            "0.541038525963149\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (6762, 439788)\n",
            "\n",
            "0.541038525963149\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (6762, 1716823)\n",
            "\n",
            "0.5209380234505863\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (6762, 1672842)\n",
            "\n",
            "0.5418760469011725\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (6762, 1311208)\n",
            "\n",
            "0.5418760469011725\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (6762, 874326)\n",
            "\n",
            "0.5393634840871022\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (6762, 434538)\n",
            "\n",
            "0.5393634840871022\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (6762, 2144942)\n",
            "\n",
            "0.5226130653266332\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (6762, 2100961)\n",
            "\n",
            "0.5326633165829145\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (6762, 1739327)\n",
            "\n",
            "0.5418760469011725\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (6762, 1302445)\n",
            "\n",
            "0.5393634840871022\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (6762, 862657)\n",
            "\n",
            "0.5393634840871022\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (6762, 428119)\n",
            "\n",
            "0.5393634840871022\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 7 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "air france aircraft carrying people disappeared radar atlantic ocean brazil tell difference israeli palestinian former german mp judge offers reward prosecution bush cheney rumsfeld blair north korea starts landing exercises using amphibious vessels may planning attack south korean island president el salvador sends son france escape violence native el salvador son stabbed death awl parisian bridge random act violence apparent motive indonesian model married malaysian prince says kidnapped drugged sexually abused royal family escapes help singaporean police attack liberty untold story israel deadly assault u spy ship book review\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (5071, 40782)\n",
            "\n",
            "0.5066964285714286\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (5071, 364074)\n",
            "\n",
            "0.5267857142857143\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (5071, 323292)\n",
            "\n",
            "0.5357142857142857\n",
=======
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 4 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (5071, 751183)\n",
            "\n",
            "0.5223214285714286\n",
=======
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (5071, 710401)\n",
            "\n",
            "0.5524553571428571\n",
=======
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (5071, 387109)\n",
            "\n",
            "0.5736607142857143\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (5071, 1141239)\n",
            "\n",
            "0.5223214285714286\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (5071, 1100457)\n",
            "\n",
            "0.5714285714285714\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (5071, 777165)\n",
            "\n",
            "0.5859375\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (5071, 390056)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (5071, 1527434)\n",
            "\n",
            "0.5167410714285714\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (5071, 1486652)\n",
            "\n",
            "0.5736607142857143\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (5071, 1163360)\n",
            "\n",
            "0.5859375\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (5071, 776251)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (5071, 386195)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (5071, 1908822)\n",
            "\n",
            "0.5167410714285714\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (5071, 1868040)\n",
            "\n",
            "0.5770089285714286\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (5071, 1544748)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (5071, 1157639)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (5071, 767583)\n",
            "\n",
            "0.5870535714285714\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (5071, 381388)\n",
            "\n",
            "0.5870535714285714\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 8 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "air france aircraft carrying people disappeared radar atlantic ocean brazil tell difference israeli palestinian former german mp judge offers reward prosecution bush cheney rumsfeld blair north korea starts landing exercises using amphibious vessels may planning attack south korean island president el salvador sends son france escape violence native el salvador son stabbed death awl parisian bridge random act violence apparent motive indonesian model married malaysian prince says kidnapped drugged sexually abused royal family escapes help singaporean police attack liberty untold story israel deadly assault u spy ship book review el salvador first leftist president takes power hillary clinton attended inauguration\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (5071, 44527)\n",
            "\n",
            "0.5357142857142857\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (5071, 407323)\n",
            "\n",
            "0.5379464285714286\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (5071, 362796)\n",
            "\n",
            "0.5524553571428571\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (5071, 846770)\n",
            "\n",
            "0.5357142857142857\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (5071, 802243)\n",
            "\n",
            "0.5680803571428571\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (5071, 439447)\n",
            "\n",
            "0.5814732142857143\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (5071, 1290808)\n",
            "\n",
            "0.5401785714285714\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (5071, 1246281)\n",
            "\n",
            "0.5669642857142857\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (5071, 883485)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (5071, 444038)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (5071, 1731255)\n",
            "\n",
            "0.5290178571428571\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (5071, 1686728)\n",
            "\n",
            "0.5814732142857143\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (5071, 1323932)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (5071, 884485)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (5071, 440447)\n",
            "\n",
            "0.5892857142857143\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (5071, 2166969)\n",
            "\n",
            "0.5245535714285714\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (5071, 2122442)\n",
            "\n",
            "0.5747767857142857\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (5071, 1759646)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (5071, 1320199)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (5071, 876161)\n",
            "\n",
            "0.5892857142857143\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (5071, 435714)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 9 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "norwegian air ceo says flights u europe coming soon russian warships launch missiles isis caspian seawind power cheapest electricity produce germany u k even without government subsidies paedophile bishop escaped charges mps royal family intervened court toldteslas hit danish tax cars green goals ditched three month old government already said abandoning ambitious co emissions targets dropping plans become fossil fuel free images pluto charon continue captivate nasa world alive every week floored stern said nasa wont let tell going tell thursday amazing scientists nobel discovering genetic mechanisms explain dont cancerdoctors without borders wants independent inquiry u attack hospitalitalian priest gino flaim defends paedophiles blames love seeking children\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (3381, 37661)\n",
            "\n",
            "0.5460636515912898\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (3381, 320582)\n",
            "\n",
            "0.5611390284757118\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (3381, 282921)\n",
            "\n",
            "0.5460636515912898\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (3381, 655887)\n",
            "\n",
            "0.5477386934673367\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (3381, 618226)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (3381, 335305)\n",
            "\n",
            "0.5360134003350083\n",
=======
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 5 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (3381, 994149)\n",
            "\n",
            "0.5527638190954773\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (3381, 956488)\n",
            "\n",
            "0.5376884422110553\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (3381, 673567)\n",
            "\n",
            "0.5393634840871022\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (3381, 338262)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (3381, 1329935)\n",
            "\n",
            "0.5544388609715243\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (3381, 1292274)\n",
            "\n",
            "0.5443886097152428\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (3381, 1009353)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (3381, 674048)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (3381, 335786)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (3381, 1662533)\n",
            "\n",
            "0.5527638190954773\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (3381, 1624872)\n",
            "\n",
            "0.5460636515912898\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (3381, 1341951)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (3381, 1006646)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (3381, 668384)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (3381, 332598)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 10 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "norwegian air ceo says flights u europe coming soon russian warships launch missiles isis caspian seawind power cheapest electricity produce germany u k even without government subsidies paedophile bishop escaped charges mps royal family intervened court toldteslas hit danish tax cars green goals ditched three month old government already said abandoning ambitious co emissions targets dropping plans become fossil fuel free images pluto charon continue captivate nasa world alive every week floored stern said nasa wont let tell going tell thursday amazing scientists nobel discovering genetic mechanisms explain dont cancerdoctors without borders wants independent inquiry u attack hospitalitalian priest gino flaim defends paedophiles blames love seeking children emails show qadaffi son offered talks clinton ordered top general take call\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (3381, 40224)\n",
            "\n",
            "0.507537688442211\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (3381, 351197)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (3381, 310973)\n",
            "\n",
            "0.541038525963149\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (3381, 722875)\n",
            "\n",
            "0.5477386934673367\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (3381, 682651)\n",
            "\n",
            "0.5360134003350083\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (3381, 371678)\n",
            "\n",
            "0.5376884422110553\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (3381, 1098571)\n",
            "\n",
            "0.5443886097152428\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (3381, 1058347)\n",
            "\n",
            "0.5276381909547738\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (3381, 747374)\n",
            "\n",
            "0.5376884422110553\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (3381, 375696)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (3381, 1471962)\n",
            "\n",
            "0.5510887772194305\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (3381, 1431738)\n",
            "\n",
            "0.5376884422110553\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (3381, 1120765)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (3381, 749087)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (3381, 373391)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (3381, 1842202)\n",
            "\n",
            "0.559463986599665\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (3381, 1801978)\n",
            "\n",
            "0.5443886097152428\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (3381, 1491005)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (3381, 1119327)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (3381, 743631)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (3381, 370240)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 11 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "norwegian air ceo says flights u europe coming soon russian warships launch missiles isis caspian seawind power cheapest electricity produce germany u k even without government subsidies paedophile bishop escaped charges mps royal family intervened court toldteslas hit danish tax cars green goals ditched three month old government already said abandoning ambitious co emissions targets dropping plans become fossil fuel free images pluto charon continue captivate nasa world alive every week floored stern said nasa wont let tell going tell thursday amazing scientists nobel discovering genetic mechanisms explain dont cancerdoctors without borders wants independent inquiry u attack hospitalitalian priest gino flaim defends paedophiles blames love seeking children emails show qadaffi son offered talks clinton ordered top general take call obama turn syria proxy war u russia\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (3381, 42761)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (3381, 380640)\n",
            "\n",
            "0.5360134003350083\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (3381, 337879)\n",
            "\n",
            "0.525963149078727\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (3381, 787677)\n",
            "\n",
            "0.5343383584589615\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (3381, 744916)\n",
            "\n",
            "0.5293132328308208\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (3381, 407037)\n",
            "\n",
            "0.5393634840871022\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (3381, 1199806)\n",
            "\n",
            "0.542713567839196\n",
=======
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 6 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (3381, 1157045)\n",
            "\n",
            "0.5443886097152428\n",
=======
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (3381, 819166)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (3381, 412129)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (3381, 1609843)\n",
            "\n",
            "0.5443886097152428\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (3381, 1567082)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (3381, 1229203)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (3381, 822166)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (3381, 410037)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (3381, 2016772)\n",
            "\n",
            "0.5443886097152428\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (3381, 1974011)\n",
            "\n",
            "0.5443886097152428\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (3381, 1636132)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (3381, 1229095)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (3381, 816966)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (3381, 406929)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 12 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "norwegian air ceo says flights u europe coming soon russian warships launch missiles isis caspian seawind power cheapest electricity produce germany u k even without government subsidies paedophile bishop escaped charges mps royal family intervened court toldteslas hit danish tax cars green goals ditched three month old government already said abandoning ambitious co emissions targets dropping plans become fossil fuel free images pluto charon continue captivate nasa world alive every week floored stern said nasa wont let tell going tell thursday amazing scientists nobel discovering genetic mechanisms explain dont cancerdoctors without borders wants independent inquiry u attack hospitalitalian priest gino flaim defends paedophiles blames love seeking children emails show qadaffi son offered talks clinton ordered top general take call obama turn syria proxy war u russiatoyota u unsure isis got brand new pickup trucks\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (3381, 45225)\n",
            "\n",
            "0.509212730318258\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (3381, 409440)\n",
            "\n",
            "0.5376884422110553\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (3381, 364215)\n",
            "\n",
            "0.541038525963149\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (3381, 851251)\n",
            "\n",
            "0.5393634840871022\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (3381, 806026)\n",
            "\n",
            "0.5360134003350083\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (3381, 441811)\n",
            "\n",
            "0.5477386934673367\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (3381, 1299226)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (3381, 1254001)\n",
            "\n",
            "0.5460636515912898\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (3381, 889786)\n",
            "\n",
            "0.5460636515912898\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (3381, 447975)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (3381, 1745292)\n",
            "\n",
            "0.541038525963149\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (3381, 1700067)\n",
            "\n",
            "0.5477386934673367\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (3381, 1335852)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (3381, 894041)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (3381, 446066)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (3381, 2188314)\n",
            "\n",
            "0.5326633165829145\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (3381, 2143089)\n",
            "\n",
            "0.5443886097152428\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (3381, 1778874)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (3381, 1337063)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (3381, 889088)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (3381, 443022)\n",
            "\n",
            "0.542713567839196\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 25 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "leaked uk copyright lobby holds closed door meetings gov discuss national web censorship regimetaiwan blogger imprisoned negative restaurant review fined jailed contending food salty japan issued tsunami alert magnitude earthquakeworld wealthiest people richer credit crunch says studythe dutch passed law prohibiting internet providers slowing traffic unless ease congestion preserve security block spam toronto police never use controversial crowd control technique known kettling employed last years g summitsomali man tried kill danish cartoonist drew cartoon prophet muhammad sentenced years dutch lawmakers adopt net neutrality lawryan cleary arrested lulzsec member threatens kill self comp taken awaycannibalism comes north koreanuclear experts killed russia plane crash helped design iran facilityrightwing geert wilders cleared hate anti islamic charges netherlands courtnazi hunting france first civilized internet online world looking nervously europe whose leaders join force bring civility internet france leads cheering squadwhile consumed politics day oceans dying faster scientists previously thought european elites lost generation european union bad shape common currency shambles economies many member states moribund young europeans longer see eu helps millions taking streets demand future grid straw squares turns chinese sand soil china struggled keep deserts cover quarter country gaining ground soil stabilization sustainable livestock farming beginning slow rates desertification north korea meth export rapid rise crystal meth addiction china likely source north korea horrendous poverty kim jong il kingdom forces people take things like cancer drug sole form medication daughter muammar gaddafi launched lawsuit murder following death april four members family including month old daughter nato air strike legal papers submitted prosecutor office brussels tuesday french lawyer german internet platform awarded prize role uncovering plagiarism forced popular former defense minister karl theodor zu guttenberg step users collaborated guttenplag wiki danish police want id use internet sri lankas bloody secret sri lankas killing fields shows doesnt constitute crimes humanity nothing views livemint comflash flood hits beijingstaples breached canadian privacy law wiping customer data laptops storage devices reselling women sexually assaulted many injured latest mass rape suspected rebels eastern democratic republic congo international aid workers local media reported thursday new concerns emerge north korea nuclear program satellite images show fresh construction yongbyon nuke site\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (1690, 47261)\n",
            "\n",
            "0.5250836120401338\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (1690, 426583)\n",
            "\n",
            "0.5284280936454849\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (1690, 379322)\n",
            "\n",
            "0.5585284280936454\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (1690, 889173)\n",
            "\n",
            "0.5451505016722408\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (1690, 841912)\n",
            "\n",
            "0.568561872909699\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (1690, 462590)\n",
            "\n",
            "0.5618729096989966\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (1690, 1360161)\n",
            "\n",
            "0.5384615384615384\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (1690, 1312900)\n",
            "\n",
            "0.5585284280936454\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (1690, 933578)\n",
            "\n",
            "0.5585284280936454\n",
=======
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 7 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (1690, 470988)\n",
            "\n",
            "0.5585284280936454\n",
=======
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (1690, 1831076)\n",
            "\n",
            "0.5351170568561873\n",
=======
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (1690, 1783815)\n",
            "\n",
            "0.5551839464882943\n",
=======
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (1690, 1404493)\n",
            "\n",
            "0.5585284280936454\n",
=======
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (1690, 941903)\n",
            "\n",
            "0.5585284280936454\n",
=======
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (1690, 470915)\n",
            "\n",
            "0.5585284280936454\n",
=======
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (1690, 2300683)\n",
            "\n",
            "0.5451505016722408\n",
=======
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (1690, 2253422)\n",
            "\n",
            "0.5551839464882943\n",
=======
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (1690, 1874100)\n",
            "\n",
            "0.5585284280936454\n",
=======
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (1690, 1411510)\n",
            "\n",
            "0.5585284280936454\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (1690, 940522)\n",
            "\n",
            "0.5585284280936454\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (1690, 469607)\n",
            "\n",
            "0.5585284280936454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgc2E1npZvJC"
      },
      "source": [
        "Kiértékelés."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWUCZnMNfebo",
        "outputId": "6d861b00-29e3-4b73-99ad-64651a1d26a6"
      },
      "source": [
        "best_model_rows = 0\r\n",
        "\r\n",
        "for model in range(len(rows_summary_value)):\r\n",
        "    print(str(rows_summary_value[model]) + \":\\t\\t\\t\\t\\t\" \r\n",
        "          + str(rows_summary_accuraccy[model]))\r\n",
        "\r\n",
        "    if rows_summary_accuraccy[model] > best_model_rows:\r\n",
        "        best_model_rows = rows_summary_accuraccy[model]\r\n",
        "        best_model_rows_index = model\r\n",
        "\r\n",
        "print(\"--------------------------------------------\\nBest row value:\\n\" \r\n",
        "      + str(rows_summary_value[best_model_rows_index]) + \"\\t\\t\\t\\t\\t\" + \r\n",
        "      str(rows_summary_accuraccy[best_model_rows_index]))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1:\t\t\t\t\t0.5442477876106194\n",
            "2:\t\t\t\t\t0.541189611840268\n",
            "3:\t\t\t\t\t0.5525764558022622\n",
            "4:\t\t\t\t\t0.5404801786711334\n",
            "5:\t\t\t\t\t0.5388739946380697\n",
            "6:\t\t\t\t\t0.5418760469011725\n",
            "7:\t\t\t\t\t0.5881696428571429\n",
            "8:\t\t\t\t\t0.5892857142857143\n",
            "9:\t\t\t\t\t0.5611390284757118\n",
            "10:\t\t\t\t\t0.559463986599665\n",
            "11:\t\t\t\t\t0.5443886097152428\n",
            "12:\t\t\t\t\t0.5477386934673367\n",
            "25:\t\t\t\t\t0.568561872909699\n",
            "--------------------------------------------\n",
            "Best row value:\n",
            "8\t\t\t\t\t0.5892857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-GyfELNcMas"
      },
      "source": [
        "A legjobb ROWS eredményeinek megjelenítése."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnMyo9Ljca4I",
        "outputId": "674f0c54-291b-46d0-941e-f6617f1ffb53"
      },
      "source": [
        "ROWS = int(rows_summary_value[best_model_rows_index])\r\n",
        "\r\n",
        "model_type = []\r\n",
        "result = []\r\n",
        "\r\n",
        "df_sum_news_labels = preprocess()\r\n",
        "train = split_to_train()\r\n",
        "test = split_to_test()\r\n",
        "\r\n",
        "# check\r\n",
        "split_sum = len(train) + len(test)\r\n",
        "sum = len(df_sum_news_labels)\r\n",
        "assert split_sum == sum    \r\n",
        "\r\n",
        "train_headlines = []\r\n",
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0, len(train.index)):\r\n",
        "    train_headlines.append(train.iloc[row, 1])\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "# show the first\r\n",
        "print(train_headlines[0])\r\n",
        "\r\n",
        "for MODEL_TYPE in model_type_values:\r\n",
        "\r\n",
        "    for n in range(1,MODEL_TYPE+1):\r\n",
        "        print(\"--------------------------------------------\\n\\nStart of the \" \r\n",
        "              + str(n) + \",\" + str(MODEL_TYPE) + \" gram model\\n\")\r\n",
        "\r\n",
        "        _gram_vectorizer_ = CountVectorizer(ngram_range=(n,MODEL_TYPE))\r\n",
        "        _train_vectorizer_ = _gram_vectorizer_.fit_transform(train_headlines)\r\n",
        "\r\n",
        "        print(\"The shape is: \" + str(_train_vectorizer_.shape) + \"\\n\")\r\n",
        "\r\n",
        "        _gram_model_ = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "        _gram_model_ = _gram_model_.fit(_train_vectorizer_, train[\"Label\"])\r\n",
        "\r\n",
        "        _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "        _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
        "        print (accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "        model_type.append(str(n) + \",\" + str(MODEL_TYPE) + \" n-gram\")\r\n",
        "        result.append(accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "best_model_gram = 0\r\n",
        "\r\n",
        "for model in range(len(model_type)):\r\n",
        "    print(str(model_type[model]) + \":\\t\\t\\t\\t\\t\" + str(result[model]))\r\n",
        "\r\n",
        "    if result[model] > best_model_gram:\r\n",
        "        best_model_gram = result[model]\r\n",
        "        best_model_gram_index = model\r\n",
        "\r\n",
        "print(\"--------------------------------------------\\nBest model:\\n\" \r\n",
        "      + str(model_type[best_model_gram_index]) + \"\\t\\t\\t\\t\\t\" + \r\n",
        "      str(result[best_model_gram_index]))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "air france aircraft carrying people disappeared radar atlantic ocean brazil tell difference israeli palestinian former german mp judge offers reward prosecution bush cheney rumsfeld blair north korea starts landing exercises using amphibious vessels may planning attack south korean island president el salvador sends son france escape violence native el salvador son stabbed death awl parisian bridge random act violence apparent motive indonesian model married malaysian prince says kidnapped drugged sexually abused royal family escapes help singaporean police attack liberty untold story israel deadly assault u spy ship book review el salvador first leftist president takes power hillary clinton attended inauguration\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (5071, 44527)\n",
            "\n",
            "0.5357142857142857\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (5071, 407323)\n",
            "\n",
            "0.5379464285714286\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (5071, 362796)\n",
            "\n",
            "0.5524553571428571\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (5071, 846770)\n",
            "\n",
            "0.5357142857142857\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (5071, 802243)\n",
            "\n",
            "0.5680803571428571\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (5071, 439447)\n",
            "\n",
            "0.5814732142857143\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (5071, 1290808)\n",
            "\n",
            "0.5401785714285714\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (5071, 1246281)\n",
            "\n",
            "0.5669642857142857\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (5071, 883485)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (5071, 444038)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (5071, 1731255)\n",
            "\n",
            "0.5290178571428571\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (5071, 1686728)\n",
            "\n",
            "0.5814732142857143\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (5071, 1323932)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (5071, 884485)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (5071, 440447)\n",
            "\n",
            "0.5892857142857143\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (5071, 2166969)\n",
            "\n",
            "0.5245535714285714\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (5071, 2122442)\n",
            "\n",
            "0.5747767857142857\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (5071, 1759646)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (5071, 1320199)\n",
            "\n",
            "0.5881696428571429\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (5071, 876161)\n",
            "\n",
            "0.5892857142857143\n",
=======
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 8 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 9 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 10 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 11 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 12 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
<<<<<<< HEAD
            "The shape is: (5071, 435714)\n",
            "\n",
            "0.5881696428571429\n",
            "1,1 n-gram:\t\t\t\t\t0.5357142857142857\n",
            "1,2 n-gram:\t\t\t\t\t0.5379464285714286\n",
            "2,2 n-gram:\t\t\t\t\t0.5524553571428571\n",
            "1,3 n-gram:\t\t\t\t\t0.5357142857142857\n",
            "2,3 n-gram:\t\t\t\t\t0.5680803571428571\n",
            "3,3 n-gram:\t\t\t\t\t0.5814732142857143\n",
            "1,4 n-gram:\t\t\t\t\t0.5401785714285714\n",
            "2,4 n-gram:\t\t\t\t\t0.5669642857142857\n",
            "3,4 n-gram:\t\t\t\t\t0.5881696428571429\n",
            "4,4 n-gram:\t\t\t\t\t0.5881696428571429\n",
            "1,5 n-gram:\t\t\t\t\t0.5290178571428571\n",
            "2,5 n-gram:\t\t\t\t\t0.5814732142857143\n",
            "3,5 n-gram:\t\t\t\t\t0.5881696428571429\n",
            "4,5 n-gram:\t\t\t\t\t0.5881696428571429\n",
            "5,5 n-gram:\t\t\t\t\t0.5892857142857143\n",
            "1,6 n-gram:\t\t\t\t\t0.5245535714285714\n",
            "2,6 n-gram:\t\t\t\t\t0.5747767857142857\n",
            "3,6 n-gram:\t\t\t\t\t0.5881696428571429\n",
            "4,6 n-gram:\t\t\t\t\t0.5881696428571429\n",
            "5,6 n-gram:\t\t\t\t\t0.5892857142857143\n",
            "6,6 n-gram:\t\t\t\t\t0.5881696428571429\n",
            "--------------------------------------------\n",
            "Best model:\n",
            "5,5 n-gram\t\t\t\t\t0.5892857142857143\n"
=======
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 25 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
<<<<<<< HEAD
        "id": "C5fXYYfZm_7W"
      },
      "source": [
        "A legjobbhoz tartozó korrelációs tényezők megjelenítése."
=======
        "id": "Tgc2E1npZvJC"
      },
      "source": [
        "Kiértékelés."
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "id": "Qk-qyHFInIOl",
        "outputId": "c19d9de3-1ea7-4282-fdd6-b8b757a7c85f"
      },
      "source": [
        "ROWS = int(rows_summary_value[best_model_rows_index])\r\n",
        "MODEL_TYPE = str(model_type[best_model_gram_index])\r\n",
        "\r\n",
        "df_sum_news_labels = preprocess()\r\n",
        "train = split_to_train()\r\n",
        "test = split_to_test()\r\n",
        "\r\n",
        "# check\r\n",
        "split_sum = len(train) + len(test)\r\n",
        "sum = len(df_sum_news_labels)\r\n",
        "assert split_sum == sum    \r\n",
        "\r\n",
        "train_headlines = []\r\n",
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0, len(train.index)):\r\n",
        "    train_headlines.append(train.iloc[row, 1])\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "# show the first\r\n",
        "print(train_headlines[0])\r\n",
        "\r\n",
        "_gram_vectorizer_ = CountVectorizer(ngram_range=(int(MODEL_TYPE[0]),int(MODEL_TYPE[2])))\r\n",
        "_train_vectorizer_ = _gram_vectorizer_.fit_transform(train_headlines)\r\n",
        "\r\n",
        "print(\"The shape is: \" + str(_train_vectorizer_.shape) + \"\\n\")\r\n",
        "\r\n",
        "_gram_model_ = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "_gram_model_ = _gram_model_.fit(_train_vectorizer_, train[\"Label\"])\r\n",
        "\r\n",
        "_gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "_gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
        "print (accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "model_type.append(str(n) + \",\" + str(MODEL_TYPE) + \" n-gram\")\r\n",
        "result.append(accuracy_score(test[\"Label\"], _gram_predictions_))"
      ],
      "execution_count": 79,
=======
        "id": "pWUCZnMNfebo",
        "outputId": "3916f084-cf3f-4f0f-c41e-3cee80816fde"
      },
      "source": [
        "best_model = 0\r\n",
        "\r\n",
        "for model in range(len(rows_summary_value)):\r\n",
        "    print(str(rows_summary_value[model]) + \":\\t\\t\\t\\t\\t\" \r\n",
        "          + str(rows_summary_accuraccy[model]))\r\n",
        "\r\n",
        "    if rows_summary_accuraccy[model] > best_model:\r\n",
        "        best_model = rows_summary_accuraccy[model]\r\n",
        "        best_model_index = model\r\n",
        "\r\n",
        "print(\"--------------------------------------------\\nBest row value:\\n\" \r\n",
        "      + str(rows_summary_value[best_model_index]) + \"\\t\\t\\t\\t\\t\" + \r\n",
        "      str(rows_summary_accuraccy[best_model_index]))"
      ],
      "execution_count": 396,
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "air france aircraft carrying people disappeared radar atlantic ocean brazil tell difference israeli palestinian former german mp judge offers reward prosecution bush cheney rumsfeld blair north korea starts landing exercises using amphibious vessels may planning attack south korean island president el salvador sends son france escape violence native el salvador son stabbed death awl parisian bridge random act violence apparent motive indonesian model married malaysian prince says kidnapped drugged sexually abused royal family escapes help singaporean police attack liberty untold story israel deadly assault u spy ship book review el salvador first leftist president takes power hillary clinton attended inauguration\n",
            "The shape is: (5071, 440447)\n",
            "\n",
            "0.5892857142857143\n"
=======
            "1:\t\t\t\t\t0.5110304384250209\n",
            "1:\t\t\t\t\t0.5283440379782184\n",
            "1:\t\t\t\t\t0.5495671600111701\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5110304384250209\n",
            "2:\t\t\t\t\t0.5283440379782184\n",
            "2:\t\t\t\t\t0.5495671600111701\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5110304384250209\n",
            "3:\t\t\t\t\t0.5283440379782184\n",
            "3:\t\t\t\t\t0.5495671600111701\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5110304384250209\n",
            "4:\t\t\t\t\t0.5283440379782184\n",
            "4:\t\t\t\t\t0.5495671600111701\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5110304384250209\n",
            "5:\t\t\t\t\t0.5283440379782184\n",
            "5:\t\t\t\t\t0.5495671600111701\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5110304384250209\n",
            "6:\t\t\t\t\t0.5283440379782184\n",
            "6:\t\t\t\t\t0.5495671600111701\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5110304384250209\n",
            "7:\t\t\t\t\t0.5283440379782184\n",
            "7:\t\t\t\t\t0.5495671600111701\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5110304384250209\n",
            "8:\t\t\t\t\t0.5283440379782184\n",
            "8:\t\t\t\t\t0.5495671600111701\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5110304384250209\n",
            "9:\t\t\t\t\t0.5283440379782184\n",
            "9:\t\t\t\t\t0.5495671600111701\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5110304384250209\n",
            "10:\t\t\t\t\t0.5283440379782184\n",
            "10:\t\t\t\t\t0.5495671600111701\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5110304384250209\n",
            "11:\t\t\t\t\t0.5283440379782184\n",
            "11:\t\t\t\t\t0.5495671600111701\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5110304384250209\n",
            "12:\t\t\t\t\t0.5283440379782184\n",
            "12:\t\t\t\t\t0.5495671600111701\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5110304384250209\n",
            "25:\t\t\t\t\t0.5283440379782184\n",
            "25:\t\t\t\t\t0.5495671600111701\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "1:\t\t\t\t\t0.5110304384250209\n",
            "1:\t\t\t\t\t0.5283440379782184\n",
            "1:\t\t\t\t\t0.5495671600111701\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5110304384250209\n",
            "2:\t\t\t\t\t0.5283440379782184\n",
            "2:\t\t\t\t\t0.5495671600111701\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5110304384250209\n",
            "3:\t\t\t\t\t0.5283440379782184\n",
            "3:\t\t\t\t\t0.5495671600111701\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5110304384250209\n",
            "4:\t\t\t\t\t0.5283440379782184\n",
            "4:\t\t\t\t\t0.5495671600111701\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5110304384250209\n",
            "5:\t\t\t\t\t0.5283440379782184\n",
            "5:\t\t\t\t\t0.5495671600111701\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5110304384250209\n",
            "6:\t\t\t\t\t0.5283440379782184\n",
            "6:\t\t\t\t\t0.5495671600111701\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5110304384250209\n",
            "7:\t\t\t\t\t0.5283440379782184\n",
            "7:\t\t\t\t\t0.5495671600111701\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5110304384250209\n",
            "8:\t\t\t\t\t0.5283440379782184\n",
            "8:\t\t\t\t\t0.5495671600111701\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5110304384250209\n",
            "9:\t\t\t\t\t0.5283440379782184\n",
            "9:\t\t\t\t\t0.5495671600111701\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5110304384250209\n",
            "10:\t\t\t\t\t0.5283440379782184\n",
            "10:\t\t\t\t\t0.5495671600111701\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5110304384250209\n",
            "11:\t\t\t\t\t0.5283440379782184\n",
            "11:\t\t\t\t\t0.5495671600111701\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5110304384250209\n",
            "12:\t\t\t\t\t0.5283440379782184\n",
            "12:\t\t\t\t\t0.5495671600111701\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5110304384250209\n",
            "25:\t\t\t\t\t0.5283440379782184\n",
            "25:\t\t\t\t\t0.5495671600111701\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "--------------------------------------------\n",
            "Best row value:\n",
            "1\t\t\t\t\t0.5520804244624407\n"
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
          ],
          "name": "stdout"
        }
      ]
    },
    {
<<<<<<< HEAD
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "ee6Q8qicpSAP",
        "outputId": "05af4d49-8fad-445c-d3de-5b72042e34fd"
      },
      "source": [
        "_gram_words_best_ = _gram_vectorizer_.get_feature_names()\r\n",
        "_gram_coeffs_best_ = _gram_model_.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : _gram_words_best_, \r\n",
        "                        'Coefficient' : _gram_coeffs_best_})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "\r\n",
        "coeffdf.head(10)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>331615</th>\n",
              "      <td>russia india china south africa</td>\n",
              "      <td>0.118901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260355</th>\n",
              "      <td>north korea preparing restart nuclear</td>\n",
              "      <td>0.103224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260434</th>\n",
              "      <td>north korea shoot rocket shoot</td>\n",
              "      <td>0.102229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49444</th>\n",
              "      <td>british prime minister david cameron</td>\n",
              "      <td>0.101564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14235</th>\n",
              "      <td>american country legalize gay marriage</td>\n",
              "      <td>0.099965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99455</th>\n",
              "      <td>define israel nation state jewish</td>\n",
              "      <td>0.098194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196050</th>\n",
              "      <td>israel nation state jewish people</td>\n",
              "      <td>0.098194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307426</th>\n",
              "      <td>pushes define israel nation state</td>\n",
              "      <td>0.098194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44895</th>\n",
              "      <td>bombing doctors without borders hospital</td>\n",
              "      <td>0.094717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239700</th>\n",
              "      <td>military help georgia declaration war</td>\n",
              "      <td>0.091112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Word  Coefficient\n",
              "331615           russia india china south africa     0.118901\n",
              "260355     north korea preparing restart nuclear     0.103224\n",
              "260434            north korea shoot rocket shoot     0.102229\n",
              "49444       british prime minister david cameron     0.101564\n",
              "14235     american country legalize gay marriage     0.099965\n",
              "99455          define israel nation state jewish     0.098194\n",
              "196050         israel nation state jewish people     0.098194\n",
              "307426         pushes define israel nation state     0.098194\n",
              "44895   bombing doctors without borders hospital     0.094717\n",
              "239700     military help georgia declaration war     0.091112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "FkcfT8TFpTlq",
        "outputId": "263a2e70-5eb7-4bc9-f2cb-5965e0dd2661"
      },
      "source": [
        "coeffdf.tail(10)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>391199</th>\n",
              "      <td>times journalist marie colvin killed</td>\n",
              "      <td>-0.104737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150909</th>\n",
              "      <td>fury die american attack soil</td>\n",
              "      <td>-0.107945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275098</th>\n",
              "      <td>pakistan reacts fury die american</td>\n",
              "      <td>-0.107945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312765</th>\n",
              "      <td>reacts fury die american attack</td>\n",
              "      <td>-0.107945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42928</th>\n",
              "      <td>blocks internet access new york</td>\n",
              "      <td>-0.112290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65574</th>\n",
              "      <td>china blocks internet access new</td>\n",
              "      <td>-0.112290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189076</th>\n",
              "      <td>internet access new york times</td>\n",
              "      <td>-0.112290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184722</th>\n",
              "      <td>indian space research organisation isro</td>\n",
              "      <td>-0.112298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154710</th>\n",
              "      <td>german chancellor angela merkel said</td>\n",
              "      <td>-0.116800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258056</th>\n",
              "      <td>news world phone hacking scandal</td>\n",
              "      <td>-0.136456</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Word  Coefficient\n",
              "391199     times journalist marie colvin killed    -0.104737\n",
              "150909            fury die american attack soil    -0.107945\n",
              "275098        pakistan reacts fury die american    -0.107945\n",
              "312765          reacts fury die american attack    -0.107945\n",
              "42928           blocks internet access new york    -0.112290\n",
              "65574          china blocks internet access new    -0.112290\n",
              "189076           internet access new york times    -0.112290\n",
              "184722  indian space research organisation isro    -0.112298\n",
              "154710     german chancellor angela merkel said    -0.116800\n",
              "258056         news world phone hacking scandal    -0.136456"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
=======
>>>>>>> 5470059f7e1990bedca0af2cf990efd5f6a98a2e
      "cell_type": "markdown",
      "metadata": {
        "id": "UKZQkIdFAXfG"
      },
      "source": [
        "## ECO_BSN_DF, ECO_FNC_DF, ECO_US_DF 2008-2016"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyZGBhb0CcgL"
      },
      "source": [
        "Először megvizsgálom a reddit-es világhírekkel megegyező intervallumon ezeket az összevont adathalmazokat, majd egyesítve és kombinálva a kettőt megvizsgálom, hogy javítja-e a pontosságot.\r\n",
        "\r\n",
        "Ezeket az adathalmazokat én magam gyűjtöttem az alábbi oldalakról:\r\n",
        "\r\n",
        "\r\n",
        "*   https://www.economist.com/business/ \r\n",
        "*   https://www.economist.com/finance-and-economics/ \r\n",
        "*   https://www.economist.com/united-states/ "
      ]
    }
  ]
}