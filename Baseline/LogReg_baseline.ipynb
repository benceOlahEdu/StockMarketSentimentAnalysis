{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogReg_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ygDjIPBVTLl"
      },
      "source": [
        "# **Stock market news feed semantic analysis** *(Baseline LogReg)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kLvL-AJVg3C"
      },
      "source": [
        "Ebben a notebookban az eddigi általam kibányászott, megszerzett adathalmazokat fogom a hagyományos bag of words és logistic regression módszerrel megvizsgálni. Ezek után n-gram modelleket is ki fogok próbálni. Az általa használt források és referenciák az eredményekhez:\r\n",
        "\r\n",
        "\r\n",
        "*   https://colab.research.google.com/drive/1QPrBkh-KwX6qcUtiNWKp9rJoneBfGEVh#scrollTo=bQUJwMjYYN4- *(saját munka - átdolgozott)*\r\n",
        "*   https://colab.research.google.com/drive/1MdpXGCj2fb3g1BI_XfF54OWLkYQCZBBy#scrollTo=LndWT2Kn-UMK *(saját baseline munka)*\r\n",
        "*   https://www.kaggle.com/ndrewgele/omg-nlp-with-the-djia-and-reddit#Basic-Model-Training-and-Testing\r\n",
        "*   https://www.kaggle.com/lseiyjg/use-news-to-predict-stock-markets\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvCnWXPfXgZi"
      },
      "source": [
        "A használt adathalmazok alapján külön fejezeteket készítek és mindenhol jelzem a forrását és a megszerzésének a módját, ha saját bányászás eredménye."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsAeJYBEXzW_"
      },
      "source": [
        "## **A projekt előkészítése**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuHwIVcIX2Zp"
      },
      "source": [
        "A Drive csatlakoztatása a szükséges fájlok későbbi betöltésére. A betöltés közvetlen a használat előtt fogom megtenni."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvU8LOxdKH5-",
        "outputId": "50020d67-e2a4-4c33-f442-d31658b394de"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfOuSSouYIb7"
      },
      "source": [
        "A szükséges könyvtárak betöltése a projekthez."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgUBe7_VYLjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ec6f52-fad3-45f4-9b6f-aa4cd2839855"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import pandas_datareader as web\r\n",
        "from numpy.random import MT19937\r\n",
        "from numpy.random import RandomState, SeedSequence\r\n",
        "import string\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "nltk.download('punkt')\r\n",
        "from nltk.tokenize import word_tokenize  \r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import accuracy_score \r\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZiFx9dUgBsN"
      },
      "source": [
        "A projektben használt makrók definiálása."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bULVBJPegGcc"
      },
      "source": [
        "# Shuffle cycle number for the dataframe\r\n",
        "SHUFFLE_CYCLE = 500"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vfWZE7fZzcF"
      },
      "source": [
        "A reprodukálhatóság miatt definiálok egy seed-et a véletlen szám generátorhoz, amit a továbbiakban használni fogok."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEjH22olZ1L_"
      },
      "source": [
        "# Random seed\r\n",
        "RANDOM_SEED = 1234\r\n",
        "\r\n",
        "# Numpy random seed\r\n",
        "NP_SEED = 1234\r\n",
        "\r\n",
        "# Max iteration for training\r\n",
        "MAX_ITER = 100000\r\n",
        "\r\n",
        "# Train size\r\n",
        "TRAIN_SPLIT = 0.85\r\n",
        "\r\n",
        "# Test size\r\n",
        "TEST_SPLIT = 0.15"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw003siyimeD"
      },
      "source": [
        "rs = RandomState(MT19937(SeedSequence(NP_SEED)))\r\n",
        "np.random.seed(NP_SEED)"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoE6btiUYg-a"
      },
      "source": [
        "## **KAG_REDDIT_WRLD_DJIA_DF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2jP3czjYt6c"
      },
      "source": [
        "Ez az adathalmaz a top25 hírt tartalmazza a Reddit World News kategóriából 2008.08.08-2016.07.01 időtartamban. Ez nem általam gyűjtött adathalmaz, a forrása:\r\n",
        "Sun, J. (2016, August). Daily News for Stock Market Prediction, Version 1. Retrieved 2021.02.19. from https://www.kaggle.com/aaron7sun/stocknews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu_wdhA1ZSrt"
      },
      "source": [
        "Az adathalmaz betöltése a csatlakoztatott Drive-omból."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw00CWOBZbeF"
      },
      "source": [
        "# Copy the dataset to the local environment\r\n",
        "!cp \"/content/drive/MyDrive/Combined_News_DJIA.csv\" \"Combined_News_DJIA.csv\"\r\n",
        "\r\n",
        "# Check the copy is succesfull -> good if no assertation error\r\n",
        "read = !ls\r\n",
        "assert read[0].find(\"Combined_News_DJIA.csv\") != -1"
      ],
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W_uQPC2Mt6F"
      },
      "source": [
        "Az eredmények elmentésére és indexelésére az alábbi két tömböt fogom hasnzálni."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ria16HC2MyZa"
      },
      "source": [
        "model_type = [\"Bag of words\", \"1,2 n-gram\", \"2,2 n-gram\", \r\n",
        "              \"1,3 n-gram\", \"2,3 n-gram\", \"3,3 n-gram\"]\r\n",
        "\r\n",
        "result = []              "
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z73YJGnjYxAz"
      },
      "source": [
        "Makró definiálás."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lMyUJerYzAg"
      },
      "source": [
        "# Number of merged news into one string\r\n",
        "ROWS = 2"
      ],
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1DAhyIob0Bm"
      },
      "source": [
        "### A szöveg előkészítése"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20KSUSX1b4-z"
      },
      "source": [
        "Az adathalmaz betöltése."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "tPmTqk3Gb2Fo",
        "outputId": "2801f6cd-7f42-4552-cc4f-88b04df1823a"
      },
      "source": [
        "# Load the dataset \r\n",
        "df_combined = pd.read_csv('Combined_News_DJIA.csv', index_col = \"Date\")\r\n",
        "\r\n",
        "# Show the dataframe\r\n",
        "df_combined.head()"
      ],
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Top1</th>\n",
              "      <th>Top2</th>\n",
              "      <th>Top3</th>\n",
              "      <th>Top4</th>\n",
              "      <th>Top5</th>\n",
              "      <th>Top6</th>\n",
              "      <th>Top7</th>\n",
              "      <th>Top8</th>\n",
              "      <th>Top9</th>\n",
              "      <th>Top10</th>\n",
              "      <th>Top11</th>\n",
              "      <th>Top12</th>\n",
              "      <th>Top13</th>\n",
              "      <th>Top14</th>\n",
              "      <th>Top15</th>\n",
              "      <th>Top16</th>\n",
              "      <th>Top17</th>\n",
              "      <th>Top18</th>\n",
              "      <th>Top19</th>\n",
              "      <th>Top20</th>\n",
              "      <th>Top21</th>\n",
              "      <th>Top22</th>\n",
              "      <th>Top23</th>\n",
              "      <th>Top24</th>\n",
              "      <th>Top25</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-08-08</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
              "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
              "      <td>b'Russian tanks are moving towards the capital...</td>\n",
              "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
              "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
              "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
              "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
              "      <td>b'Georgian troops retreat from S. Osettain cap...</td>\n",
              "      <td>b'Did the U.S. Prep Georgia for War with Russia?'</td>\n",
              "      <td>b'Rice Gives Green Light for Israel to Attack ...</td>\n",
              "      <td>b'Announcing:Class Action Lawsuit on Behalf of...</td>\n",
              "      <td>b\"So---Russia and Georgia are at war and the N...</td>\n",
              "      <td>b\"China tells Bush to stay out of other countr...</td>\n",
              "      <td>b'Did World War III start today?'</td>\n",
              "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
              "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
              "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
              "      <td>b'This is a busy day:  The European Union has ...</td>\n",
              "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
              "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
              "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
              "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
              "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
              "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-11</th>\n",
              "      <td>1</td>\n",
              "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
              "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
              "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
              "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
              "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
              "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
              "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
              "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
              "      <td>b'Welcome To World War IV! Now In High Definit...</td>\n",
              "      <td>b\"Georgia's move, a mistake of monumental prop...</td>\n",
              "      <td>b'Russia presses deeper into Georgia; U.S. say...</td>\n",
              "      <td>b'Abhinav Bindra wins first ever Individual Ol...</td>\n",
              "      <td>b' U.S. ship heads for Arctic to define territ...</td>\n",
              "      <td>b'Drivers in a Jerusalem taxi station threaten...</td>\n",
              "      <td>b'The French Team is Stunned by Phelps and the...</td>\n",
              "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
              "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
              "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
              "      <td>b'China to overtake US as largest manufacturer'</td>\n",
              "      <td>b'War in South Ossetia [PICS]'</td>\n",
              "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
              "      <td>b' Russia has just beaten the United States ov...</td>\n",
              "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
              "      <td>b'Russia is so much better at war'</td>\n",
              "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-12</th>\n",
              "      <td>0</td>\n",
              "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
              "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
              "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
              "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
              "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
              "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
              "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
              "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
              "      <td>b\"The US military was surprised by the timing ...</td>\n",
              "      <td>b'U.S. Beats War Drum as Iran Dumps the Dollar'</td>\n",
              "      <td>b'Gorbachev: \"Georgian military attacked the S...</td>\n",
              "      <td>b'CNN use footage of Tskhinvali ruins to cover...</td>\n",
              "      <td>b'Beginning a war as the Olympics were opening...</td>\n",
              "      <td>b'55 pyramids as large as the Luxor stacked in...</td>\n",
              "      <td>b'The 11 Top Party Cities in the World'</td>\n",
              "      <td>b'U.S. troops still in Georgia (did you know t...</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
              "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
              "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
              "      <td>b'War in Georgia: The Israeli connection'</td>\n",
              "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
              "      <td>b'Christopher King argues that the US and NATO...</td>\n",
              "      <td>b'America: The New Mexico?'</td>\n",
              "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-13</th>\n",
              "      <td>0</td>\n",
              "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
              "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
              "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
              "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
              "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
              "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
              "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
              "      <td>b'Russian forces sink Georgian ships '</td>\n",
              "      <td>b\"The commander of a Navy air reconnaissance s...</td>\n",
              "      <td>b\"92% of CNN readers: Russia's actions in Geor...</td>\n",
              "      <td>b'USA to send fleet into Black Sea to help Geo...</td>\n",
              "      <td>b\"US warns against Israeli plan to strike agai...</td>\n",
              "      <td>b\"In an intriguing cyberalliance, two Estonian...</td>\n",
              "      <td>b'The CNN Effect: Georgia Schools Russia in In...</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Elephants extinct by 2020?'</td>\n",
              "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
              "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
              "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
              "      <td>b'Israeli defence minister: US against strike ...</td>\n",
              "      <td>b'Gorbachev: We Had No Choice'</td>\n",
              "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
              "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
              "      <td>b'Georgian president  says US military will ta...</td>\n",
              "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-14</th>\n",
              "      <td>1</td>\n",
              "      <td>b'All the experts admit that we should legalis...</td>\n",
              "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
              "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
              "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
              "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
              "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
              "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
              "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
              "      <td>b'Russia exaggerating South Ossetian death tol...</td>\n",
              "      <td>b' Musharraf expected to resign rather than fa...</td>\n",
              "      <td>b'Moscow Made Plans Months Ago to Invade Georgia'</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Nigeria has handed over the potentially oil-...</td>\n",
              "      <td>b'The US and Poland have agreed a preliminary ...</td>\n",
              "      <td>b'Russia apparently is sabotaging infrastructu...</td>\n",
              "      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n",
              "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
              "      <td>b'War in the Caucasus is as much the product o...</td>\n",
              "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
              "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
              "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
              "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
              "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
              "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
              "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Label  ...                                              Top25\n",
              "Date               ...                                                   \n",
              "2008-08-08      0  ...           b\"No Help for Mexico's Kidnapping Surge\"\n",
              "2008-08-11      1  ...  b\"So this is what it's come to: trading sex fo...\n",
              "2008-08-12      0  ...  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...\n",
              "2008-08-13      0  ...  b'2006: Nobel laureate Aleksander Solzhenitsyn...\n",
              "2008-08-14      1  ...  b'Philippines : Peace Advocate say Muslims nee...\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdvD8SIQcPB6"
      },
      "source": [
        "Érdekességképpen a következőkben megvizsgálom, hogy az adathalmaz címkéi megfelelőek. A forrás szerint a címke 1, ha nőtt vagy azonos maradt az érték azon a napon, illetve 0, ha csökkent. (Adj Close adott napi értéke az előző napihoz viszonyítva)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "oj26KF2ncgji",
        "outputId": "719ce00d-c37b-404e-c81b-37e17b19362d"
      },
      "source": [
        "# Load the stock data\r\n",
        "df_stock = web.DataReader(\"DJIA\", data_source=\"yahoo\", start=\"2008-08-08\", \r\n",
        "                          end=\"2016-07-01\")\r\n",
        " \r\n",
        "# Show the stock data\r\n",
        "df_stock.head()"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-08-08</th>\n",
              "      <td>11808.490234</td>\n",
              "      <td>11344.230469</td>\n",
              "      <td>11432.089844</td>\n",
              "      <td>11734.320312</td>\n",
              "      <td>4966810000</td>\n",
              "      <td>11734.320312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-11</th>\n",
              "      <td>11933.549805</td>\n",
              "      <td>11580.190430</td>\n",
              "      <td>11729.669922</td>\n",
              "      <td>11782.349609</td>\n",
              "      <td>5067310000</td>\n",
              "      <td>11782.349609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-12</th>\n",
              "      <td>11830.389648</td>\n",
              "      <td>11541.429688</td>\n",
              "      <td>11781.700195</td>\n",
              "      <td>11642.469727</td>\n",
              "      <td>4711290000</td>\n",
              "      <td>11642.469727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-13</th>\n",
              "      <td>11689.049805</td>\n",
              "      <td>11377.370117</td>\n",
              "      <td>11632.809570</td>\n",
              "      <td>11532.959961</td>\n",
              "      <td>4787600000</td>\n",
              "      <td>11532.959961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-14</th>\n",
              "      <td>11744.330078</td>\n",
              "      <td>11399.839844</td>\n",
              "      <td>11532.070312</td>\n",
              "      <td>11615.929688</td>\n",
              "      <td>4064000000</td>\n",
              "      <td>11615.929688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    High           Low  ...      Volume     Adj Close\n",
              "Date                                    ...                          \n",
              "2008-08-08  11808.490234  11344.230469  ...  4966810000  11734.320312\n",
              "2008-08-11  11933.549805  11580.190430  ...  5067310000  11782.349609\n",
              "2008-08-12  11830.389648  11541.429688  ...  4711290000  11642.469727\n",
              "2008-08-13  11689.049805  11377.370117  ...  4787600000  11532.959961\n",
              "2008-08-14  11744.330078  11399.839844  ...  4064000000  11615.929688\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9UbGo05jACh"
      },
      "source": [
        "Az dátumok formátumát egységesre hozom az összehasonlítás érdekében."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "J6UkTz6Vg23F",
        "outputId": "1a43c1a2-0bd9-4e0a-c700-972c92615ff2"
      },
      "source": [
        "temp_day = []\r\n",
        "\r\n",
        "for day in range(len(df_stock)):\r\n",
        "    temp_day.append(df_stock.index[day].date())\r\n",
        "\r\n",
        "df_stock.index = temp_day\r\n",
        "\r\n",
        "# Show the stock data\r\n",
        "df_stock.head()"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-08-08</th>\n",
              "      <td>11808.490234</td>\n",
              "      <td>11344.230469</td>\n",
              "      <td>11432.089844</td>\n",
              "      <td>11734.320312</td>\n",
              "      <td>4966810000</td>\n",
              "      <td>11734.320312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-11</th>\n",
              "      <td>11933.549805</td>\n",
              "      <td>11580.190430</td>\n",
              "      <td>11729.669922</td>\n",
              "      <td>11782.349609</td>\n",
              "      <td>5067310000</td>\n",
              "      <td>11782.349609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-12</th>\n",
              "      <td>11830.389648</td>\n",
              "      <td>11541.429688</td>\n",
              "      <td>11781.700195</td>\n",
              "      <td>11642.469727</td>\n",
              "      <td>4711290000</td>\n",
              "      <td>11642.469727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-13</th>\n",
              "      <td>11689.049805</td>\n",
              "      <td>11377.370117</td>\n",
              "      <td>11632.809570</td>\n",
              "      <td>11532.959961</td>\n",
              "      <td>4787600000</td>\n",
              "      <td>11532.959961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-14</th>\n",
              "      <td>11744.330078</td>\n",
              "      <td>11399.839844</td>\n",
              "      <td>11532.070312</td>\n",
              "      <td>11615.929688</td>\n",
              "      <td>4064000000</td>\n",
              "      <td>11615.929688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    High           Low  ...      Volume     Adj Close\n",
              "2008-08-08  11808.490234  11344.230469  ...  4966810000  11734.320312\n",
              "2008-08-11  11933.549805  11580.190430  ...  5067310000  11782.349609\n",
              "2008-08-12  11830.389648  11541.429688  ...  4711290000  11642.469727\n",
              "2008-08-13  11689.049805  11377.370117  ...  4787600000  11532.959961\n",
              "2008-08-14  11744.330078  11399.839844  ...  4064000000  11615.929688\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWWYe1PpdCK3"
      },
      "source": [
        "Először a dátumok ellenőzöm, hogy megegyeznek-e."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77SDqWWGdF31",
        "outputId": "60099718-3aa1-46e4-9f19-81fd76857ded"
      },
      "source": [
        "difference = []\r\n",
        "\r\n",
        "if len(df_combined) == len(df_stock):\r\n",
        "    print(\"The lengths are the same!\")\r\n",
        "\r\n",
        "for day in range(max(len(df_combined), len(df_stock))):\r\n",
        "    if str(df_combined.index[day]) != str(df_stock.index[day]):\r\n",
        "        print(\"There is difference at: \" + str(day) + \" index\")\r\n",
        "        print(\"News: \" + str(df_combined.index[day]) + \"\\tStock: \" + str(df_stock.index[day]))\r\n",
        "        difference.append(day)\r\n",
        "\r\n",
        "if len(difference) is 0:\r\n",
        "    print(\"The dates matched!\")"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The lengths are the same!\n",
            "The dates matched!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJogdlwsjJm3"
      },
      "source": [
        "A labelek ellenőrzése."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyySRYjNjLwt",
        "outputId": "827a7967-f81e-4976-89e2-07bf0a3838ca"
      },
      "source": [
        "difference = []\r\n",
        "\r\n",
        "for day in range(len(df_stock)):\r\n",
        "    # label should be 1 -> rise\r\n",
        "    if int(df_stock[\"Adj Close\"][day]) >= int(df_stock[\"Adj Close\"][day - 1]):\r\n",
        "        if df_combined[\"Label\"][day] != 1:\r\n",
        "            difference.append(str(df_stock.index[day]))\r\n",
        "            print(\"Problem at day \" + str(df_stock.index[day]))\r\n",
        "            print(\"Today: \" + str(df_stock[\"Adj Close\"][day]) +\"\\t\\tYesterday: \" + str(df_stock[\"Adj Close\"][day - 1]) + \"\\t\\tLabel: \" + str(df_combined[\"Label\"][day]) + \"\\n\")\r\n",
        "\r\n",
        "    # label should be 0 -> fall\r\n",
        "    if int(df_stock[\"Adj Close\"][day]) < int(df_stock[\"Adj Close\"][day - 1]):\r\n",
        "        if df_combined[\"Label\"][day] != 0:\r\n",
        "            difference.append(str(df_stock.index[day]))\r\n",
        "            print(\"Problem at day \" + str(df_stock.index[day]))\r\n",
        "            print(\"Today: \" + str(df_stock[\"Adj Close\"][day]) +\"\\t\\tYesterday: \" + str(df_stock[\"Adj Close\"][day - 1]) + \"\\t\\tLabel: \" + str(df_combined[\"Label\"][day]) + \"\\n\")\r\n",
        "\r\n",
        "print(\"All differences: \" + str(len(difference)))      "
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Problem at day 2010-10-14\n",
            "Today: 11096.919921875\t\tYesterday: 11096.080078125\t\tLabel: 0\n",
            "\n",
            "Problem at day 2012-11-12\n",
            "Today: 12815.080078125\t\tYesterday: 12815.3896484375\t\tLabel: 0\n",
            "\n",
            "Problem at day 2012-11-15\n",
            "Today: 12570.9501953125\t\tYesterday: 12570.9501953125\t\tLabel: 0\n",
            "\n",
            "Problem at day 2013-04-12\n",
            "Today: 14865.0595703125\t\tYesterday: 14865.1396484375\t\tLabel: 0\n",
            "\n",
            "Problem at day 2014-04-24\n",
            "Today: 16501.650390625\t\tYesterday: 16501.650390625\t\tLabel: 0\n",
            "\n",
            "Problem at day 2015-08-12\n",
            "Today: 17402.509765625\t\tYesterday: 17402.83984375\t\tLabel: 0\n",
            "\n",
            "Problem at day 2015-11-27\n",
            "Today: 17813.390625\t\tYesterday: 17813.390625\t\tLabel: 0\n",
            "\n",
            "All differences: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOI1OZJPU6Wh"
      },
      "source": [
        "Látható, hogy rossz a label pár helyen. Egy kis kutakodás után megtaláltam, hogy maga az árfolyam lekérdezésük volt hibás pár nap esetében, ezért ezeket javítom, majd elmentem a drive-omon a javítottat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHvqT2FRtBkW",
        "outputId": "8c166236-01c4-4972-f443-83a456f76639"
      },
      "source": [
        "# correct the wrong labels\r\n",
        "for row in difference:\r\n",
        "    if df_combined.loc[row, \"Label\"] == 0:\r\n",
        "        df_combined.loc[row, \"Label\"] = 1\r\n",
        "    else:\r\n",
        "        df_combined.loc[row, \"Label\"] = 0\r\n",
        "\r\n",
        "# check them\r\n",
        "for row in difference:\r\n",
        "    print(str(row) + \"\\t\\t\" + str(df_combined.loc[row, \"Label\"]))"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2010-10-14\t\t1\n",
            "2012-11-12\t\t1\n",
            "2012-11-15\t\t1\n",
            "2013-04-12\t\t1\n",
            "2014-04-24\t\t1\n",
            "2015-08-12\t\t1\n",
            "2015-11-27\t\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTIqNqucuiBO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "b512d283-69e4-493b-8dce-78347223e734"
      },
      "source": [
        "# save to drive\r\n",
        "df_combined.to_csv('drive/MyDrive/Kaggle dataset/Reddit Top 25 DJIA/KAG_REDDIT_WRLD_DJIA_DF_corrected.csv')\r\n",
        "\r\n",
        "# Show the dataset\r\n",
        "df_combined.head()"
      ],
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Top1</th>\n",
              "      <th>Top2</th>\n",
              "      <th>Top3</th>\n",
              "      <th>Top4</th>\n",
              "      <th>Top5</th>\n",
              "      <th>Top6</th>\n",
              "      <th>Top7</th>\n",
              "      <th>Top8</th>\n",
              "      <th>Top9</th>\n",
              "      <th>Top10</th>\n",
              "      <th>Top11</th>\n",
              "      <th>Top12</th>\n",
              "      <th>Top13</th>\n",
              "      <th>Top14</th>\n",
              "      <th>Top15</th>\n",
              "      <th>Top16</th>\n",
              "      <th>Top17</th>\n",
              "      <th>Top18</th>\n",
              "      <th>Top19</th>\n",
              "      <th>Top20</th>\n",
              "      <th>Top21</th>\n",
              "      <th>Top22</th>\n",
              "      <th>Top23</th>\n",
              "      <th>Top24</th>\n",
              "      <th>Top25</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-08-08</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
              "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
              "      <td>b'Russian tanks are moving towards the capital...</td>\n",
              "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
              "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
              "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
              "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
              "      <td>b'Georgian troops retreat from S. Osettain cap...</td>\n",
              "      <td>b'Did the U.S. Prep Georgia for War with Russia?'</td>\n",
              "      <td>b'Rice Gives Green Light for Israel to Attack ...</td>\n",
              "      <td>b'Announcing:Class Action Lawsuit on Behalf of...</td>\n",
              "      <td>b\"So---Russia and Georgia are at war and the N...</td>\n",
              "      <td>b\"China tells Bush to stay out of other countr...</td>\n",
              "      <td>b'Did World War III start today?'</td>\n",
              "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
              "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
              "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
              "      <td>b'This is a busy day:  The European Union has ...</td>\n",
              "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
              "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
              "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
              "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
              "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
              "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-11</th>\n",
              "      <td>1</td>\n",
              "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
              "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
              "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
              "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
              "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
              "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
              "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
              "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
              "      <td>b'Welcome To World War IV! Now In High Definit...</td>\n",
              "      <td>b\"Georgia's move, a mistake of monumental prop...</td>\n",
              "      <td>b'Russia presses deeper into Georgia; U.S. say...</td>\n",
              "      <td>b'Abhinav Bindra wins first ever Individual Ol...</td>\n",
              "      <td>b' U.S. ship heads for Arctic to define territ...</td>\n",
              "      <td>b'Drivers in a Jerusalem taxi station threaten...</td>\n",
              "      <td>b'The French Team is Stunned by Phelps and the...</td>\n",
              "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
              "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
              "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
              "      <td>b'China to overtake US as largest manufacturer'</td>\n",
              "      <td>b'War in South Ossetia [PICS]'</td>\n",
              "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
              "      <td>b' Russia has just beaten the United States ov...</td>\n",
              "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
              "      <td>b'Russia is so much better at war'</td>\n",
              "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-12</th>\n",
              "      <td>0</td>\n",
              "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
              "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
              "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
              "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
              "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
              "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
              "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
              "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
              "      <td>b\"The US military was surprised by the timing ...</td>\n",
              "      <td>b'U.S. Beats War Drum as Iran Dumps the Dollar'</td>\n",
              "      <td>b'Gorbachev: \"Georgian military attacked the S...</td>\n",
              "      <td>b'CNN use footage of Tskhinvali ruins to cover...</td>\n",
              "      <td>b'Beginning a war as the Olympics were opening...</td>\n",
              "      <td>b'55 pyramids as large as the Luxor stacked in...</td>\n",
              "      <td>b'The 11 Top Party Cities in the World'</td>\n",
              "      <td>b'U.S. troops still in Georgia (did you know t...</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
              "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
              "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
              "      <td>b'War in Georgia: The Israeli connection'</td>\n",
              "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
              "      <td>b'Christopher King argues that the US and NATO...</td>\n",
              "      <td>b'America: The New Mexico?'</td>\n",
              "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-13</th>\n",
              "      <td>0</td>\n",
              "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
              "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
              "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
              "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
              "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
              "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
              "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
              "      <td>b'Russian forces sink Georgian ships '</td>\n",
              "      <td>b\"The commander of a Navy air reconnaissance s...</td>\n",
              "      <td>b\"92% of CNN readers: Russia's actions in Geor...</td>\n",
              "      <td>b'USA to send fleet into Black Sea to help Geo...</td>\n",
              "      <td>b\"US warns against Israeli plan to strike agai...</td>\n",
              "      <td>b\"In an intriguing cyberalliance, two Estonian...</td>\n",
              "      <td>b'The CNN Effect: Georgia Schools Russia in In...</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Elephants extinct by 2020?'</td>\n",
              "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
              "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
              "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
              "      <td>b'Israeli defence minister: US against strike ...</td>\n",
              "      <td>b'Gorbachev: We Had No Choice'</td>\n",
              "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
              "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
              "      <td>b'Georgian president  says US military will ta...</td>\n",
              "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-14</th>\n",
              "      <td>1</td>\n",
              "      <td>b'All the experts admit that we should legalis...</td>\n",
              "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
              "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
              "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
              "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
              "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
              "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
              "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
              "      <td>b'Russia exaggerating South Ossetian death tol...</td>\n",
              "      <td>b' Musharraf expected to resign rather than fa...</td>\n",
              "      <td>b'Moscow Made Plans Months Ago to Invade Georgia'</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Nigeria has handed over the potentially oil-...</td>\n",
              "      <td>b'The US and Poland have agreed a preliminary ...</td>\n",
              "      <td>b'Russia apparently is sabotaging infrastructu...</td>\n",
              "      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n",
              "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
              "      <td>b'War in the Caucasus is as much the product o...</td>\n",
              "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
              "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
              "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
              "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
              "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
              "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
              "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Label  ...                                              Top25\n",
              "Date               ...                                                   \n",
              "2008-08-08      0  ...           b\"No Help for Mexico's Kidnapping Surge\"\n",
              "2008-08-11      1  ...  b\"So this is what it's come to: trading sex fo...\n",
              "2008-08-12      0  ...  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...\n",
              "2008-08-13      0  ...  b'2006: Nobel laureate Aleksander Solzhenitsyn...\n",
              "2008-08-14      1  ...  b'Philippines : Peace Advocate say Muslims nee...\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAhg7d5Xj2kt"
      },
      "source": [
        "A következőkben az esetleges adat nélküli napokat, illetve cellákat keresem meg és helyettesítem őket egy üres sztringgel. Ez a későbbi szövegfeldolgozás hibamentességéhez szükséges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrFufwo6j5_H"
      },
      "source": [
        "# Find the cells with NaN and after the rows for them\r\n",
        "is_NaN = df_combined.isnull()\r\n",
        "row_has_NaN = is_NaN.any(axis = 1)\r\n",
        "rows_with_NaN = df_combined[row_has_NaN]\r\n",
        "\r\n",
        "# Replace them\r\n",
        "df_combined = df_combined.replace(np.nan, \" \")\r\n",
        "\r\n",
        "# Check the process\r\n",
        "is_NaN = df_combined.isnull()\r\n",
        "row_has_NaN = is_NaN.any(axis = 1)\r\n",
        "rows_with_NaN = df_combined[row_has_NaN]\r\n",
        "\r\n",
        "assert len(rows_with_NaN) is 0"
      ],
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxCOud0ki5M-"
      },
      "source": [
        "Ezek után az egy naphoz tartozó híreket közös sztringekbe fűzöm. Az egy sztringbe tartozó hírek számát makróval definiálom:\r\n",
        "\r\n",
        "\r\n",
        "*   ROWS - egymásba fűzött hírek száma\r\n",
        "\r\n",
        "Itt megtalálható már az első előkészítő algoritmusom, méghozzá a sztringek elején található b karakter eltávolítása."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqv3bDcAi6Bf",
        "outputId": "614472e1-7951-494a-d165-4ff12ed12bfa"
      },
      "source": [
        "# Get column names\r\n",
        "combined_column_names = []\r\n",
        "for column in df_combined.columns:\r\n",
        "  combined_column_names.append(column)\r\n",
        "\r\n",
        "# 2D array creation for the news based on macros\r\n",
        "COLUMNS = len(df_combined)\r\n",
        "news_sum = [[0 for i in range(COLUMNS)] for j in range(int((len(combined_column_names) - 1) / ROWS))]  \r\n",
        "\r\n",
        "# Show the column names\r\n",
        "print(\"Column names of the dataset:\") \r\n",
        "print(combined_column_names)\r\n",
        "\r\n",
        "# Merge the news\r\n",
        "for row in range(len(df_combined)):\r\n",
        "  for column in range(int((len(combined_column_names) - 1) / ROWS)):\r\n",
        "    temp = \"\"\r\n",
        "    news = \"\"\r\n",
        "    for word in range(ROWS):\r\n",
        "      news = df_combined[combined_column_names[(column * ROWS) + (word + 1)]][row]\r\n",
        "      # Remove the b character at the begining of the string\r\n",
        "      if news[0] is \"b\":\r\n",
        "        news = \" \" + news[1:]\r\n",
        "      temp = temp + news\r\n",
        "    news_sum[column][row] = temp\r\n",
        "\r\n",
        "# Show the first day second package of the news\r\n",
        "print(\"\\nThe first day second package of the news:\")\r\n",
        "print(news_sum[1][0])"
      ],
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column names of the dataset:\n",
            "['Label', 'Top1', 'Top2', 'Top3', 'Top4', 'Top5', 'Top6', 'Top7', 'Top8', 'Top9', 'Top10', 'Top11', 'Top12', 'Top13', 'Top14', 'Top15', 'Top16', 'Top17', 'Top18', 'Top19', 'Top20', 'Top21', 'Top22', 'Top23', 'Top24', 'Top25']\n",
            "\n",
            "The first day second package of the news:\n",
            " 'Russia Today: Columns of troops roll into South Ossetia; footage from fighting (YouTube)' 'Russian tanks are moving towards the capital of South Ossetia, which has reportedly been completely destroyed by Georgian artillery fire'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvOqG6vckIcF"
      },
      "source": [
        "Ezek után a korábbi oszlopokat(Top1, Top2...) kicserélem a csoportosításnak megfelelő számú oszlopokra és nevekre (News_1, News_2...), majd feltöltöm őket az összevont hírcsomagokkal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "xljXPUwmkKrZ",
        "outputId": "312e082f-5715-4fba-b33c-902018f8944b"
      },
      "source": [
        "# Drop the old columns\r\n",
        "for column in range(len(combined_column_names) - 1):\r\n",
        "  df_combined.drop(combined_column_names[column + 1], axis = 1, inplace = True)\r\n",
        "\r\n",
        "# Create the new columns with the merged news\r\n",
        "for column in range(int((len(combined_column_names) - 1) / ROWS)):\r\n",
        "  colum_name = \"News_\" + str(column + 1)\r\n",
        "  df_combined[colum_name] = news_sum[column]\r\n",
        "\r\n",
        "# Show the DataFrame\r\n",
        "df_combined.head()"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News_1</th>\n",
              "      <th>News_2</th>\n",
              "      <th>News_3</th>\n",
              "      <th>News_4</th>\n",
              "      <th>News_5</th>\n",
              "      <th>News_6</th>\n",
              "      <th>News_7</th>\n",
              "      <th>News_8</th>\n",
              "      <th>News_9</th>\n",
              "      <th>News_10</th>\n",
              "      <th>News_11</th>\n",
              "      <th>News_12</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-08-08</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "      <td>'Russia Today: Columns of troops roll into So...</td>\n",
              "      <td>\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
              "      <td>\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
              "      <td>'Georgian troops retreat from S. Osettain cap...</td>\n",
              "      <td>'Rice Gives Green Light for Israel to Attack ...</td>\n",
              "      <td>\"So---Russia and Georgia are at war and the N...</td>\n",
              "      <td>'Did World War III start today?' 'Georgia Inv...</td>\n",
              "      <td>'Al-Qaeda Faces Islamist Backlash' 'Condoleez...</td>\n",
              "      <td>'This is a busy day:  The European Union has ...</td>\n",
              "      <td>'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
              "      <td>'Indian shoe manufactory  - And again in a se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-11</th>\n",
              "      <td>1</td>\n",
              "      <td>'Why wont America and Nato help us? If they w...</td>\n",
              "      <td>\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
              "      <td>\"Olympic opening ceremony fireworks 'faked'\" ...</td>\n",
              "      <td>'Russia angered by Israeli military sale to G...</td>\n",
              "      <td>'Welcome To World War IV! Now In High Definit...</td>\n",
              "      <td>'Russia presses deeper into Georgia; U.S. say...</td>\n",
              "      <td>' U.S. ship heads for Arctic to define territ...</td>\n",
              "      <td>'The French Team is Stunned by Phelps and the...</td>\n",
              "      <td>'\"Do not believe TV, neither Russian nor Geor...</td>\n",
              "      <td>'China to overtake US as largest manufacturer...</td>\n",
              "      <td>'Israeli Physicians Group Condemns State Tort...</td>\n",
              "      <td>'Perhaps *the* question about the Georgia - R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-12</th>\n",
              "      <td>0</td>\n",
              "      <td>'Remember that adorable 9-year-old who sang a...</td>\n",
              "      <td>'\"If we had no sexual harassment we would hav...</td>\n",
              "      <td>'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
              "      <td>'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
              "      <td>\"The US military was surprised by the timing ...</td>\n",
              "      <td>'Gorbachev: \"Georgian military attacked the S...</td>\n",
              "      <td>'Beginning a war as the Olympics were opening...</td>\n",
              "      <td>'The 11 Top Party Cities in the World' 'U.S. ...</td>\n",
              "      <td>'Why Russias response to Georgia was right' '...</td>\n",
              "      <td>'Russia, Georgia, and NATO: Cold War Two' 'Re...</td>\n",
              "      <td>'War in Georgia: The Israeli connection' 'All...</td>\n",
              "      <td>'Christopher King argues that the US and NATO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-13</th>\n",
              "      <td>0</td>\n",
              "      <td>' U.S. refuses Israel weapons to attack Iran:...</td>\n",
              "      <td>' Israel clears troops who killed Reuters cam...</td>\n",
              "      <td>'Body of 14 year old found in trunk; Latest (...</td>\n",
              "      <td>\"Bush announces Operation Get All Up In Russi...</td>\n",
              "      <td>\"The commander of a Navy air reconnaissance s...</td>\n",
              "      <td>'USA to send fleet into Black Sea to help Geo...</td>\n",
              "      <td>\"In an intriguing cyberalliance, two Estonian...</td>\n",
              "      <td>'Why Russias response to Georgia was right' '...</td>\n",
              "      <td>'US humanitarian missions soon in Georgia - i...</td>\n",
              "      <td>'Russian convoy heads into Georgia, violating...</td>\n",
              "      <td>'Gorbachev: We Had No Choice' 'Witness: Russi...</td>\n",
              "      <td>' Quarter of Russians blame U.S. for conflict...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-14</th>\n",
              "      <td>1</td>\n",
              "      <td>'All the experts admit that we should legalis...</td>\n",
              "      <td>'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
              "      <td>'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
              "      <td>'Poland and US agree to missle defense deal. ...</td>\n",
              "      <td>'Russia exaggerating South Ossetian death tol...</td>\n",
              "      <td>'Moscow Made Plans Months Ago to Invade Georg...</td>\n",
              "      <td>'Nigeria has handed over the potentially oil-...</td>\n",
              "      <td>'Russia apparently is sabotaging infrastructu...</td>\n",
              "      <td>\"Georgia confict could set back Russia's US r...</td>\n",
              "      <td>'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
              "      <td>'Saudi Arabia: Mother moves to block child ma...</td>\n",
              "      <td>'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Label  ...                                            News_12\n",
              "Date               ...                                                   \n",
              "2008-08-08      0  ...   'Indian shoe manufactory  - And again in a se...\n",
              "2008-08-11      1  ...   'Perhaps *the* question about the Georgia - R...\n",
              "2008-08-12      0  ...   'Christopher King argues that the US and NATO...\n",
              "2008-08-13      0  ...   ' Quarter of Russians blame U.S. for conflict...\n",
              "2008-08-14      1  ...   'Russia: World  \"can forget about\" Georgia\\'s...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Gmqmlpkqhm"
      },
      "source": [
        "Egy új dataframebe újracsoportosítom a hír blokkokat a címkéjükkel, már a dátumok nélkül."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "YoeoCzPekrN2",
        "outputId": "7a95ed55-bdb4-43ab-b2bb-ab79a89a8746"
      },
      "source": [
        "# The label column \r\n",
        "LABEL_COLUMN = 0\r\n",
        "\r\n",
        "news_sum = []\r\n",
        "label_sum = []\r\n",
        "\r\n",
        "# Get the column names\r\n",
        "combined_column_names = []\r\n",
        "for column in df_combined.columns:\r\n",
        "  combined_column_names.append(column)\r\n",
        "\r\n",
        "# Write out the column names \r\n",
        "print(combined_column_names)\r\n",
        "print(\"\\n\")\r\n",
        "\r\n",
        "# Connect the merged news with the labels\r\n",
        "for column in range(len(df_combined)):\r\n",
        "  for row in range(len(combined_column_names) - 1):\r\n",
        "    news_sum.append(df_combined[combined_column_names[row + 1]][column])\r\n",
        "    label_sum.append(df_combined[combined_column_names[LABEL_COLUMN]][column])\r\n",
        "\r\n",
        "# Create the new DataFrame\r\n",
        "df_sum_news_labels = pd.DataFrame(data = label_sum, index = None, columns = [\"Label\"])\r\n",
        "df_sum_news_labels[\"News\"] = news_sum\r\n",
        "\r\n",
        "# Show it\r\n",
        "df_sum_news_labels.head()"
      ],
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Label', 'News_1', 'News_2', 'News_3', 'News_4', 'News_5', 'News_6', 'News_7', 'News_8', 'News_9', 'News_10', 'News_11', 'News_12']\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>'Russia Today: Columns of troops roll into So...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>'Georgian troops retreat from S. Osettain cap...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label                                               News\n",
              "0      0   \"Georgia 'downs two Russian warplanes' as cou...\n",
              "1      0   'Russia Today: Columns of troops roll into So...\n",
              "2      0   \"Afghan children raped with 'impunity,' U.N. ...\n",
              "3      0   \"Breaking: Georgia invades South Ossetia, Rus...\n",
              "4      0   'Georgian troops retreat from S. Osettain cap..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 349
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYQSgwmslqkO"
      },
      "source": [
        "Először a szövegek előfeldolgozásával kezdem: írásjelek eltávolítása, számok eltávolítása, felesleges szóközök eltávolítása, aztán minden szót kis kezdőbetűjü szóvá konvertálom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "YJT565FZlsgZ",
        "outputId": "11b3808c-d8db-41c0-faa1-63320e7ac4ee"
      },
      "source": [
        "# Removing punctuations\r\n",
        "temp_news = []\r\n",
        "for line in news_sum:\r\n",
        "  temp_attach = \"\"\r\n",
        "  for word in line:\r\n",
        "    temp = \" \"\r\n",
        "    if word not in string.punctuation:\r\n",
        "      temp = word\r\n",
        "    temp_attach = temp_attach + \"\".join(temp)\r\n",
        "  temp_news.append(temp_attach)\r\n",
        "\r\n",
        "news_sum = temp_news\r\n",
        "temp_news = []\r\n",
        "\r\n",
        "# Remove numbers\r\n",
        "for line in news_sum:\r\n",
        "  temp_attach = \"\"\r\n",
        "  for word in line:\r\n",
        "    temp = \" \"\r\n",
        "    if not word.isdigit():\r\n",
        "      temp = word\r\n",
        "    temp_attach = temp_attach + \"\".join(temp)\r\n",
        "  temp_news.append(temp_attach)\r\n",
        "\r\n",
        "# Remove space\r\n",
        "for line in range(len(temp_news)):    \r\n",
        "  temp_news[line] = \" \".join(temp_news[line].split())\r\n",
        "\r\n",
        "# Converting headlines to lower case\r\n",
        "for line in range(len(temp_news)): \r\n",
        "    temp_news[line] = temp_news[line].lower()\r\n",
        "\r\n",
        "# Update the data frame\r\n",
        "df_sum_news_labels[\"News\"] = temp_news\r\n",
        "\r\n",
        "# Show it\r\n",
        "df_sum_news_labels.head()"
      ],
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>georgia downs two russian warplanes as countri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>russia today columns of troops roll into south...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>afghan children raped with impunity u n offici...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>breaking georgia invades south ossetia russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>georgian troops retreat from s osettain capita...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label                                               News\n",
              "0      0  georgia downs two russian warplanes as countri...\n",
              "1      0  russia today columns of troops roll into south...\n",
              "2      0  afghan children raped with impunity u n offici...\n",
              "3      0  breaking georgia invades south ossetia russia ...\n",
              "4      0  georgian troops retreat from s osettain capita..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkCvCsvel989"
      },
      "source": [
        "A következőkben az úgy nevezett töltelék szavakat (stop words) fogom eltávolítani."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "k3WjnHkAmA4e",
        "outputId": "01ebf7ec-8374-4175-8ed3-5b8e39b8ff5f"
      },
      "source": [
        "# Load the stop words\r\n",
        "stop_words = set(stopwords.words('english'))\r\n",
        "\r\n",
        "filtered_sentence = []\r\n",
        "news_sum = df_sum_news_labels[\"News\"]\r\n",
        "\r\n",
        "# Remove stop words\r\n",
        "for line in news_sum:\r\n",
        "  word_tokens = word_tokenize(line)\r\n",
        "  temp_attach = \"\"\r\n",
        "  for word in word_tokens:\r\n",
        "    temp = \" \"\r\n",
        "    if not word in stop_words:\r\n",
        "      temp = temp + word\r\n",
        "    temp_attach = temp_attach + \"\".join(temp)\r\n",
        "  filtered_sentence.append(temp_attach)\r\n",
        "\r\n",
        "# Remove space\r\n",
        "for line in range(len(filtered_sentence)):    \r\n",
        "  filtered_sentence[line] = \" \".join(filtered_sentence[line].split())\r\n",
        "\r\n",
        "# Update the data frame\r\n",
        "df_sum_news_labels[\"News\"] = filtered_sentence\r\n",
        "\r\n",
        "# Show the DataFrame\r\n",
        "df_sum_news_labels.head()"
      ],
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>georgia downs two russian warplanes countries ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>russia today columns troops roll south ossetia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>afghan children raped impunity u n official sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>breaking georgia invades south ossetia russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>georgian troops retreat osettain capital presu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label                                               News\n",
              "0      0  georgia downs two russian warplanes countries ...\n",
              "1      0  russia today columns troops roll south ossetia...\n",
              "2      0  afghan children raped impunity u n official sa...\n",
              "3      0  breaking georgia invades south ossetia russia ...\n",
              "4      0  georgian troops retreat osettain capital presu..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 351
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1DHwHi3mbDn"
      },
      "source": [
        "Az adathalmazban lévő nulla hosszú sztring csomagok megkeresése és a hozzájuk tartozó cellák törlése következik."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUqfwAe1mbqM",
        "outputId": "a0a824bf-7828-4eed-b1c2-699f5de44ef7"
      },
      "source": [
        "news_sum = df_sum_news_labels[\"News\"]\r\n",
        "null_indexes = []\r\n",
        "index = 0\r\n",
        "\r\n",
        "for line in news_sum:\r\n",
        "  if line is \"\":\r\n",
        "    null_indexes.append(index)\r\n",
        "  index = index + 1\r\n",
        "\r\n",
        "print(null_indexes)\r\n",
        "\r\n",
        "for row in null_indexes:\r\n",
        "  df_sum_news_labels = df_sum_news_labels.drop(row)\r\n",
        "\r\n",
        "news_sum = df_sum_news_labels[\"News\"]\r\n",
        "null_indexes = []\r\n",
        "index = 0\r\n",
        "\r\n",
        "for line in news_sum:\r\n",
        "  if line is \"\":\r\n",
        "    null_indexes.append(index)\r\n",
        "  index = index + 1\r\n",
        "  \r\n",
        "assert len(null_indexes) is 0"
      ],
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3335]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UW_rMpOmlSH"
      },
      "source": [
        "Az adathalmaz véletlenszerű sorbarendezése."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "FwdW_tECmlxs",
        "outputId": "3266b199-c0d6-473c-8c69-3fd387b10f2d"
      },
      "source": [
        "# Do the shuffle\r\n",
        "for i in range(SHUFFLE_CYCLE):\r\n",
        "  df_sum_news_labels = shuffle(df_sum_news_labels, random_state = rs)\r\n",
        "\r\n",
        "# Reset the index\r\n",
        "df_sum_news_labels.reset_index(inplace=True, drop=True)\r\n",
        "\r\n",
        "# Show the data frame\r\n",
        "df_sum_news_labels.head()"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>israel stole b palestinian workers israeli eco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>sec state john kerry russia lying face troops ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>mining company idemitsu australia resources ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>pirate party fires broadside german political ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>cairo court gives death penalty egyptian chris...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label                                               News\n",
              "0      0  israel stole b palestinian workers israeli eco...\n",
              "1      1  sec state john kerry russia lying face troops ...\n",
              "2      0  mining company idemitsu australia resources ad...\n",
              "3      0  pirate party fires broadside german political ...\n",
              "4      1  cairo court gives death penalty egyptian chris..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9cUBq_WnJbH"
      },
      "source": [
        "Az adathalmaz szétbontása tanító és validáló/tesztelő adathalmazokra, majd a szétbontás ellenőrzése mérettel és első elem kiíratásával."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-Mg2z7LnKH1",
        "outputId": "dfc2c9d8-ab9f-4c35-9bce-a08a8b6398ea"
      },
      "source": [
        "INPUT_SIZE = len(df_sum_news_labels)\r\n",
        "TRAIN_SIZE = int(TRAIN_SPLIT * INPUT_SIZE) \r\n",
        "TEST_SIZE = int(TEST_SPLIT * INPUT_SIZE)\r\n",
        "\r\n",
        "# Split the dataset\r\n",
        "train = df_sum_news_labels[:TRAIN_SIZE] \r\n",
        "test = df_sum_news_labels[TRAIN_SIZE:]\r\n",
        "\r\n",
        "# Print out the length\r\n",
        "print(\"Train data set length: \" + str(len(train)))\r\n",
        "print(\"Test data set length: \" + str(len(test)))\r\n",
        "print(\"Split summa: \" + str(len(train) + len(test)))\r\n",
        "print(\"Dataset summa before split: \" + str(len(df_sum_news_labels)))\r\n",
        "\r\n",
        "# check\r\n",
        "split_sum = len(train) + len(test)\r\n",
        "sum = len(df_sum_news_labels)\r\n",
        "assert split_sum == sum"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data set length: 20286\n",
            "Test data set length: 3581\n",
            "Split summa: 23867\n",
            "Dataset summa before split: 23867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "s03PFsFQsgpS",
        "outputId": "f3ba4742-2cbc-43fc-ed40-27ed20ae30f6"
      },
      "source": [
        "train.tail(1)"
      ],
      "execution_count": 355,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20285</th>\n",
              "      <td>1</td>\n",
              "      <td>special forces raid bp moscow officespakistani...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Label                                               News\n",
              "20285      1  special forces raid bp moscow officespakistani..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 355
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "Au3VLLVzsh0U",
        "outputId": "417b5313-df97-4597-d6bb-ae3c4f045aa1"
      },
      "source": [
        "test.head(1)"
      ],
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20286</th>\n",
              "      <td>1</td>\n",
              "      <td>charlie hebdo pakistani legislators chant deat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Label                                               News\n",
              "20286      1  charlie hebdo pakistani legislators chant deat..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0H2KEdmsNJA"
      },
      "source": [
        "Ezek lementése."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVLjLPzzsRs4"
      },
      "source": [
        "# save to drive\r\n",
        "train.to_csv('drive/MyDrive/Kaggle dataset/Reddit Top 25 DJIA/train.csv')\r\n",
        "test.to_csv('drive/MyDrive/Kaggle dataset/Reddit Top 25 DJIA/test.csv')"
      ],
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRgA6S5muPbE"
      },
      "source": [
        "### Bag of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsDa53wcxRdG"
      },
      "source": [
        "Először a tanító adathalmaz híreit fűzöm össze egy tömbbe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "5RhOIEt3wmHn",
        "outputId": "5634ba26-413b-40a5-e35f-56144eb1f18d"
      },
      "source": [
        "train_headlines = []\r\n",
        "\r\n",
        "for row in range(0, len(train.index)):\r\n",
        "    train_headlines.append(train.iloc[row, 1])\r\n",
        "\r\n",
        "# show the first\r\n",
        "train_headlines[0]"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'israel stole b palestinian workers israeli economists revealed generose lay bleeding near husbands corpse soldiers cut amputated leg cooked pieces ordered children eat mothers flesh one son refused kill kill told soldiers mother remembers eat part mother'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 358
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83MuhLlOxYK5"
      },
      "source": [
        "Ezek után vektorizálom őket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N3hIvbQxgr6",
        "outputId": "199bdffa-bcb0-4e14-a950-591381af356b"
      },
      "source": [
        "bow_vectorizer = CountVectorizer()\r\n",
        "bow_train = bow_vectorizer.fit_transform(train_headlines)\r\n",
        "print(bow_train.shape)"
      ],
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20286, 38607)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExOpaN_Ix3r_"
      },
      "source": [
        "Egy logistic regression modellt fogok erre a tanító halmazra betanítani."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D36NSmICyOCC"
      },
      "source": [
        "bow_model = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "bow_model = bow_model.fit(bow_train, train[\"Label\"])"
      ],
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7EYr5_yygsr"
      },
      "source": [
        "A teszt adathalmaz előkészítése, majd becslés a modell segítségével a következő lépés."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkxsor9uygSa"
      },
      "source": [
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "bow_test = bow_vectorizer.transform(test_headlines)\r\n",
        "bow_predictions = bow_model.predict(bow_test)"
      ],
      "execution_count": 361,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFBYXRil2nS2"
      },
      "source": [
        "Az eredmények megjelenítése egy táblázatban."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "Vfgw4P9-2rkL",
        "outputId": "bc36858d-ade3-4fd3-f656-d55f932215fe"
      },
      "source": [
        "pd.crosstab(test[\"Label\"], bow_predictions, rownames=[\"Actual\"], colnames=[\"Predicted\"])"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>722</td>\n",
              "      <td>895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>856</td>\n",
              "      <td>1108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted    0     1\n",
              "Actual              \n",
              "0          722   895\n",
              "1          856  1108"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9uWaAGm3E_J"
      },
      "source": [
        "A pontossága a modellnek."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHxtBIe23HqK",
        "outputId": "b00d79a7-971a-4b94-d2d2-51f4a8a18d86"
      },
      "source": [
        "print (classification_report(test[\"Label\"], bow_predictions))\r\n",
        "print (accuracy_score(test[\"Label\"], bow_predictions))\r\n",
        "\r\n",
        "result.append(accuracy_score(test[\"Label\"], bow_predictions))"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQZQqPar4Im8"
      },
      "source": [
        "A következőkben a top 10 legbefolyásolóbb sztringet jelenítem meg mind pozítiv és mind negatív irányba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "oveqbdwt4Q-9",
        "outputId": "05246602-c5e4-4f34-d5ff-58a014a27f6d"
      },
      "source": [
        "bow_words = bow_vectorizer.get_feature_names()\r\n",
        "bow_coeffs = bow_model.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : bow_words, \r\n",
        "                        'Coefficient' : bow_coeffs})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "coeffdf.head(10)"
      ],
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37860</th>\n",
              "      <td>wolves</td>\n",
              "      <td>1.575139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34454</th>\n",
              "      <td>thriving</td>\n",
              "      <td>1.555963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18822</th>\n",
              "      <td>landing</td>\n",
              "      <td>1.423610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29746</th>\n",
              "      <td>sanaa</td>\n",
              "      <td>1.413760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29141</th>\n",
              "      <td>riyadh</td>\n",
              "      <td>1.389342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9779</th>\n",
              "      <td>division</td>\n",
              "      <td>1.387358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6402</th>\n",
              "      <td>collection</td>\n",
              "      <td>1.378622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20284</th>\n",
              "      <td>manipulate</td>\n",
              "      <td>1.356852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21932</th>\n",
              "      <td>movies</td>\n",
              "      <td>1.354048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6072</th>\n",
              "      <td>clashed</td>\n",
              "      <td>1.340151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Word  Coefficient\n",
              "37860      wolves     1.575139\n",
              "34454    thriving     1.555963\n",
              "18822     landing     1.423610\n",
              "29746       sanaa     1.413760\n",
              "29141      riyadh     1.389342\n",
              "9779     division     1.387358\n",
              "6402   collection     1.378622\n",
              "20284  manipulate     1.356852\n",
              "21932      movies     1.354048\n",
              "6072      clashed     1.340151"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "EKPketqV4uVw",
        "outputId": "a018ff0c-d158-433c-df3c-77b039254f42"
      },
      "source": [
        "coeffdf.tail(10)"
      ],
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15686</th>\n",
              "      <td>horns</td>\n",
              "      <td>-1.304928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25589</th>\n",
              "      <td>player</td>\n",
              "      <td>-1.329162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32153</th>\n",
              "      <td>spilled</td>\n",
              "      <td>-1.333695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25317</th>\n",
              "      <td>picked</td>\n",
              "      <td>-1.342825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5847</th>\n",
              "      <td>choppers</td>\n",
              "      <td>-1.347697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7215</th>\n",
              "      <td>contributed</td>\n",
              "      <td>-1.354432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3140</th>\n",
              "      <td>begging</td>\n",
              "      <td>-1.359860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15680</th>\n",
              "      <td>hormuz</td>\n",
              "      <td>-1.365731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20925</th>\n",
              "      <td>merchant</td>\n",
              "      <td>-1.407644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>census</td>\n",
              "      <td>-1.428086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Word  Coefficient\n",
              "15686        horns    -1.304928\n",
              "25589       player    -1.329162\n",
              "32153      spilled    -1.333695\n",
              "25317       picked    -1.342825\n",
              "5847      choppers    -1.347697\n",
              "7215   contributed    -1.354432\n",
              "3140       begging    -1.359860\n",
              "15680       hormuz    -1.365731\n",
              "20925     merchant    -1.407644\n",
              "5372        census    -1.428086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytoEWvZ_48_x"
      },
      "source": [
        "### 2-gram modell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_11F44gu5TdJ"
      },
      "source": [
        "Hasonlóan az eddigiekhez vektorizálom a tanító adathalmazom, logistic regression modellt illesztek rá, becslést hajtok végre majd kiértékelem az eredményeket. Először a (1,2) n-gram modellel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1reDgLAU5jQd",
        "outputId": "a14a35f8-4e7e-42fa-dbf7-f3b6f750035e"
      },
      "source": [
        "gram_vectorizer_12 = CountVectorizer(ngram_range=(1,2))\r\n",
        "train_vectorizer_12 = gram_vectorizer_12.fit_transform(train_headlines)\r\n",
        "\r\n",
        "print(train_vectorizer_12.shape)\r\n",
        "\r\n",
        "gram_model_12 = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "gram_model_12 = gram_model_12.fit(train_vectorizer_12, train[\"Label\"])\r\n",
        "\r\n",
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "gram_test_12 = gram_vectorizer_12.transform(test_headlines)\r\n",
        "gram_predictions_12 = gram_model_12.predict(gram_test_12)\r\n",
        "\r\n",
        "pd.crosstab(test[\"Label\"], gram_predictions_12, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "print (classification_report(test[\"Label\"], gram_predictions_12))\r\n",
        "print (accuracy_score(test[\"Label\"], gram_predictions_12))\r\n",
        "\r\n",
        "result.append(accuracy_score(test[\"Label\"], gram_predictions_12))"
      ],
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20286, 387915)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "t_JxbXWM7wss",
        "outputId": "3f55fd4f-ea30-4c87-98b8-cbd6b1d50a13"
      },
      "source": [
        "gram_words_12 = gram_vectorizer_12.get_feature_names()\r\n",
        "gram_coeffs_12 = gram_model_12.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : gram_words_12, \r\n",
        "                        'Coefficient' : gram_coeffs_12})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "coeffdf.head(10)"
      ],
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>189169</th>\n",
              "      <td>landing</td>\n",
              "      <td>0.985440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304143</th>\n",
              "      <td>security council</td>\n",
              "      <td>0.930576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222340</th>\n",
              "      <td>mumbai</td>\n",
              "      <td>0.868996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379692</th>\n",
              "      <td>wolves</td>\n",
              "      <td>0.841094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308844</th>\n",
              "      <td>sexual violence</td>\n",
              "      <td>0.835806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341463</th>\n",
              "      <td>terror attack</td>\n",
              "      <td>0.826805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202341</th>\n",
              "      <td>luxury</td>\n",
              "      <td>0.812963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305226</th>\n",
              "      <td>seize</td>\n",
              "      <td>0.812070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45967</th>\n",
              "      <td>buildings</td>\n",
              "      <td>0.791482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>abroad</td>\n",
              "      <td>0.788123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Word  Coefficient\n",
              "189169           landing     0.985440\n",
              "304143  security council     0.930576\n",
              "222340            mumbai     0.868996\n",
              "379692            wolves     0.841094\n",
              "308844   sexual violence     0.835806\n",
              "341463     terror attack     0.826805\n",
              "202341            luxury     0.812963\n",
              "305226             seize     0.812070\n",
              "45967          buildings     0.791482\n",
              "817               abroad     0.788123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "g96l9WK57xMH",
        "outputId": "aadf87b1-4ba9-4f0d-ec7c-2c40fc9f23eb"
      },
      "source": [
        "coeffdf.tail(10)"
      ],
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33163</th>\n",
              "      <td>begin</td>\n",
              "      <td>-0.780491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327730</th>\n",
              "      <td>stranded</td>\n",
              "      <td>-0.785083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325355</th>\n",
              "      <td>statistics</td>\n",
              "      <td>-0.797791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158709</th>\n",
              "      <td>hormuz</td>\n",
              "      <td>-0.809017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201819</th>\n",
              "      <td>low</td>\n",
              "      <td>-0.814543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55167</th>\n",
              "      <td>census</td>\n",
              "      <td>-0.841566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17177</th>\n",
              "      <td>appeal</td>\n",
              "      <td>-0.855236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227465</th>\n",
              "      <td>nepal</td>\n",
              "      <td>-0.893965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318316</th>\n",
              "      <td>somalia</td>\n",
              "      <td>-0.973756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362365</th>\n",
              "      <td>us army</td>\n",
              "      <td>-1.024815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Word  Coefficient\n",
              "33163        begin    -0.780491\n",
              "327730    stranded    -0.785083\n",
              "325355  statistics    -0.797791\n",
              "158709      hormuz    -0.809017\n",
              "201819         low    -0.814543\n",
              "55167       census    -0.841566\n",
              "17177       appeal    -0.855236\n",
              "227465       nepal    -0.893965\n",
              "318316     somalia    -0.973756\n",
              "362365     us army    -1.024815"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFrdv3Um9CoD"
      },
      "source": [
        "Másodjára a (2,2) n-gram modellel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IdZdzJl9Ftm",
        "outputId": "7fb628ee-c85f-41c4-edfc-9ab9dcd06f65"
      },
      "source": [
        "gram_vectorizer_22 = CountVectorizer(ngram_range=(2,2))\r\n",
        "train_vectorizer_22 = gram_vectorizer_22.fit_transform(train_headlines)\r\n",
        "\r\n",
        "print(train_vectorizer_22.shape)\r\n",
        "\r\n",
        "gram_model_22 = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "gram_model_22 = gram_model_22.fit(train_vectorizer_22, train[\"Label\"])\r\n",
        "\r\n",
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "gram_test_22 = gram_vectorizer_22.transform(test_headlines)\r\n",
        "gram_predictions_22 = gram_model_22.predict(gram_test_22)\r\n",
        "\r\n",
        "pd.crosstab(test[\"Label\"], gram_predictions_22, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "print (classification_report(test[\"Label\"], gram_predictions_22))\r\n",
        "print (accuracy_score(test[\"Label\"], gram_predictions_22))\r\n",
        "\r\n",
        "result.append(accuracy_score(test[\"Label\"], gram_predictions_22))"
      ],
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20286, 349308)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "snpLViV79GlO",
        "outputId": "40b78be5-e3d4-4acd-a88e-bad247bb4fe8"
      },
      "source": [
        "gram_words_22 = gram_vectorizer_22.get_feature_names()\r\n",
        "gram_coeffs_22 = gram_model_22.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : gram_words_22, \r\n",
        "                        'Coefficient' : gram_coeffs_22})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "coeffdf.head(10)"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>273713</th>\n",
              "      <td>security council</td>\n",
              "      <td>0.931506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261036</th>\n",
              "      <td>rights watch</td>\n",
              "      <td>0.907768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278130</th>\n",
              "      <td>sexual violence</td>\n",
              "      <td>0.873731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326960</th>\n",
              "      <td>us spying</td>\n",
              "      <td>0.796756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8109</th>\n",
              "      <td>air pollution</td>\n",
              "      <td>0.772872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1787</th>\n",
              "      <td>according new</td>\n",
              "      <td>0.771510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223688</th>\n",
              "      <td>peace deal</td>\n",
              "      <td>0.764626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209611</th>\n",
              "      <td>nuclear strike</td>\n",
              "      <td>0.755552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93315</th>\n",
              "      <td>eastern ukraine</td>\n",
              "      <td>0.727508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311763</th>\n",
              "      <td>time since</td>\n",
              "      <td>0.725524</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Word  Coefficient\n",
              "273713  security council     0.931506\n",
              "261036      rights watch     0.907768\n",
              "278130   sexual violence     0.873731\n",
              "326960         us spying     0.796756\n",
              "8109       air pollution     0.772872\n",
              "1787       according new     0.771510\n",
              "223688        peace deal     0.764626\n",
              "209611    nuclear strike     0.755552\n",
              "93315    eastern ukraine     0.727508\n",
              "311763        time since     0.725524"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 370
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "uiSp21nl9Gai",
        "outputId": "82f27292-4c61-45b0-c632-d1a7b3ea4875"
      },
      "source": [
        "coeffdf.tail(10)"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>299371</th>\n",
              "      <td>support israel</td>\n",
              "      <td>-0.746145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285792</th>\n",
              "      <td>solar system</td>\n",
              "      <td>-0.774426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293773</th>\n",
              "      <td>stock market</td>\n",
              "      <td>-0.774850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294959</th>\n",
              "      <td>strait hormuz</td>\n",
              "      <td>-0.783698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54807</th>\n",
              "      <td>chinese officials</td>\n",
              "      <td>-0.787793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220259</th>\n",
              "      <td>panama papers</td>\n",
              "      <td>-0.852689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192889</th>\n",
              "      <td>military bases</td>\n",
              "      <td>-0.904961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268109</th>\n",
              "      <td>saudi king</td>\n",
              "      <td>-0.922218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334265</th>\n",
              "      <td>war iran</td>\n",
              "      <td>-0.940277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326071</th>\n",
              "      <td>us army</td>\n",
              "      <td>-1.035989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Word  Coefficient\n",
              "299371     support israel    -0.746145\n",
              "285792       solar system    -0.774426\n",
              "293773       stock market    -0.774850\n",
              "294959      strait hormuz    -0.783698\n",
              "54807   chinese officials    -0.787793\n",
              "220259      panama papers    -0.852689\n",
              "192889     military bases    -0.904961\n",
              "268109         saudi king    -0.922218\n",
              "334265           war iran    -0.940277\n",
              "326071            us army    -1.035989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUxZOqjo5Eg7"
      },
      "source": [
        "### 3-gram modell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX7vV_715ckj"
      },
      "source": [
        "Hasonlóan az eddigiekhez vektorizálom a tanító adathalmazom, logistic regression modellt illesztek rá, becslést hajtok végre majd kiértékelem az eredményeket. Először a (1,3) n-gram modellel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRNHw3tAMSjp",
        "outputId": "6b21a676-3abe-4fd8-81df-6295cc3a48f9"
      },
      "source": [
        "gram_vectorizer_13 = CountVectorizer(ngram_range=(1,3))\r\n",
        "train_vectorizer_13 = gram_vectorizer_13.fit_transform(train_headlines)\r\n",
        "\r\n",
        "print(train_vectorizer_13.shape)\r\n",
        "\r\n",
        "gram_model_13 = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "gram_model_13 = gram_model_13.fit(train_vectorizer_13, train[\"Label\"])\r\n",
        "\r\n",
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "gram_test_13 = gram_vectorizer_13.transform(test_headlines)\r\n",
        "gram_predictions_13 = gram_model_13.predict(gram_test_13)\r\n",
        "\r\n",
        "pd.crosstab(test[\"Label\"], gram_predictions_13, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "print (classification_report(test[\"Label\"], gram_predictions_13))\r\n",
        "print (accuracy_score(test[\"Label\"], gram_predictions_13))\r\n",
        "\r\n",
        "result.append(accuracy_score(test[\"Label\"], gram_predictions_13))"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20286, 802274)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "AG-xubCYMiFF",
        "outputId": "e1a95aaa-e7cd-446c-d427-c5ef149d2d2a"
      },
      "source": [
        "gram_words_13 = gram_vectorizer_13.get_feature_names()\r\n",
        "gram_coeffs_13 = gram_model_13.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : gram_words_13, \r\n",
        "                        'Coefficient' : gram_coeffs_13})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "coeffdf.head(10)"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>457197</th>\n",
              "      <td>mumbai</td>\n",
              "      <td>0.798173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388804</th>\n",
              "      <td>landing</td>\n",
              "      <td>0.754990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629974</th>\n",
              "      <td>seize</td>\n",
              "      <td>0.702728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627639</th>\n",
              "      <td>security council</td>\n",
              "      <td>0.698021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391604</th>\n",
              "      <td>latest</td>\n",
              "      <td>0.686259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14397</th>\n",
              "      <td>agencies</td>\n",
              "      <td>0.672385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>679261</th>\n",
              "      <td>struggle</td>\n",
              "      <td>0.670076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761964</th>\n",
              "      <td>volcano</td>\n",
              "      <td>0.664893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415963</th>\n",
              "      <td>luxury</td>\n",
              "      <td>0.635630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94259</th>\n",
              "      <td>buildings</td>\n",
              "      <td>0.632831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Word  Coefficient\n",
              "457197            mumbai     0.798173\n",
              "388804           landing     0.754990\n",
              "629974             seize     0.702728\n",
              "627639  security council     0.698021\n",
              "391604            latest     0.686259\n",
              "14397           agencies     0.672385\n",
              "679261          struggle     0.670076\n",
              "761964           volcano     0.664893\n",
              "415963            luxury     0.635630\n",
              "94259          buildings     0.632831"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "DequuzvFMmH3",
        "outputId": "71b27243-eaae-4e33-8988-f659294ea6f3"
      },
      "source": [
        "coeffdf.tail(10)"
      ],
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>112761</th>\n",
              "      <td>census</td>\n",
              "      <td>-0.641643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594601</th>\n",
              "      <td>revolt</td>\n",
              "      <td>-0.642421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723238</th>\n",
              "      <td>trafficking</td>\n",
              "      <td>-0.659209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68214</th>\n",
              "      <td>begin</td>\n",
              "      <td>-0.661095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35574</th>\n",
              "      <td>appeal</td>\n",
              "      <td>-0.738186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693724</th>\n",
              "      <td>system</td>\n",
              "      <td>-0.740079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747588</th>\n",
              "      <td>us army</td>\n",
              "      <td>-0.748473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467784</th>\n",
              "      <td>nepal</td>\n",
              "      <td>-0.749290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414991</th>\n",
              "      <td>low</td>\n",
              "      <td>-0.756724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>656691</th>\n",
              "      <td>somalia</td>\n",
              "      <td>-0.922395</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Word  Coefficient\n",
              "112761       census    -0.641643\n",
              "594601       revolt    -0.642421\n",
              "723238  trafficking    -0.659209\n",
              "68214         begin    -0.661095\n",
              "35574        appeal    -0.738186\n",
              "693724       system    -0.740079\n",
              "747588      us army    -0.748473\n",
              "467784        nepal    -0.749290\n",
              "414991          low    -0.756724\n",
              "656691      somalia    -0.922395"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHmKu3djMS14"
      },
      "source": [
        "Hasonlóan az eddigiekhez vektorizálom a tanító adathalmazom, logistic regression modellt illesztek rá, becslést hajtok végre majd kiértékelem az eredményeket. Először a (2,3) n-gram modellel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Etgz8IAjMUE3",
        "outputId": "c8605f33-479c-42ef-a037-3155d4e7bb98"
      },
      "source": [
        "gram_vectorizer_23 = CountVectorizer(ngram_range=(2,3))\r\n",
        "train_vectorizer_23 = gram_vectorizer_23.fit_transform(train_headlines)\r\n",
        "\r\n",
        "print(train_vectorizer_23.shape)\r\n",
        "\r\n",
        "gram_model_23 = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "gram_model_23 = gram_model_23.fit(train_vectorizer_23, train[\"Label\"])\r\n",
        "\r\n",
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "gram_test_23 = gram_vectorizer_23.transform(test_headlines)\r\n",
        "gram_predictions_23 = gram_model_23.predict(gram_test_23)\r\n",
        "\r\n",
        "pd.crosstab(test[\"Label\"], gram_predictions_23, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "print (classification_report(test[\"Label\"], gram_predictions_23))\r\n",
        "print (accuracy_score(test[\"Label\"], gram_predictions_23))\r\n",
        "\r\n",
        "result.append(accuracy_score(test[\"Label\"], gram_predictions_23))"
      ],
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20286, 763667)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "uVN0l54FMi1-",
        "outputId": "f4eaacac-8ac7-4560-ff21-a7862e6ed470"
      },
      "source": [
        "gram_words_23 = gram_vectorizer_23.get_feature_names()\r\n",
        "gram_coeffs_23 = gram_model_23.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : gram_words_23, \r\n",
        "                        'Coefficient' : gram_coeffs_23})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "coeffdf.head(10)"
      ],
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>597209</th>\n",
              "      <td>security council</td>\n",
              "      <td>0.724715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607058</th>\n",
              "      <td>sexual violence</td>\n",
              "      <td>0.636324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153212</th>\n",
              "      <td>court rules</td>\n",
              "      <td>0.616613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201062</th>\n",
              "      <td>eastern ukraine</td>\n",
              "      <td>0.601972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17359</th>\n",
              "      <td>air pollution</td>\n",
              "      <td>0.599077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568778</th>\n",
              "      <td>rights watch</td>\n",
              "      <td>0.585935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3769</th>\n",
              "      <td>according new</td>\n",
              "      <td>0.571407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622533</th>\n",
              "      <td>social media</td>\n",
              "      <td>0.569983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713767</th>\n",
              "      <td>us spying</td>\n",
              "      <td>0.560623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751370</th>\n",
              "      <td>world largest</td>\n",
              "      <td>0.556218</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Word  Coefficient\n",
              "597209  security council     0.724715\n",
              "607058   sexual violence     0.636324\n",
              "153212       court rules     0.616613\n",
              "201062   eastern ukraine     0.601972\n",
              "17359      air pollution     0.599077\n",
              "568778      rights watch     0.585935\n",
              "3769       according new     0.571407\n",
              "622533      social media     0.569983\n",
              "713767         us spying     0.560623\n",
              "751370     world largest     0.556218"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 376
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "pIO9FkYuMnNb",
        "outputId": "502fbe0b-416f-4409-deb3-4e6522204bef"
      },
      "source": [
        "coeffdf.tail(10)"
      ],
      "execution_count": 377,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>548009</th>\n",
              "      <td>red cross</td>\n",
              "      <td>-0.576519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>640979</th>\n",
              "      <td>stock market</td>\n",
              "      <td>-0.582220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39938</th>\n",
              "      <td>around world</td>\n",
              "      <td>-0.592300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449734</th>\n",
              "      <td>news international</td>\n",
              "      <td>-0.611127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650490</th>\n",
              "      <td>suicide bomber</td>\n",
              "      <td>-0.660796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419034</th>\n",
              "      <td>military bases</td>\n",
              "      <td>-0.663339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729640</th>\n",
              "      <td>war iran</td>\n",
              "      <td>-0.688157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584685</th>\n",
              "      <td>saudi king</td>\n",
              "      <td>-0.693207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480834</th>\n",
              "      <td>panama papers</td>\n",
              "      <td>-0.703129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711294</th>\n",
              "      <td>us army</td>\n",
              "      <td>-0.758311</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Word  Coefficient\n",
              "548009           red cross    -0.576519\n",
              "640979        stock market    -0.582220\n",
              "39938         around world    -0.592300\n",
              "449734  news international    -0.611127\n",
              "650490      suicide bomber    -0.660796\n",
              "419034      military bases    -0.663339\n",
              "729640            war iran    -0.688157\n",
              "584685          saudi king    -0.693207\n",
              "480834       panama papers    -0.703129\n",
              "711294             us army    -0.758311"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 377
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tftajhXMMUUs"
      },
      "source": [
        "Hasonlóan az eddigiekhez vektorizálom a tanító adathalmazom, logistic regression modellt illesztek rá, becslést hajtok végre majd kiértékelem az eredményeket. Először a (3,3) n-gram modellel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T-9458xMaJq",
        "outputId": "6fe87015-8b62-4903-a399-03d4c5774895"
      },
      "source": [
        "gram_vectorizer_33 = CountVectorizer(ngram_range=(3,3))\r\n",
        "train_vectorizer_33 = gram_vectorizer_33.fit_transform(train_headlines)\r\n",
        "\r\n",
        "print(train_vectorizer_33.shape)\r\n",
        "\r\n",
        "gram_model_33 = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "gram_model_33 = gram_model_33.fit(train_vectorizer_33, train[\"Label\"])\r\n",
        "\r\n",
        "test_headlines = []\r\n",
        "\r\n",
        "for row in range(0,len(test.index)):\r\n",
        "    test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "gram_test_33 = gram_vectorizer_33.transform(test_headlines)\r\n",
        "gram_predictions_33 = gram_model_33.predict(gram_test_33)\r\n",
        "\r\n",
        "pd.crosstab(test[\"Label\"], gram_predictions_33, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "print (classification_report(test[\"Label\"], gram_predictions_33))\r\n",
        "print (accuracy_score(test[\"Label\"], gram_predictions_33))\r\n",
        "\r\n",
        "result.append(accuracy_score(test[\"Label\"], gram_predictions_33))"
      ],
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20286, 414359)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "Z7_f6ay_MjhC",
        "outputId": "0701cc62-3ee0-4623-8df9-7228dd0e8096"
      },
      "source": [
        "gram_words_33 = gram_vectorizer_33.get_feature_names()\r\n",
        "gram_coeffs_33 = gram_model_33.coef_.tolist()[0]\r\n",
        "\r\n",
        "coeffdf = pd.DataFrame({'Word' : gram_words_33, \r\n",
        "                        'Coefficient' : gram_coeffs_33})\r\n",
        "\r\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\r\n",
        "coeffdf.head(10)"
      ],
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>132267</th>\n",
              "      <td>first time since</td>\n",
              "      <td>0.916949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381429</th>\n",
              "      <td>un security council</td>\n",
              "      <td>0.755421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168514</th>\n",
              "      <td>human rights watch</td>\n",
              "      <td>0.694514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10082</th>\n",
              "      <td>al jazeera english</td>\n",
              "      <td>0.683763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280085</th>\n",
              "      <td>president hosni mubarak</td>\n",
              "      <td>0.623580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381127</th>\n",
              "      <td>un general assembly</td>\n",
              "      <td>0.533258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283226</th>\n",
              "      <td>pro russian separatists</td>\n",
              "      <td>0.515341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410908</th>\n",
              "      <td>year old man</td>\n",
              "      <td>0.508897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402301</th>\n",
              "      <td>wikileaks julian assange</td>\n",
              "      <td>0.505865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140822</th>\n",
              "      <td>french president sarkozy</td>\n",
              "      <td>0.503710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Word  Coefficient\n",
              "132267          first time since     0.916949\n",
              "381429       un security council     0.755421\n",
              "168514        human rights watch     0.694514\n",
              "10082         al jazeera english     0.683763\n",
              "280085   president hosni mubarak     0.623580\n",
              "381127       un general assembly     0.533258\n",
              "283226   pro russian separatists     0.515341\n",
              "410908              year old man     0.508897\n",
              "402301  wikileaks julian assange     0.505865\n",
              "140822  french president sarkozy     0.503710"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 379
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "KNFCAZ2pMpCY",
        "outputId": "34231d96-9660-4f68-b938-6d92c5100c85"
      },
      "source": [
        "coeffdf.tail(10)"
      ],
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>148251</th>\n",
              "      <td>girl gang raped</td>\n",
              "      <td>-0.515230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26624</th>\n",
              "      <td>aung san suu</td>\n",
              "      <td>-0.526697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178458</th>\n",
              "      <td>international space station</td>\n",
              "      <td>-0.526701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326323</th>\n",
              "      <td>sentenced years prison</td>\n",
              "      <td>-0.549481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165697</th>\n",
              "      <td>homes east jerusalem</td>\n",
              "      <td>-0.554131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109678</th>\n",
              "      <td>egypt muslim brotherhood</td>\n",
              "      <td>-0.560240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357226</th>\n",
              "      <td>syrian security forces</td>\n",
              "      <td>-0.603754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229484</th>\n",
              "      <td>missile defense system</td>\n",
              "      <td>-0.661560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58597</th>\n",
              "      <td>chancellor angela merkel</td>\n",
              "      <td>-0.701318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123670</th>\n",
              "      <td>faces years jail</td>\n",
              "      <td>-0.717956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Word  Coefficient\n",
              "148251              girl gang raped    -0.515230\n",
              "26624                  aung san suu    -0.526697\n",
              "178458  international space station    -0.526701\n",
              "326323       sentenced years prison    -0.549481\n",
              "165697         homes east jerusalem    -0.554131\n",
              "109678     egypt muslim brotherhood    -0.560240\n",
              "357226       syrian security forces    -0.603754\n",
              "229484       missile defense system    -0.661560\n",
              "58597      chancellor angela merkel    -0.701318\n",
              "123670             faces years jail    -0.717956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 380
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKpZIe-RTmk_"
      },
      "source": [
        "### 4-gram modell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y75LfFJBTtrz"
      },
      "source": [
        "Ebben a fejezetben már egy ciklusban vizsgálom meg a bizonyos modelleket és mentem le az eredményeiket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PabhGwFWUZrZ",
        "outputId": "d5b64c23-8a92-4948-894e-5266932868f3"
      },
      "source": [
        "for n in range(1,5):\r\n",
        "    print(\"--------------------------------------------\\n\\nStart of the \" \r\n",
        "          + str(n) + \",4 gram model\\n\")\r\n",
        "\r\n",
        "    _gram_vectorizer_ = CountVectorizer(ngram_range=(n,4))\r\n",
        "    _train_vectorizer_ = _gram_vectorizer_.fit_transform(train_headlines)\r\n",
        "\r\n",
        "    print(\"The shape is: \" + str(_train_vectorizer_.shape) + \"\\n\")\r\n",
        "\r\n",
        "    _gram_model_ = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "    _gram_model_ = _gram_model_.fit(_train_vectorizer_, train[\"Label\"])\r\n",
        "\r\n",
        "    test_headlines = []\r\n",
        "\r\n",
        "    for row in range(0,len(test.index)):\r\n",
        "        test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "    _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "    _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
        "    pd.crosstab(test[\"Label\"], _gram_predictions_, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "    print (classification_report(test[\"Label\"], _gram_predictions_))\r\n",
        "    print (accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "    model_type.append(str(n) + \",4 n-gram\")\r\n",
        "    result.append(accuracy_score(test[\"Label\"], _gram_predictions_))"
      ],
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omkP2pSAV6Qm"
      },
      "source": [
        "### 5-gram modell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Y4HliaV-rg"
      },
      "source": [
        "Ebben a fejezetben már egy ciklusban vizsgálom meg a bizonyos modelleket és mentem le az eredményeiket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8hdr8A-WBRq",
        "outputId": "de60392b-eb33-45ef-d99c-1e28098b7b91"
      },
      "source": [
        "MODEL_TYPE = 5\r\n",
        "\r\n",
        "for n in range(1,MODEL_TYPE+1):\r\n",
        "    print(\"--------------------------------------------\\n\\nStart of the \" \r\n",
        "          + str(n) + \",\" + str(MODEL_TYPE) + \" gram model\\n\")\r\n",
        "\r\n",
        "    _gram_vectorizer_ = CountVectorizer(ngram_range=(n,MODEL_TYPE))\r\n",
        "    _train_vectorizer_ = _gram_vectorizer_.fit_transform(train_headlines)\r\n",
        "\r\n",
        "    print(\"The shape is: \" + str(_train_vectorizer_.shape) + \"\\n\")\r\n",
        "\r\n",
        "    _gram_model_ = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "    _gram_model_ = _gram_model_.fit(_train_vectorizer_, train[\"Label\"])\r\n",
        "\r\n",
        "    test_headlines = []\r\n",
        "\r\n",
        "    for row in range(0,len(test.index)):\r\n",
        "        test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "    _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "    _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
        "    pd.crosstab(test[\"Label\"], _gram_predictions_, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "    print (classification_report(test[\"Label\"], _gram_predictions_))\r\n",
        "    print (accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "    model_type.append(str(n) + \",\" + str(MODEL_TYPE) + \" n-gram\")\r\n",
        "    result.append(accuracy_score(test[\"Label\"], _gram_predictions_))"
      ],
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgRyRExGWvFN"
      },
      "source": [
        "### 6-gram modell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv2plcaDWy8V"
      },
      "source": [
        "Ebben a fejezetben már egy ciklusban vizsgálom meg a bizonyos modelleket és mentem le az eredményeiket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-9kyXKFW1KI",
        "outputId": "716d0c9f-7ad0-42af-e64c-b318593a3ccd"
      },
      "source": [
        "MODEL_TYPE = 6\r\n",
        "\r\n",
        "for n in range(1,MODEL_TYPE+1):\r\n",
        "    print(\"--------------------------------------------\\n\\nStart of the \" \r\n",
        "          + str(n) + \",\" + str(MODEL_TYPE) + \" gram model\\n\")\r\n",
        "\r\n",
        "    _gram_vectorizer_ = CountVectorizer(ngram_range=(n,MODEL_TYPE))\r\n",
        "    _train_vectorizer_ = _gram_vectorizer_.fit_transform(train_headlines)\r\n",
        "\r\n",
        "    print(\"The shape is: \" + str(_train_vectorizer_.shape) + \"\\n\")\r\n",
        "\r\n",
        "    _gram_model_ = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "    _gram_model_ = _gram_model_.fit(_train_vectorizer_, train[\"Label\"])\r\n",
        "\r\n",
        "    test_headlines = []\r\n",
        "\r\n",
        "    for row in range(0,len(test.index)):\r\n",
        "        test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "    _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "    _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
        "    pd.crosstab(test[\"Label\"], _gram_predictions_, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "    print (classification_report(test[\"Label\"], _gram_predictions_))\r\n",
        "    print (accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "    model_type.append(str(n) + \",\" + str(MODEL_TYPE) + \" n-gram\")\r\n",
        "    result.append(accuracy_score(test[\"Label\"], _gram_predictions_))"
      ],
      "execution_count": 383,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh7BcurhRaGe"
      },
      "source": [
        "### Eredmények összegzése"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr2NAOefRc1j"
      },
      "source": [
        "Az eredmények kiíratása, a legjobbat kiemelve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykPdalGBRgeL",
        "outputId": "b81e540b-eeaf-4f52-af0d-4ff30d9d5256"
      },
      "source": [
        "best_model = 0\r\n",
        "\r\n",
        "for model in range(len(model_type)):\r\n",
        "    print(str(model_type[model]) + \":\\t\\t\\t\\t\\t\" + str(result[model]))\r\n",
        "\r\n",
        "    if result[model] > best_model:\r\n",
        "        best_model = result[model]\r\n",
        "        best_model_index = model\r\n",
        "\r\n",
        "print(\"--------------------------------------------\\nBest model:\\n\" \r\n",
        "      + str(model_type[best_model_index]) + \"\\t\\t\\t\\t\\t\" + \r\n",
        "      str(result[best_model_index]))\r\n"
      ],
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bag of words:\t\t\t\t\t0.5110304384250209\n",
            "1,2 n-gram:\t\t\t\t\t0.5110304384250209\n",
            "2,2 n-gram:\t\t\t\t\t0.5283440379782184\n",
            "1,3 n-gram:\t\t\t\t\t0.5227590058642837\n",
            "2,3 n-gram:\t\t\t\t\t0.5403518570231779\n",
            "3,3 n-gram:\t\t\t\t\t0.5495671600111701\n",
            "1,4 n-gram:\t\t\t\t\t0.5196872382016197\n",
            "2,4 n-gram:\t\t\t\t\t0.542306618263055\n",
            "3,4 n-gram:\t\t\t\t\t0.5520804244624407\n",
            "4,4 n-gram:\t\t\t\t\t0.5498464116168668\n",
            "1,5 n-gram:\t\t\t\t\t0.5210834962301033\n",
            "2,5 n-gram:\t\t\t\t\t0.5420273666573583\n",
            "3,5 n-gram:\t\t\t\t\t0.5490086567997766\n",
            "4,5 n-gram:\t\t\t\t\t0.5504049148282603\n",
            "5,5 n-gram:\t\t\t\t\t0.5495671600111701\n",
            "1,6 n-gram:\t\t\t\t\t0.5205249930187098\n",
            "2,6 n-gram:\t\t\t\t\t0.542306618263055\n",
            "3,6 n-gram:\t\t\t\t\t0.5481709019826864\n",
            "4,6 n-gram:\t\t\t\t\t0.550684166433957\n",
            "5,6 n-gram:\t\t\t\t\t0.5495671600111701\n",
            "6,6 n-gram:\t\t\t\t\t0.5490086567997766\n",
            "--------------------------------------------\n",
            "Best model:\n",
            "3,4 n-gram\t\t\t\t\t0.5520804244624407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnuJNnfVYu04"
      },
      "source": [
        "### ROWS makró optimalizálás"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG3gtt_TY80k"
      },
      "source": [
        "Ebben a fejezetben a különböző ROWS értékekre (mennyi napi hírt fűzünk egybe) futtatom végig egy automatizált bag of words -> 6,6 gram modell tanítást és becslést és állapítom meg, hogy melyik a legpontosabb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUJCC_EiZo63"
      },
      "source": [
        "A tesztelendő paraméterek megadása."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KUt-wbZZO1i",
        "outputId": "37bd36bb-cf7e-4712-b873-28bb272311e6"
      },
      "source": [
        "# Number of merged news into one string: 1...12, 25 \r\n",
        "rows_values = []\r\n",
        "for value in range(1,13):\r\n",
        "    rows_values.append(value)\r\n",
        "\r\n",
        "rows_values.append(25)\r\n",
        "\r\n",
        "rows_values"
      ],
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 25]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHIHq8mVcNvZ"
      },
      "source": [
        "A modell típusok összegyűjtése az automatizált tanításhoz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U4xwuVXcRsp",
        "outputId": "6afd6281-b04a-4b38-ce1c-674ec5db5dd1"
      },
      "source": [
        "model_type_values = []\r\n",
        "for value in range(1,7):\r\n",
        "    model_type_values.append(value)\r\n",
        "\r\n",
        "model_type_values"
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu9UswHzer9O"
      },
      "source": [
        "A paraméterhez tartozó eredmények tárolására létrehozom az alábbi tömböket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRcPzJ-1exEu"
      },
      "source": [
        "rows_summary_value = []\r\n",
        "rows_summary_accuraccy = []"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0_5e2otZsMM"
      },
      "source": [
        "Automatizált tanítás és mentések."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq0Oo4iHZufG",
        "outputId": "a2656491-65f4-4b49-f1df-a5a15ca5a201"
      },
      "source": [
        "for ROWS in rows_values:\r\n",
        "\r\n",
        "    print(\"--------------------------------------------\\n\\nStart of the ROWS = \" \r\n",
        "      + str(ROWS) + \" sequence\\n\\n--------------------------------------------\\n\")\r\n",
        "    \r\n",
        "    model_type = []\r\n",
        "    result = []\r\n",
        "\r\n",
        "    for MODEL_TYPE in model_type_values:\r\n",
        "\r\n",
        "        for n in range(1,MODEL_TYPE+1):\r\n",
        "            print(\"--------------------------------------------\\n\\nStart of the \" \r\n",
        "                  + str(n) + \",\" + str(MODEL_TYPE) + \" gram model\\n\")\r\n",
        "\r\n",
        "            _gram_vectorizer_ = CountVectorizer(ngram_range=(n,MODEL_TYPE))\r\n",
        "            _train_vectorizer_ = _gram_vectorizer_.fit_transform(train_headlines)\r\n",
        "\r\n",
        "            print(\"The shape is: \" + str(_train_vectorizer_.shape) + \"\\n\")\r\n",
        "\r\n",
        "            _gram_model_ = LogisticRegression(random_state=RANDOM_SEED, max_iter=MAX_ITER)\r\n",
        "            _gram_model_ = _gram_model_.fit(_train_vectorizer_, train[\"Label\"])\r\n",
        "\r\n",
        "            test_headlines = []\r\n",
        "\r\n",
        "            for row in range(0,len(test.index)):\r\n",
        "                test_headlines.append(test.iloc[row, 1])\r\n",
        "\r\n",
        "            _gram_test_ = _gram_vectorizer_.transform(test_headlines)\r\n",
        "            _gram_predictions_ = _gram_model_.predict(_gram_test_)\r\n",
        "\r\n",
        "            pd.crosstab(test[\"Label\"], _gram_predictions_, rownames=[\"Actual\"], colnames=[\"Predicted\"])\r\n",
        "\r\n",
        "            print (classification_report(test[\"Label\"], _gram_predictions_))\r\n",
        "            print (accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "            model_type.append(str(n) + \",\" + str(MODEL_TYPE) + \" n-gram\")\r\n",
        "            result.append(accuracy_score(test[\"Label\"], _gram_predictions_))\r\n",
        "\r\n",
        "    rows_summary_value.append(ROWS)\r\n",
        "\r\n",
        "    # save the best\r\n",
        "    best_model = 0\r\n",
        "\r\n",
        "    for model in range(len(model_type)):\r\n",
        "        if result[model] > best_model:\r\n",
        "            best_model = result[model]\r\n",
        "            best_model_index = model\r\n",
        "\r\n",
        "    rows_summary_accuraccy.append(best_model)"
      ],
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 1 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 2 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 3 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 4 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 5 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 6 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 7 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 8 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 9 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 10 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 11 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 12 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the ROWS = 25 sequence\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,1 gram model\n",
            "\n",
            "The shape is: (20286, 38607)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.45      0.45      1617\n",
            "           1       0.55      0.56      0.56      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,2 gram model\n",
            "\n",
            "The shape is: (20286, 387915)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42      1617\n",
            "           1       0.55      0.60      0.58      1964\n",
            "\n",
            "    accuracy                           0.51      3581\n",
            "   macro avg       0.50      0.50      0.50      3581\n",
            "weighted avg       0.51      0.51      0.51      3581\n",
            "\n",
            "0.5110304384250209\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,2 gram model\n",
            "\n",
            "The shape is: (20286, 349308)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.31      0.37      1617\n",
            "           1       0.55      0.71      0.62      1964\n",
            "\n",
            "    accuracy                           0.53      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.53      0.51      3581\n",
            "\n",
            "0.5283440379782184\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,3 gram model\n",
            "\n",
            "The shape is: (20286, 802274)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.39      0.43      1617\n",
            "           1       0.56      0.63      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.51      3581\n",
            "weighted avg       0.52      0.52      0.52      3581\n",
            "\n",
            "0.5227590058642837\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,3 gram model\n",
            "\n",
            "The shape is: (20286, 763667)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.25      0.33      1617\n",
            "           1       0.56      0.78      0.65      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.49      3581\n",
            "weighted avg       0.52      0.54      0.50      3581\n",
            "\n",
            "0.5403518570231779\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,3 gram model\n",
            "\n",
            "The shape is: (20286, 414359)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.07      0.12      1617\n",
            "           1       0.55      0.94      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.51      0.41      3581\n",
            "weighted avg       0.53      0.55      0.44      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,4 gram model\n",
            "\n",
            "The shape is: (20286, 1206740)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.37      0.41      1617\n",
            "           1       0.55      0.64      0.59      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5196872382016197\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,4 gram model\n",
            "\n",
            "The shape is: (20286, 1168133)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.19      0.27      1617\n",
            "           1       0.56      0.83      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.52      0.51      0.47      3581\n",
            "weighted avg       0.52      0.54      0.49      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,4 gram model\n",
            "\n",
            "The shape is: (20286, 818825)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.04      0.08      1617\n",
            "           1       0.55      0.97      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.55      0.51      0.39      3581\n",
            "weighted avg       0.55      0.55      0.42      3581\n",
            "\n",
            "0.5520804244624407\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,4 gram model\n",
            "\n",
            "The shape is: (20286, 404466)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.01      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.56      0.50      0.37      3581\n",
            "weighted avg       0.56      0.55      0.40      3581\n",
            "\n",
            "0.5498464116168668\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,5 gram model\n",
            "\n",
            "The shape is: (20286, 1592567)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.41      1617\n",
            "           1       0.55      0.65      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5210834962301033\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,5 gram model\n",
            "\n",
            "The shape is: (20286, 1553960)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23      1617\n",
            "           1       0.55      0.87      0.67      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.45      3581\n",
            "weighted avg       0.52      0.54      0.47      3581\n",
            "\n",
            "0.5420273666573583\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,5 gram model\n",
            "\n",
            "The shape is: (20286, 1204652)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.03      0.05      1617\n",
            "           1       0.55      0.98      0.70      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.53      0.50      0.38      3581\n",
            "weighted avg       0.53      0.55      0.41      3581\n",
            "\n",
            "0.5490086567997766\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,5 gram model\n",
            "\n",
            "The shape is: (20286, 790293)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.01      0.02      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.40      3581\n",
            "\n",
            "0.5504049148282603\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,5 gram model\n",
            "\n",
            "The shape is: (20286, 385827)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.01      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.60      0.50      0.36      3581\n",
            "weighted avg       0.59      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 1,6 gram model\n",
            "\n",
            "The shape is: (20286, 1958520)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.35      0.40      1617\n",
            "           1       0.55      0.66      0.60      1964\n",
            "\n",
            "    accuracy                           0.52      3581\n",
            "   macro avg       0.51      0.51      0.50      3581\n",
            "weighted avg       0.51      0.52      0.51      3581\n",
            "\n",
            "0.5205249930187098\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 2,6 gram model\n",
            "\n",
            "The shape is: (20286, 1919913)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.12      0.20      1617\n",
            "           1       0.55      0.89      0.68      1964\n",
            "\n",
            "    accuracy                           0.54      3581\n",
            "   macro avg       0.51      0.51      0.44      3581\n",
            "weighted avg       0.52      0.54      0.46      3581\n",
            "\n",
            "0.542306618263055\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 3,6 gram model\n",
            "\n",
            "The shape is: (20286, 1570605)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.02      0.03      1617\n",
            "           1       0.55      0.99      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.52      0.50      0.37      3581\n",
            "weighted avg       0.52      0.55      0.40      3581\n",
            "\n",
            "0.5481709019826864\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 4,6 gram model\n",
            "\n",
            "The shape is: (20286, 1156246)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.01      0.02      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.40      3581\n",
            "\n",
            "0.550684166433957\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 5,6 gram model\n",
            "\n",
            "The shape is: (20286, 751780)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.61      0.50      0.36      3581\n",
            "weighted avg       0.60      0.55      0.39      3581\n",
            "\n",
            "0.5495671600111701\n",
            "--------------------------------------------\n",
            "\n",
            "Start of the 6,6 gram model\n",
            "\n",
            "The shape is: (20286, 365953)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.00      0.01      1617\n",
            "           1       0.55      1.00      0.71      1964\n",
            "\n",
            "    accuracy                           0.55      3581\n",
            "   macro avg       0.59      0.50      0.36      3581\n",
            "weighted avg       0.58      0.55      0.39      3581\n",
            "\n",
            "0.5490086567997766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgc2E1npZvJC"
      },
      "source": [
        "Kiértékelés."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWUCZnMNfebo",
        "outputId": "3916f084-cf3f-4f0f-c41e-3cee80816fde"
      },
      "source": [
        "best_model = 0\r\n",
        "\r\n",
        "for model in range(len(rows_summary_value)):\r\n",
        "    print(str(rows_summary_value[model]) + \":\\t\\t\\t\\t\\t\" \r\n",
        "          + str(rows_summary_accuraccy[model]))\r\n",
        "\r\n",
        "    if rows_summary_accuraccy[model] > best_model:\r\n",
        "        best_model = rows_summary_accuraccy[model]\r\n",
        "        best_model_index = model\r\n",
        "\r\n",
        "print(\"--------------------------------------------\\nBest row value:\\n\" \r\n",
        "      + str(rows_summary_value[best_model_index]) + \"\\t\\t\\t\\t\\t\" + \r\n",
        "      str(rows_summary_accuraccy[best_model_index]))"
      ],
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1:\t\t\t\t\t0.5110304384250209\n",
            "1:\t\t\t\t\t0.5283440379782184\n",
            "1:\t\t\t\t\t0.5495671600111701\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5110304384250209\n",
            "2:\t\t\t\t\t0.5283440379782184\n",
            "2:\t\t\t\t\t0.5495671600111701\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5110304384250209\n",
            "3:\t\t\t\t\t0.5283440379782184\n",
            "3:\t\t\t\t\t0.5495671600111701\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5110304384250209\n",
            "4:\t\t\t\t\t0.5283440379782184\n",
            "4:\t\t\t\t\t0.5495671600111701\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5110304384250209\n",
            "5:\t\t\t\t\t0.5283440379782184\n",
            "5:\t\t\t\t\t0.5495671600111701\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5110304384250209\n",
            "6:\t\t\t\t\t0.5283440379782184\n",
            "6:\t\t\t\t\t0.5495671600111701\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5110304384250209\n",
            "7:\t\t\t\t\t0.5283440379782184\n",
            "7:\t\t\t\t\t0.5495671600111701\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5110304384250209\n",
            "8:\t\t\t\t\t0.5283440379782184\n",
            "8:\t\t\t\t\t0.5495671600111701\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5110304384250209\n",
            "9:\t\t\t\t\t0.5283440379782184\n",
            "9:\t\t\t\t\t0.5495671600111701\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5110304384250209\n",
            "10:\t\t\t\t\t0.5283440379782184\n",
            "10:\t\t\t\t\t0.5495671600111701\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5110304384250209\n",
            "11:\t\t\t\t\t0.5283440379782184\n",
            "11:\t\t\t\t\t0.5495671600111701\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5110304384250209\n",
            "12:\t\t\t\t\t0.5283440379782184\n",
            "12:\t\t\t\t\t0.5495671600111701\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5110304384250209\n",
            "25:\t\t\t\t\t0.5283440379782184\n",
            "25:\t\t\t\t\t0.5495671600111701\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "1:\t\t\t\t\t0.5110304384250209\n",
            "1:\t\t\t\t\t0.5283440379782184\n",
            "1:\t\t\t\t\t0.5495671600111701\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5110304384250209\n",
            "2:\t\t\t\t\t0.5283440379782184\n",
            "2:\t\t\t\t\t0.5495671600111701\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5110304384250209\n",
            "3:\t\t\t\t\t0.5283440379782184\n",
            "3:\t\t\t\t\t0.5495671600111701\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5110304384250209\n",
            "4:\t\t\t\t\t0.5283440379782184\n",
            "4:\t\t\t\t\t0.5495671600111701\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5110304384250209\n",
            "5:\t\t\t\t\t0.5283440379782184\n",
            "5:\t\t\t\t\t0.5495671600111701\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5110304384250209\n",
            "6:\t\t\t\t\t0.5283440379782184\n",
            "6:\t\t\t\t\t0.5495671600111701\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5110304384250209\n",
            "7:\t\t\t\t\t0.5283440379782184\n",
            "7:\t\t\t\t\t0.5495671600111701\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5110304384250209\n",
            "8:\t\t\t\t\t0.5283440379782184\n",
            "8:\t\t\t\t\t0.5495671600111701\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5110304384250209\n",
            "9:\t\t\t\t\t0.5283440379782184\n",
            "9:\t\t\t\t\t0.5495671600111701\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5110304384250209\n",
            "10:\t\t\t\t\t0.5283440379782184\n",
            "10:\t\t\t\t\t0.5495671600111701\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5110304384250209\n",
            "11:\t\t\t\t\t0.5283440379782184\n",
            "11:\t\t\t\t\t0.5495671600111701\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5110304384250209\n",
            "12:\t\t\t\t\t0.5283440379782184\n",
            "12:\t\t\t\t\t0.5495671600111701\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5110304384250209\n",
            "25:\t\t\t\t\t0.5283440379782184\n",
            "25:\t\t\t\t\t0.5495671600111701\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "1:\t\t\t\t\t0.5520804244624407\n",
            "2:\t\t\t\t\t0.5520804244624407\n",
            "3:\t\t\t\t\t0.5520804244624407\n",
            "4:\t\t\t\t\t0.5520804244624407\n",
            "5:\t\t\t\t\t0.5520804244624407\n",
            "6:\t\t\t\t\t0.5520804244624407\n",
            "7:\t\t\t\t\t0.5520804244624407\n",
            "8:\t\t\t\t\t0.5520804244624407\n",
            "9:\t\t\t\t\t0.5520804244624407\n",
            "10:\t\t\t\t\t0.5520804244624407\n",
            "11:\t\t\t\t\t0.5520804244624407\n",
            "12:\t\t\t\t\t0.5520804244624407\n",
            "25:\t\t\t\t\t0.5520804244624407\n",
            "--------------------------------------------\n",
            "Best row value:\n",
            "1\t\t\t\t\t0.5520804244624407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKZQkIdFAXfG"
      },
      "source": [
        "## ECO_BSN_DF, ECO_FNC_DF, ECO_US_DF 2008-2016"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyZGBhb0CcgL"
      },
      "source": [
        "Először megvizsgálom a reddit-es világhírekkel megegyező intervallumon ezeket az összevont adathalmazokat, majd egyesítve és kombinálva a kettőt megvizsgálom, hogy javítja-e a pontosságot.\r\n",
        "\r\n",
        "Ezeket az adathalmazokat én magam gyűjtöttem az alábbi oldalakról:\r\n",
        "\r\n",
        "\r\n",
        "*   https://www.economist.com/business/ \r\n",
        "*   https://www.economist.com/finance-and-economics/ \r\n",
        "*   https://www.economist.com/united-states/ "
      ]
    }
  ]
}