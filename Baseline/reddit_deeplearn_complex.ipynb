{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "reddit_deeplearn_complex.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f7d79579fa5640de9b8b2a3ad4f0fb70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a84cc744fecc4f619781d7601d013998",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fbc1de3bd76245a7b48337174c6743f0",
              "IPY_MODEL_5efa710b50e348bdb10cf6ded81ab0b0"
            ]
          }
        },
        "a84cc744fecc4f619781d7601d013998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbc1de3bd76245a7b48337174c6743f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_819383e39c6149c58c6969963079c333",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8430553cfb64c7aaf051126a8e11ea8"
          }
        },
        "5efa710b50e348bdb10cf6ded81ab0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_51eee00483844ae28eb5baa5f78b5cc2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 5.98kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_118bbb1d79dc42fa930d25476a17d344"
          }
        },
        "819383e39c6149c58c6969963079c333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8430553cfb64c7aaf051126a8e11ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51eee00483844ae28eb5baa5f78b5cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "118bbb1d79dc42fa930d25476a17d344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "043dfbe5de374416a0d81c911ce75be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_66b5eef22a934d4fabd0b72fe86c2278",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2b56fc87af844bd8e249335c8af4db1",
              "IPY_MODEL_08fb7bc4c621451fbf5e984ae2fdb428"
            ]
          }
        },
        "66b5eef22a934d4fabd0b72fe86c2278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2b56fc87af844bd8e249335c8af4db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_726556e4152f4e6f8b4d1318f17429b9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57accff470674adea7189eb30d7ba07d"
          }
        },
        "08fb7bc4c621451fbf5e984ae2fdb428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_24fbe744d23b42cba679fb88e0068757",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:12&lt;00:00, 34.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3477da6d0262402d90fd0394802d3188"
          }
        },
        "726556e4152f4e6f8b4d1318f17429b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57accff470674adea7189eb30d7ba07d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24fbe744d23b42cba679fb88e0068757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3477da6d0262402d90fd0394802d3188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atTnfbF86J4f"
      },
      "source": [
        "# **Stock market news feed semantic analysis** *(Combined deep learning models)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2ALsllX6NQQ"
      },
      "source": [
        "1 news 1 data\n",
        "LSTM and BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVtxf9rvH29U",
        "outputId": "100f2d51-aae6-4f7f-ad06-e924ec2174e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeOHUBl0Lk8t"
      },
      "source": [
        "# Copy the dataset to the local environment\n",
        "!cp \"/content/drive/MyDrive/Combined_News_DJIA.csv\" \"Combined_News_DJIA.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v7o_Ni38RPe",
        "outputId": "7a9ce2c1-150e-429c-f46e-6172f881fc26"
      },
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.9.1\n",
            "    Uninstalling torchtext-0.9.1:\n",
            "      Successfully uninstalled torchtext-0.9.1\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z90A2CHLwws",
        "outputId": "afbe31f3-dbbc-404f-aef3-66813b7555c3"
      },
      "source": [
        "# Import the libraries \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas_datareader as web\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import time\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torchtext import data\n",
        "from sklearn.utils import shuffle\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize  \n",
        "from wordcloud import WordCloud\n",
        "from numpy.random import MT19937\n",
        "from numpy.random import RandomState, SeedSequence\n",
        "import sklearn.metrics as metrics\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAvcG9g6LyVh"
      },
      "source": [
        "# Number of merged news into one string\n",
        "ROWS = 1\n",
        "\n",
        "# Shuffle cycle number for the dataframe\n",
        "SHUFFLE_CYCLE = 500\n",
        "\n",
        "# Numpy random seed\n",
        "NP_SEED = 1234\n",
        "\n",
        "# Torch seed\n",
        "TORCH_SEED = 1234\n",
        "\n",
        "# Train percentage (train + valid)\n",
        "TRAIN_SPLIT = 0.8\n",
        "\n",
        "# Only validation split\n",
        "VALIDATION_SPLIT = 0.1\n",
        "\n",
        "# The label column \n",
        "LABEL_COLUMN = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMKQH4ZvL1SU"
      },
      "source": [
        "# set seeds for reproduce\n",
        "random.seed(NP_SEED)\n",
        "rs = RandomState(MT19937(SeedSequence(NP_SEED)))\n",
        "torch.manual_seed(TORCH_SEED)\n",
        "np.random.seed(NP_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed_all(TORCH_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9BCHskiL8lZ",
        "outputId": "b327e3c4-cbd0-452b-eea4-fb8b9169d1a4"
      },
      "source": [
        "# Load the dataset \n",
        "df_combined = pd.read_csv('Combined_News_DJIA.csv', index_col = \"Date\")\n",
        "\n",
        "# Find the cells with NaN and after the rows for them\n",
        "is_NaN = df_combined.isnull()\n",
        "row_has_NaN = is_NaN.any(axis = 1)\n",
        "rows_with_NaN = df_combined[row_has_NaN]\n",
        "\n",
        "# Replace them\n",
        "df_combined = df_combined.replace(np.nan, \" \")\n",
        "\n",
        "# Check the process\n",
        "is_NaN = df_combined.isnull()\n",
        "row_has_NaN = is_NaN.any(axis = 1)\n",
        "rows_with_NaN = df_combined[row_has_NaN]\n",
        "\n",
        "assert len(rows_with_NaN) is 0\n",
        "\n",
        "# Get column names\n",
        "combined_column_names = []\n",
        "for column in df_combined.columns:\n",
        "  combined_column_names.append(column)\n",
        "\n",
        "# 2D array creation for the news based on macros\n",
        "COLUMNS = len(df_combined)\n",
        "news_sum = [[0 for i in range(COLUMNS)] for j in range(int((len(combined_column_names) - 1) / ROWS))]  \n",
        "\n",
        "# Show the column names\n",
        "print(\"Column names of the dataset:\") \n",
        "print(combined_column_names)\n",
        "\n",
        "# Merge the news\n",
        "for row in range(len(df_combined)):\n",
        "  for column in range(int((len(combined_column_names) - 1) / ROWS)):\n",
        "    temp = \"\"\n",
        "    news = \"\"\n",
        "    for word in range(ROWS):\n",
        "      news = df_combined[combined_column_names[(column * ROWS) + (word + 1)]][row]\n",
        "      # Remove the b character at the begining of the string\n",
        "      if news[0] is \"b\":\n",
        "        news = \" \" + news[1:]\n",
        "      temp = temp + news\n",
        "    news_sum[column][row] = temp\n",
        "\n",
        "# Show the first day second package of the news\n",
        "print(\"\\nThe first day second package of the news:\")\n",
        "print(news_sum[1][0])\n",
        "\n",
        "# Drop the old columns\n",
        "for column in range(len(combined_column_names) - 1):\n",
        "  df_combined.drop(combined_column_names[column + 1], axis = 1, inplace = True)\n",
        "\n",
        "# Create the new columns with the merged news\n",
        "for column in range(int((len(combined_column_names) - 1) / ROWS)):\n",
        "  colum_name = \"News_\" + str(column + 1)\n",
        "  df_combined[colum_name] = news_sum[column]\n",
        "\n",
        "news_sum = []\n",
        "label_sum = []\n",
        "\n",
        "# Get the column names\n",
        "combined_column_names = []\n",
        "for column in df_combined.columns:\n",
        "  combined_column_names.append(column)\n",
        "\n",
        "# Write out the column names \n",
        "print(combined_column_names)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Connect the merged news with the labels\n",
        "for column in range(len(df_combined)):\n",
        "  for row in range(len(combined_column_names) - 1):\n",
        "    news_sum.append(df_combined[combined_column_names[row + 1]][column])\n",
        "    label_sum.append(df_combined[combined_column_names[LABEL_COLUMN]][column])\n",
        "\n",
        "# Create the new DataFrame\n",
        "df_sum_news_labels = pd.DataFrame(data = label_sum, index = None, columns = [\"Label\"])\n",
        "df_sum_news_labels[\"News\"] = news_sum\n",
        "\n",
        "# Removing punctuations\n",
        "temp_news = []\n",
        "for line in news_sum:\n",
        "  temp_attach = \"\"\n",
        "  for word in line:\n",
        "    temp = \" \"\n",
        "    if word not in string.punctuation:\n",
        "      temp = word\n",
        "    temp_attach = temp_attach + \"\".join(temp)\n",
        "  temp_news.append(temp_attach)\n",
        "\n",
        "news_sum = temp_news\n",
        "temp_news = []\n",
        "\n",
        "# Remove numbers\n",
        "for line in news_sum:\n",
        "  temp_attach = \"\"\n",
        "  for word in line:\n",
        "    temp = \" \"\n",
        "    if not word.isdigit():\n",
        "      temp = word\n",
        "    temp_attach = temp_attach + \"\".join(temp)\n",
        "  temp_news.append(temp_attach)\n",
        "\n",
        "# Remove space\n",
        "for line in range(len(temp_news)):    \n",
        "  temp_news[line] = \" \".join(temp_news[line].split())\n",
        "\n",
        "# Converting headlines to lower case\n",
        "for line in range(len(temp_news)): \n",
        "    temp_news[line] = temp_news[line].lower()\n",
        "\n",
        "# Update the data frame\n",
        "df_sum_news_labels[\"News\"] = temp_news\n",
        "\n",
        "# Load the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "filtered_sentence = []\n",
        "news_sum = df_sum_news_labels[\"News\"]\n",
        "\n",
        "# Remove stop words\n",
        "for line in news_sum:\n",
        "  word_tokens = word_tokenize(line)\n",
        "  temp_attach = \"\"\n",
        "  for word in word_tokens:\n",
        "    temp = \" \"\n",
        "    if not word in stop_words:\n",
        "      temp = temp + word\n",
        "    temp_attach = temp_attach + \"\".join(temp)\n",
        "  filtered_sentence.append(temp_attach)\n",
        "\n",
        "# Remove space\n",
        "for line in range(len(filtered_sentence)):    \n",
        "  filtered_sentence[line] = \" \".join(filtered_sentence[line].split())\n",
        "\n",
        "# Update the data frame\n",
        "df_sum_news_labels[\"News\"] = filtered_sentence\n",
        "\n",
        "news_sum = df_sum_news_labels[\"News\"]\n",
        "null_indexes = []\n",
        "index = 0\n",
        "\n",
        "for line in news_sum:\n",
        "  if line is \"\":\n",
        "    null_indexes.append(index)\n",
        "  index = index + 1\n",
        "\n",
        "print(null_indexes)\n",
        "\n",
        "for row in null_indexes:\n",
        "  df_sum_news_labels = df_sum_news_labels.drop(row)\n",
        "\n",
        "news_sum = df_sum_news_labels[\"News\"]\n",
        "null_indexes = []\n",
        "index = 0\n",
        "\n",
        "for line in news_sum:\n",
        "  if line is \"\":\n",
        "    null_indexes.append(index)\n",
        "  index = index + 1\n",
        "  \n",
        "assert len(null_indexes) is 0\n",
        "\n",
        "# Do the shuffle\n",
        "for i in range(SHUFFLE_CYCLE):\n",
        "  df_sum_news_labels = shuffle(df_sum_news_labels, random_state = rs)\n",
        "\n",
        "# Reset the index\n",
        "df_sum_news_labels.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# Create datasets\n",
        "news_string = (df_sum_news_labels['News'].values).astype('U')\n",
        " \n",
        "INPUT_SIZE = len(df_sum_news_labels)\n",
        "# 80% train -> 9% valid, 81% train; 10% test\n",
        "TRAIN_SIZE = int(TRAIN_SPLIT * INPUT_SIZE) \n",
        "VALID_SIZE = int(VALIDATION_SPLIT * TRAIN_SIZE)\n",
        "\n",
        "# Create the train data set\n",
        "train_dataset = df_sum_news_labels[:TRAIN_SIZE - VALID_SIZE] \n",
        "\n",
        "# Create the validation data set\n",
        "valid_dataset = df_sum_news_labels[TRAIN_SIZE - VALID_SIZE:TRAIN_SIZE] \n",
        "\n",
        "# Create the test data set\n",
        "test_dataset = df_sum_news_labels[TRAIN_SIZE:]\n",
        "\n",
        "# Save them without the indexes\n",
        "train_dataset.to_csv('drive/MyDrive/train.tsv', sep = '\\t', index=False)\n",
        "valid_dataset.to_csv('drive/MyDrive/valid.tsv', sep = '\\t', index=False)\n",
        "test_dataset.to_csv('drive/MyDrive/test.tsv', sep = '\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column names of the dataset:\n",
            "['Label', 'Top1', 'Top2', 'Top3', 'Top4', 'Top5', 'Top6', 'Top7', 'Top8', 'Top9', 'Top10', 'Top11', 'Top12', 'Top13', 'Top14', 'Top15', 'Top16', 'Top17', 'Top18', 'Top19', 'Top20', 'Top21', 'Top22', 'Top23', 'Top24', 'Top25']\n",
            "\n",
            "The first day second package of the news:\n",
            " 'BREAKING: Musharraf to be impeached.'\n",
            "['Label', 'News_1', 'News_2', 'News_3', 'News_4', 'News_5', 'News_6', 'News_7', 'News_8', 'News_9', 'News_10', 'News_11', 'News_12', 'News_13', 'News_14', 'News_15', 'News_16', 'News_17', 'News_18', 'News_19', 'News_20', 'News_21', 'News_22', 'News_23', 'News_24', 'News_25']\n",
            "\n",
            "\n",
            "[6947, 6948, 6949, 8723, 8724, 13134, 17048, 17049]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo7P2z4vL8_U",
        "outputId": "fb4c1036-59fd-420f-bb33-1926e5a1a763"
      },
      "source": [
        "N_VALUE_RANGE_START = 1\n",
        "N_VALUE_RANGE_END = 3\n",
        "# Vocabulary size\n",
        "MAX_VOCAB_SIZE = 7500\n",
        "\n",
        "def generate_ngrams(input):\n",
        "    n_grams = []\n",
        "    n_values = []\n",
        "    output = []\n",
        "\n",
        "    for n_value in range(N_VALUE_RANGE_START, N_VALUE_RANGE_END + 1):\n",
        "        n_values.append(n_value)\n",
        "\n",
        "    for n_value in n_values:\n",
        "        n_grams.append(set(zip(*[input[i:] for i in range(n_value)])))\n",
        "\n",
        "    for n_gram in n_grams:\n",
        "        for element in n_gram:\n",
        "            output.append(' '.join(element))\n",
        "\n",
        "    return output\n",
        "\n",
        "NEWS = data.Field(#tokenize = 'spacy', \n",
        "                  preprocessing = generate_ngrams,\n",
        "                  #tokenizer_language = 'en_core_web_sm',\n",
        "                  #include_lengths = True)\n",
        ")\n",
        "\n",
        "LABELS = data.LabelField(dtype = torch.float)\n",
        "\n",
        "fields = [('labels', LABELS), ('news', NEWS)]\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "                                        path = \"drive/MyDrive\",\n",
        "                                        train = \"train.tsv\",\n",
        "                                        validation = \"valid.tsv\",\n",
        "                                        test = \"test.tsv\",\n",
        "                                        format = \"tsv\",\n",
        "                                        fields = fields,\n",
        "                                        skip_header = True\n",
        ")\n",
        "\n",
        "NEWS.build_vocab(train_data,\n",
        "                  max_size = MAX_VOCAB_SIZE)\n",
        "\n",
        "LABELS.build_vocab(train_data)\n",
        "\n",
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Show it\n",
        "print(device)\n",
        "\n",
        "#Set the iterators for the data\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    sort_key = lambda x: x.news, #sort by n attribute (quote)\n",
        "    batch_size = 32,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyZwGZ0DGeXd",
        "outputId": "894b6dcf-d730-41c0-b574-406e62d040ad"
      },
      "source": [
        "print('Train:')\n",
        "for batch in train_iterator:\n",
        "    print(batch)\n",
        "    break\n",
        "    \n",
        "print('Valid:')\n",
        "for batch in valid_iterator:\n",
        "    print(batch)\n",
        "    break\n",
        "    \n",
        "print('Test:')\n",
        "for batch in test_iterator:\n",
        "    print(batch)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:\n",
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.labels]:[torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
            "\t[.news]:[torch.cuda.LongTensor of size 86x32 (GPU 0)]\n",
            "Valid:\n",
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.labels]:[torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
            "\t[.news]:[torch.cuda.LongTensor of size 87x32 (GPU 0)]\n",
            "Test:\n",
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.labels]:[torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
            "\t[.news]:[torch.cuda.LongTensor of size 72x32 (GPU 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNpQu9ec_DcP",
        "outputId": "7a358957-7a75-409e-9b5c-f9a5ba2fd0e0"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 4.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 27.2MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 29.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtNKOVJ9_AJN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "f7d79579fa5640de9b8b2a3ad4f0fb70",
            "a84cc744fecc4f619781d7601d013998",
            "fbc1de3bd76245a7b48337174c6743f0",
            "5efa710b50e348bdb10cf6ded81ab0b0",
            "819383e39c6149c58c6969963079c333",
            "c8430553cfb64c7aaf051126a8e11ea8",
            "51eee00483844ae28eb5baa5f78b5cc2",
            "118bbb1d79dc42fa930d25476a17d344",
            "043dfbe5de374416a0d81c911ce75be5",
            "66b5eef22a934d4fabd0b72fe86c2278",
            "e2b56fc87af844bd8e249335c8af4db1",
            "08fb7bc4c621451fbf5e984ae2fdb428",
            "726556e4152f4e6f8b4d1318f17429b9",
            "57accff470674adea7189eb30d7ba07d",
            "24fbe744d23b42cba679fb88e0068757",
            "3477da6d0262402d90fd0394802d3188"
          ]
        },
        "outputId": "40050d2c-bc8c-47aa-9663-55a3821c1c4a"
      },
      "source": [
        "# load pretrained bert\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7d79579fa5640de9b8b2a3ad4f0fb70",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "043dfbe5de374416a0d81c911ce75be5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHpLZdhLL9kc"
      },
      "source": [
        "BERT_HIDDEN_DIM = 128\n",
        "BERT_OUTPUT_DIM = 1\n",
        "BERT_N_LAYERS = 3\n",
        "BERT_BIDIRECTIONAL = True\n",
        "BERT_DROPOUT = 0.25\n",
        "\n",
        "class BERT_Model(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        \n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim) # linear out\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        text = torch.transpose(text,0,1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embedded = self.bert(text)[0] # do not teach the bert layer parameters\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        \n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "        \n",
        "        output = self.out(hidden)\n",
        "        \n",
        "        return output    \n",
        "\n",
        "LSTM_EMBEDDING_DIM = 100\n",
        "LSTM_HIDDEN_DIM = 64\n",
        "LSTM_OUTPUT_DIM = 1\n",
        "LSTM_N_LAYERS = 2\n",
        "LSTM_BIDIRECTIONAL = False\n",
        "LSTM_DROPOUT = 0.1\n",
        "LSTM_INPUT_DIM = len(NEWS.vocab)\n",
        "LSTM_PAD_IDX = NEWS.vocab.stoi[NEWS.pad_token]\n",
        "\n",
        "class LSTM_Model(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers=n_layers, \n",
        "                          bidirectional=bidirectional, \n",
        "                          dropout=dropout)\n",
        "    \n",
        "        self.fc_out = nn.Linear(int(hidden_dim), output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        hidden = self.dropout(hidden[-1,:,:])\n",
        "\n",
        "        return self.fc_out(hidden)\n",
        "\n",
        "class Combined(nn.Module):\n",
        "    def __init__(self, BERT_1, LSTM_1):\n",
        "        super(Combined, self).__init__()\n",
        "        self.BERT = BERT_1\n",
        "\n",
        "        self.LSTM = LSTM_1\n",
        "        \n",
        "        self.fc1 = nn.Linear(2, 4)\n",
        "        self.fc2 = nn.Linear(4, 16)\n",
        "        self.fc3 = nn.Linear(16, 128)\n",
        "        self.fc4 = nn.Linear(128, 256)\n",
        "        self.fc5 = nn.Linear(256, 64)\n",
        "        self.fc6 = nn.Linear(64, 8)\n",
        "        self.fc7 = nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, text):\n",
        "        x1 = self.BERT(text)\n",
        "        x2 = self.LSTM(text)\n",
        "        x = torch.cat((x1, x2), dim=1)\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        x = torch.sigmoid(self.fc4(x))\n",
        "        x = torch.sigmoid(self.fc5(x))\n",
        "        x = torch.sigmoid(self.fc6(x))\n",
        "\n",
        "        return self.fc7(x)\n",
        "\n",
        "# Create models and load state_dicts    \n",
        "BERT = BERT_Model(bert,\n",
        "                        BERT_HIDDEN_DIM,\n",
        "                        BERT_OUTPUT_DIM,\n",
        "                        BERT_N_LAYERS,\n",
        "                        BERT_BIDIRECTIONAL,\n",
        "                        BERT_DROPOUT)\n",
        "\n",
        "LSTM = LSTM_Model(LSTM_INPUT_DIM, \n",
        "                        LSTM_EMBEDDING_DIM, \n",
        "                        LSTM_HIDDEN_DIM, \n",
        "                        LSTM_OUTPUT_DIM, \n",
        "                        LSTM_N_LAYERS, \n",
        "                        LSTM_BIDIRECTIONAL, \n",
        "                        LSTM_DROPOUT, \n",
        "                        LSTM_PAD_IDX)\n",
        "# Load state dicts\n",
        "BERT.load_state_dict(torch.load('drive/MyDrive/bert_best_model.pt'))\n",
        "LSTM.load_state_dict(torch.load('drive/MyDrive/lstm_best-model.pt'))\n",
        "\n",
        "model = Combined(BERT, LSTM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZOlLjQuB8GC",
        "outputId": "220aafdd-a536-4024-ec33-13c540c54adc"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,161,127 parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT7hLteBCCk9",
        "outputId": "c036bc78-cdd9-4434-c9f0-975bfbc29e51"
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('BERT'):\n",
        "        param.requires_grad = False\n",
        "    if name.startswith('LSTM'):\n",
        "        param.requires_grad = False    \n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 52,269 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRUN57s2ChtJ",
        "outputId": "f6d6286a-cbb1-43a9-9132-8c87ebc2c16d"
      },
      "source": [
        "UNK_IDX = NEWS.vocab.stoi[NEWS.unk_token]\n",
        "\n",
        "model.LSTM.embedding.weight.data[UNK_IDX] = torch.zeros(LSTM_EMBEDDING_DIM)\n",
        "model.LSTM.embedding.weight.data[LSTM_PAD_IDX] = torch.zeros(LSTM_EMBEDDING_DIM)\n",
        "\n",
        "print(model.LSTM.embedding.weight.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-1.2893e+00,  3.1971e-01, -1.1178e+00,  ..., -1.0642e+00,\n",
            "         -7.8712e-01,  2.9927e-01],\n",
            "        ...,\n",
            "        [-9.5515e-01,  1.4307e-03,  7.2091e-01,  ...,  2.8553e-01,\n",
            "          3.5123e-01,  8.5332e-02],\n",
            "        [ 1.7967e+00, -4.4204e-01, -2.2764e-01,  ..., -1.3371e+00,\n",
            "         -1.8561e+00,  4.4284e-02],\n",
            "        [-9.3392e-01, -1.0174e+00,  1.7149e-01,  ..., -1.1119e+00,\n",
            "         -8.8879e-01, -8.2188e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6fnXmlxC7tI"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smHGkrAzC-Kd"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdKZw1ePC_7C"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train() # turn on drop out\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text = batch.news\n",
        "\n",
        "        predictions = model(text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.labels)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMkbEBFXDBcq"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval() # turn off drop out\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text = batch.news\n",
        "            \n",
        "            predictions = model(text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8PYY4B4DCxZ"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODF8iNDsDEUb",
        "outputId": "8119e18e-d83e-40f0-edd8-dfe223b3d84d"
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "no_improve_counter = 0\n",
        "last_valid_acc = 0\n",
        "\n",
        "train_loss_array = []\n",
        "train_acc_array = []\n",
        "valid_loss_array = []\n",
        "valid_acc_array = []\n",
        "\n",
        "for epoch in range(100):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_loss_array.append(train_loss)\n",
        "    train_acc_array.append(train_acc)\n",
        "    valid_loss_array.append(valid_loss)\n",
        "    valid_acc_array.append(valid_acc)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'drive/MyDrive/comb_best-model.pt')\n",
        "\n",
        "    # early leave\n",
        "    no_improvements = \"\"\n",
        "\n",
        "    if last_valid_acc > valid_acc:\n",
        "        best_valid_loss = valid_loss\n",
        "        no_improve_counter = no_improve_counter + 1\n",
        "        no_improvements = \"| There were no improvements on the validation set!\"\n",
        "    else:\n",
        "        no_improve_counter = 0\n",
        "\n",
        "    last_valid_acc = valid_acc\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s {no_improvements}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    if no_improve_counter is 5:\n",
        "      print(f'The model is not improving, going to stop.')\n",
        "      break\n",
        "\n",
        "    if train_acc > 0.95:\n",
        "      print(f'The model training is finished.')\n",
        "      break  \n",
        "    \n",
        "    torch.save(model.state_dict(), 'drive/MyDrive/comb_last-model.pt')     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 6m 59s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.36%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 02 | Epoch Time: 6m 59s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.35%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 03 | Epoch Time: 6m 58s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.42%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 04 | Epoch Time: 6m 59s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.41%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.93%\n",
            "Epoch: 05 | Epoch Time: 6m 59s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.29%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.93%\n",
            "Epoch: 06 | Epoch Time: 6m 59s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.42%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 07 | Epoch Time: 6m 58s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.30%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 08 | Epoch Time: 7m 0s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.31%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 09 | Epoch Time: 6m 53s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.23%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 10 | Epoch Time: 6m 51s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.29%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 11 | Epoch Time: 6m 53s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.41%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 12 | Epoch Time: 6m 51s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.31%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.93%\n",
            "Epoch: 13 | Epoch Time: 6m 53s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.16%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 14 | Epoch Time: 7m 0s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.29%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.93%\n",
            "Epoch: 15 | Epoch Time: 6m 53s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.35%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 16 | Epoch Time: 6m 53s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.41%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.93%\n",
            "Epoch: 17 | Epoch Time: 6m 53s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.04%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 18 | Epoch Time: 6m 54s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.23%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 53.93%\n",
            "Epoch: 19 | Epoch Time: 6m 49s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.34%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.93%\n",
            "Epoch: 20 | Epoch Time: 6m 53s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.32%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 21 | Epoch Time: 6m 53s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.42%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 22 | Epoch Time: 6m 58s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.41%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.93%\n",
            "Epoch: 23 | Epoch Time: 6m 59s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.42%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 24 | Epoch Time: 6m 59s | There were no improvements on the validation set!\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.30%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 46.07%\n",
            "Epoch: 25 | Epoch Time: 6m 58s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.10%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 53.93%\n",
            "Epoch: 26 | Epoch Time: 6m 59s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.41%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.93%\n",
            "Epoch: 27 | Epoch Time: 6m 59s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.03%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.93%\n",
            "Epoch: 28 | Epoch Time: 6m 57s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.37%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.93%\n",
            "Epoch: 29 | Epoch Time: 6m 59s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.28%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 30 | Epoch Time: 6m 59s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.32%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 31 | Epoch Time: 7m 0s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.28%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 32 | Epoch Time: 6m 59s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.30%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.93%\n",
            "Epoch: 33 | Epoch Time: 6m 59s \n",
            "\tTrain Loss: 0.691 | Train Acc: 53.33%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.93%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EBw5_mLDGhc"
      },
      "source": [
        "# Visualize the training\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.title('Train and validation loss')\n",
        "plt.plot(train_loss_array, color = \"green\", label = \"Train loss\")\n",
        "plt.plot(valid_loss_array, color = \"blue\", label = \"Valid loss\")\n",
        "plt.xlabel('Epoch',fontsize=18)\n",
        "plt.ylabel('Loss',fontsize=18)\n",
        "plt.legend(fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KR8NZ7fDHs-"
      },
      "source": [
        "# Visualize the training\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.title('Train and validation accuraccy')\n",
        "plt.plot(train_acc_array, color = \"green\", label = \"Train accuracy\")\n",
        "plt.plot(valid_acc_array, color = \"blue\", label = \"Valid accuracy\")\n",
        "plt.xlabel('Epoch',fontsize=18)\n",
        "plt.ylabel('Accuracy (%)',fontsize=18)\n",
        "plt.legend(fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt2d_Ds9DI4O"
      },
      "source": [
        "model.load_state_dict(torch.load('drive/MyDrive/comb_best-model.pt', map_location=torch.device('cpu')))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'-- Best model --')\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "\n",
        "model.load_state_dict(torch.load('drive/MyDrive/comb_last-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'\\n-- Last model --')\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrMNIbReDPSz"
      },
      "source": [
        "model.load_state_dict(torch.load('drive/MyDrive/comb_best-model.pt'))\n",
        "\n",
        "model.eval() # turn off drop out\n",
        "\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "# Collect predictions and labels\n",
        "for batch in test_iterator:\n",
        "  text = batch.news\n",
        "\n",
        "  predictions.append(model(text).squeeze(1))\n",
        "\n",
        "  labels.append(batch.labels)\n",
        "\n",
        "# Convert to numpy\n",
        "pred_tensor = torch.cat(predictions).cpu()\n",
        "labels_tensor = torch.cat(labels).cpu()\n",
        "\n",
        "# Get the metrics\n",
        "fpr, tpr, threshold = metrics.roc_curve(labels_tensor.detach().numpy(), pred_tensor.detach().numpy())\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.title('Receiver Operating Characteristic of the best model', fontsize = 18)\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right', fontsize = 18)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate', fontsize = 18)\n",
        "plt.xlabel('False Positive Rate', fontsize = 18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b4ENm97DSMo"
      },
      "source": [
        "model.load_state_dict(torch.load('drive/MyDrive/comb_last-model.pt'))\n",
        "\n",
        "model.eval() # turn off drop out\n",
        "\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "# Collect predictions and labels\n",
        "for batch in test_iterator:\n",
        "  text = batch.news\n",
        "\n",
        "  predictions.append(model(text).squeeze(1))\n",
        "\n",
        "  labels.append(batch.labels)\n",
        "\n",
        "# Convert to numpy\n",
        "pred_tensor = torch.cat(predictions).cpu()\n",
        "labels_tensor = torch.cat(labels).cpu()\n",
        "\n",
        "# Get the metrics\n",
        "fpr, tpr, threshold = metrics.roc_curve(labels_tensor.detach().numpy(), pred_tensor.detach().numpy())\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.title('Receiver Operating Characteristic of the last model', fontsize = 18)\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right', fontsize = 18)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate', fontsize = 18)\n",
        "plt.xlabel('False Positive Rate', fontsize = 18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}