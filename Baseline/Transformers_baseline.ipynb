{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers_baseline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a60eb31570e84f6091c535ff6f7e4671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03514938a55c44269b4fdbec1d8deb2f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1df641a8eba84f189f68d531d77b39ef",
              "IPY_MODEL_ef0a13bbb0bc4feca89a141b87e99c9e"
            ]
          }
        },
        "03514938a55c44269b4fdbec1d8deb2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1df641a8eba84f189f68d531d77b39ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e829173f6c14d66ba433dfccd167299",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad33a671990c4e1db5a56909433bf53d"
          }
        },
        "ef0a13bbb0bc4feca89a141b87e99c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d108fa816b404055b86114e8720139df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 422kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e330d2e717ba4c3b90072b7ec5a4ad1b"
          }
        },
        "7e829173f6c14d66ba433dfccd167299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad33a671990c4e1db5a56909433bf53d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d108fa816b404055b86114e8720139df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e330d2e717ba4c3b90072b7ec5a4ad1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "607427b7e1094173b99b1de6fbdaf611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e1bdd02bf254f0aab81bb597cac4049",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d20fc5899760468c8467a4a534cf1f54",
              "IPY_MODEL_7df1d8ec7cee4954a0da89bbbfd53eae"
            ]
          }
        },
        "9e1bdd02bf254f0aab81bb597cac4049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d20fc5899760468c8467a4a534cf1f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a41c65ae66f34bbd8b170a8b10a0e2a5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccdfb340e5c14516809c87b297946e0b"
          }
        },
        "7df1d8ec7cee4954a0da89bbbfd53eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40bea8462bba49dda211e4853171a5a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 136B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f6aef8bc11240d88b032a97c51d9373"
          }
        },
        "a41c65ae66f34bbd8b170a8b10a0e2a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccdfb340e5c14516809c87b297946e0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40bea8462bba49dda211e4853171a5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f6aef8bc11240d88b032a97c51d9373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4cb4bb7b65742cd98b938d61c954262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_58e920da37314578ad67bb632ecd7222",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bfb0479093fb4738ae4e1b0975cdf6d0",
              "IPY_MODEL_87fc80418a2946688e9e5eae94c8fee5"
            ]
          }
        },
        "58e920da37314578ad67bb632ecd7222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfb0479093fb4738ae4e1b0975cdf6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0341515547546ea95b97c76b3d652f8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a498fb5987b4aefb0624f35b7463f88"
          }
        },
        "87fc80418a2946688e9e5eae94c8fee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9dd6256d1f24623be153a61f77068e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 2.61MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2dd289502394f41a368ae3e4039c285"
          }
        },
        "b0341515547546ea95b97c76b3d652f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a498fb5987b4aefb0624f35b7463f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9dd6256d1f24623be153a61f77068e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2dd289502394f41a368ae3e4039c285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa897b2b8f414db093b3979e8d03ed31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_414d313b0d824e27977ec04790cafd37",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91d39dac9e514e8192d28de4b0c48dc8",
              "IPY_MODEL_8626dddb2a5c4da7b2dd9075a22263fe"
            ]
          }
        },
        "414d313b0d824e27977ec04790cafd37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91d39dac9e514e8192d28de4b0c48dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6dfc1670e5ca441293223a4f08eef651",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_227fc556f9cb4bdcb395aa8374aaaefb"
          }
        },
        "8626dddb2a5c4da7b2dd9075a22263fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e87eb43db5c401ea61093b1639c36c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:01&lt;00:00, 413B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79e5a832913b4123853e87d527fb35b4"
          }
        },
        "6dfc1670e5ca441293223a4f08eef651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "227fc556f9cb4bdcb395aa8374aaaefb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e87eb43db5c401ea61093b1639c36c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79e5a832913b4123853e87d527fb35b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca7c14fa4e524ec49b994c0f7a2f5584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af77a3965d794323b41385e078827777",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f68d761aa7e459e96618f4e52146d02",
              "IPY_MODEL_c91315d717094746a891404acadda1d8"
            ]
          }
        },
        "af77a3965d794323b41385e078827777": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f68d761aa7e459e96618f4e52146d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a44b995cc085493bb47b5f614dbe3a25",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5d53a08b69f40a48cdf00adad19a090"
          }
        },
        "c91315d717094746a891404acadda1d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3b2d7902dab345cca810cb8817b0095c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:11&lt;00:00, 39.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ef7c4fd4b4247ef8d5d13f6ca40eeaf"
          }
        },
        "a44b995cc085493bb47b5f614dbe3a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5d53a08b69f40a48cdf00adad19a090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b2d7902dab345cca810cb8817b0095c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ef7c4fd4b4247ef8d5d13f6ca40eeaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2DvYi9nlR8K"
      },
      "source": [
        "# **Stock market news feed semantic analysis** *(Baseline Transformers)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X44-bETwIEX"
      },
      "source": [
        "* https://colab.research.google.com/github/bentrevett/pytorch-sentiment-analysis/blob/master/6%20-%20Transformers%20for%20Sentiment%20Analysis.ipynb#scrollTo=IUvWqEq1oV7k\n",
        "* https://arxiv.org/abs/1706.03762\n",
        "* https://arxiv.org/abs/1810.04805"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcEws0Fnlk2Q"
      },
      "source": [
        "## **A projekt előkészítése**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV6Q5qolmwuK",
        "outputId": "36d90dde-7388-4854-df30-70f15f0ecba5"
      },
      "source": [
        "# attach drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE1iYb7HqpWj"
      },
      "source": [
        "https://www.kaggle.com/aaron7sun/stocknews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMrafiHCqqlX"
      },
      "source": [
        "# Copy the dataset to the local environment\n",
        "!cp \"/content/drive/MyDrive/Combined_News_DJIA.csv\" \"Combined_News_DJIA.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBEvM_cvqzAt"
      },
      "source": [
        "# set imports\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_datareader as web\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfzWnWTorBK6"
      },
      "source": [
        "# Number of merged news into one string\n",
        "ROWS = 1 # because of the max length for bert, if removing stop words and punctations will increase\n",
        "\n",
        "# Shuffle cycle number for the dataframe\n",
        "SHUFFLE_CYCLE = 500\n",
        "\n",
        "# Numpy random seed\n",
        "NP_SEED = 1234\n",
        "\n",
        "# Torch seed\n",
        "TORCH_SEED = 1234\n",
        "\n",
        "# Train percentage (train + valid)\n",
        "TRAIN_SPLIT = 0.75\n",
        "\n",
        "# Only validation split\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoDwYNWNq2ya"
      },
      "source": [
        "# set seeds for reproduce\n",
        "random.seed(NP_SEED)\n",
        "torch.manual_seed(TORCH_SEED)\n",
        "np.random.seed(NP_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed_all(TORCH_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw7WNXFTreMM"
      },
      "source": [
        "A Transformers telepítése és importálása."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5fdCNzGrLhk",
        "outputId": "2c4704e1-ade3-4f6e-c4ca-c6802511660f"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 20.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 17.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=74f7a929a1ec87ec72d245917e1a8671496c46be18236eabaf0021e4e3865f87\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "154-jSH9rhtW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "a60eb31570e84f6091c535ff6f7e4671",
            "03514938a55c44269b4fdbec1d8deb2f",
            "1df641a8eba84f189f68d531d77b39ef",
            "ef0a13bbb0bc4feca89a141b87e99c9e",
            "7e829173f6c14d66ba433dfccd167299",
            "ad33a671990c4e1db5a56909433bf53d",
            "d108fa816b404055b86114e8720139df",
            "e330d2e717ba4c3b90072b7ec5a4ad1b",
            "607427b7e1094173b99b1de6fbdaf611",
            "9e1bdd02bf254f0aab81bb597cac4049",
            "d20fc5899760468c8467a4a534cf1f54",
            "7df1d8ec7cee4954a0da89bbbfd53eae",
            "a41c65ae66f34bbd8b170a8b10a0e2a5",
            "ccdfb340e5c14516809c87b297946e0b",
            "40bea8462bba49dda211e4853171a5a5",
            "2f6aef8bc11240d88b032a97c51d9373",
            "b4cb4bb7b65742cd98b938d61c954262",
            "58e920da37314578ad67bb632ecd7222",
            "bfb0479093fb4738ae4e1b0975cdf6d0",
            "87fc80418a2946688e9e5eae94c8fee5",
            "b0341515547546ea95b97c76b3d652f8",
            "1a498fb5987b4aefb0624f35b7463f88",
            "b9dd6256d1f24623be153a61f77068e9",
            "e2dd289502394f41a368ae3e4039c285"
          ]
        },
        "outputId": "fe674b2a-c0b4-481f-bc3b-46a69b47d169"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a60eb31570e84f6091c535ff6f7e4671",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "607427b7e1094173b99b1de6fbdaf611",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4cb4bb7b65742cd98b938d61c954262",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPgJAl5Z3yhQ"
      },
      "source": [
        "Torchtext frissítése és importálása."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBsvIiBc30k1",
        "outputId": "091f7430-c54c-4421-dc32-ac52d91d9a6d"
      },
      "source": [
        "pip install torchtext==0.4.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████▏                         | 10kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (1.8.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0) (1.24.3)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.9.0\n",
            "    Uninstalling torchtext-0.9.0:\n",
            "      Successfully uninstalled torchtext-0.9.0\n",
            "Successfully installed torchtext-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48lwXlmW346d"
      },
      "source": [
        "from torchtext import data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7oxCaAQrph-"
      },
      "source": [
        "## **Az adathalmaz előkészítése**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPOtZf4dsrJG",
        "outputId": "97ab5098-3b0f-4389-9e85-f3d53e170d09"
      },
      "source": [
        "# Load the dataset \n",
        "df_combined = pd.read_csv('Combined_News_DJIA.csv', index_col = \"Date\")\n",
        "\n",
        "# Show the dataframe\n",
        "df_combined.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Top1</th>\n",
              "      <th>Top2</th>\n",
              "      <th>Top3</th>\n",
              "      <th>Top4</th>\n",
              "      <th>Top5</th>\n",
              "      <th>Top6</th>\n",
              "      <th>Top7</th>\n",
              "      <th>Top8</th>\n",
              "      <th>Top9</th>\n",
              "      <th>Top10</th>\n",
              "      <th>Top11</th>\n",
              "      <th>Top12</th>\n",
              "      <th>Top13</th>\n",
              "      <th>Top14</th>\n",
              "      <th>Top15</th>\n",
              "      <th>Top16</th>\n",
              "      <th>Top17</th>\n",
              "      <th>Top18</th>\n",
              "      <th>Top19</th>\n",
              "      <th>Top20</th>\n",
              "      <th>Top21</th>\n",
              "      <th>Top22</th>\n",
              "      <th>Top23</th>\n",
              "      <th>Top24</th>\n",
              "      <th>Top25</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-08-08</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
              "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
              "      <td>b'Russian tanks are moving towards the capital...</td>\n",
              "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
              "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
              "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
              "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
              "      <td>b'Georgian troops retreat from S. Osettain cap...</td>\n",
              "      <td>b'Did the U.S. Prep Georgia for War with Russia?'</td>\n",
              "      <td>b'Rice Gives Green Light for Israel to Attack ...</td>\n",
              "      <td>b'Announcing:Class Action Lawsuit on Behalf of...</td>\n",
              "      <td>b\"So---Russia and Georgia are at war and the N...</td>\n",
              "      <td>b\"China tells Bush to stay out of other countr...</td>\n",
              "      <td>b'Did World War III start today?'</td>\n",
              "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
              "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
              "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
              "      <td>b'This is a busy day:  The European Union has ...</td>\n",
              "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
              "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
              "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
              "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
              "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
              "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-11</th>\n",
              "      <td>1</td>\n",
              "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
              "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
              "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
              "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
              "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
              "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
              "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
              "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
              "      <td>b'Welcome To World War IV! Now In High Definit...</td>\n",
              "      <td>b\"Georgia's move, a mistake of monumental prop...</td>\n",
              "      <td>b'Russia presses deeper into Georgia; U.S. say...</td>\n",
              "      <td>b'Abhinav Bindra wins first ever Individual Ol...</td>\n",
              "      <td>b' U.S. ship heads for Arctic to define territ...</td>\n",
              "      <td>b'Drivers in a Jerusalem taxi station threaten...</td>\n",
              "      <td>b'The French Team is Stunned by Phelps and the...</td>\n",
              "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
              "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
              "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
              "      <td>b'China to overtake US as largest manufacturer'</td>\n",
              "      <td>b'War in South Ossetia [PICS]'</td>\n",
              "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
              "      <td>b' Russia has just beaten the United States ov...</td>\n",
              "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
              "      <td>b'Russia is so much better at war'</td>\n",
              "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-12</th>\n",
              "      <td>0</td>\n",
              "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
              "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
              "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
              "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
              "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
              "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
              "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
              "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
              "      <td>b\"The US military was surprised by the timing ...</td>\n",
              "      <td>b'U.S. Beats War Drum as Iran Dumps the Dollar'</td>\n",
              "      <td>b'Gorbachev: \"Georgian military attacked the S...</td>\n",
              "      <td>b'CNN use footage of Tskhinvali ruins to cover...</td>\n",
              "      <td>b'Beginning a war as the Olympics were opening...</td>\n",
              "      <td>b'55 pyramids as large as the Luxor stacked in...</td>\n",
              "      <td>b'The 11 Top Party Cities in the World'</td>\n",
              "      <td>b'U.S. troops still in Georgia (did you know t...</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
              "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
              "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
              "      <td>b'War in Georgia: The Israeli connection'</td>\n",
              "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
              "      <td>b'Christopher King argues that the US and NATO...</td>\n",
              "      <td>b'America: The New Mexico?'</td>\n",
              "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-13</th>\n",
              "      <td>0</td>\n",
              "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
              "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
              "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
              "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
              "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
              "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
              "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
              "      <td>b'Russian forces sink Georgian ships '</td>\n",
              "      <td>b\"The commander of a Navy air reconnaissance s...</td>\n",
              "      <td>b\"92% of CNN readers: Russia's actions in Geor...</td>\n",
              "      <td>b'USA to send fleet into Black Sea to help Geo...</td>\n",
              "      <td>b\"US warns against Israeli plan to strike agai...</td>\n",
              "      <td>b\"In an intriguing cyberalliance, two Estonian...</td>\n",
              "      <td>b'The CNN Effect: Georgia Schools Russia in In...</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Elephants extinct by 2020?'</td>\n",
              "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
              "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
              "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
              "      <td>b'Israeli defence minister: US against strike ...</td>\n",
              "      <td>b'Gorbachev: We Had No Choice'</td>\n",
              "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
              "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
              "      <td>b'Georgian president  says US military will ta...</td>\n",
              "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-14</th>\n",
              "      <td>1</td>\n",
              "      <td>b'All the experts admit that we should legalis...</td>\n",
              "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
              "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
              "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
              "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
              "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
              "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
              "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
              "      <td>b'Russia exaggerating South Ossetian death tol...</td>\n",
              "      <td>b' Musharraf expected to resign rather than fa...</td>\n",
              "      <td>b'Moscow Made Plans Months Ago to Invade Georgia'</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Nigeria has handed over the potentially oil-...</td>\n",
              "      <td>b'The US and Poland have agreed a preliminary ...</td>\n",
              "      <td>b'Russia apparently is sabotaging infrastructu...</td>\n",
              "      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n",
              "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
              "      <td>b'War in the Caucasus is as much the product o...</td>\n",
              "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
              "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
              "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
              "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
              "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
              "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
              "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Label  ...                                              Top25\n",
              "Date               ...                                                   \n",
              "2008-08-08      0  ...           b\"No Help for Mexico's Kidnapping Surge\"\n",
              "2008-08-11      1  ...  b\"So this is what it's come to: trading sex fo...\n",
              "2008-08-12      0  ...  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...\n",
              "2008-08-13      0  ...  b'2006: Nobel laureate Aleksander Solzhenitsyn...\n",
              "2008-08-14      1  ...  b'Philippines : Peace Advocate say Muslims nee...\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wotqIbyyxsrz"
      },
      "source": [
        "# Find the cells with NaN and after the rows for them\n",
        "is_NaN = df_combined.isnull()\n",
        "row_has_NaN = is_NaN.any(axis = 1)\n",
        "rows_with_NaN = df_combined[row_has_NaN]\n",
        "\n",
        "# Replace them\n",
        "df_combined = df_combined.replace(np.nan, \" \")\n",
        "\n",
        "# Check the process\n",
        "is_NaN = df_combined.isnull()\n",
        "row_has_NaN = is_NaN.any(axis = 1)\n",
        "rows_with_NaN = df_combined[row_has_NaN]\n",
        "\n",
        "assert len(rows_with_NaN) is 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0laCgraz7cw",
        "outputId": "a32dcd43-5ceb-4c99-9d9c-8e43d0606038"
      },
      "source": [
        "# correct the wrong labels in the dataset\n",
        "\n",
        "# Load the stock data\n",
        "df_stock = web.DataReader(\"DJIA\", data_source=\"yahoo\", start=\"2008-08-08\", \n",
        "                          end=\"2016-07-01\")\n",
        "\n",
        "temp_day = []\n",
        "\n",
        "for day in range(len(df_stock)):\n",
        "    temp_day.append(df_stock.index[day].date())\n",
        "\n",
        "df_stock.index = temp_day\n",
        "\n",
        "difference = []\n",
        "\n",
        "if len(df_combined) == len(df_stock):\n",
        "    print(\"The lengths are the same!\")\n",
        "\n",
        "for day in range(max(len(df_combined), len(df_stock))):\n",
        "    if str(df_combined.index[day]) != str(df_stock.index[day]):\n",
        "        print(\"There is difference at: \" + str(day) + \" index\")\n",
        "        print(\"News: \" + str(df_combined.index[day]) + \"\\tStock: \" + str(df_stock.index[day]))\n",
        "        difference.append(day)\n",
        "\n",
        "if len(difference) is 0:\n",
        "    print(\"The dates matched!\")\n",
        "\n",
        "    difference = []\n",
        "\n",
        "for day in range(len(df_stock)):\n",
        "    # label should be 1 -> rise\n",
        "    if int(df_stock[\"Adj Close\"][day]) >= int(df_stock[\"Adj Close\"][day - 1]):\n",
        "        if df_combined[\"Label\"][day] != 1:\n",
        "            difference.append(str(df_stock.index[day]))\n",
        "            print(\"Problem at day \" + str(df_stock.index[day]))\n",
        "            print(\"Today: \" + str(df_stock[\"Adj Close\"][day]) +\"\\t\\tYesterday: \" + str(df_stock[\"Adj Close\"][day - 1]) + \"\\t\\tLabel: \" + str(df_combined[\"Label\"][day]) + \"\\n\")\n",
        "\n",
        "    # label should be 0 -> fall\n",
        "    if int(df_stock[\"Adj Close\"][day]) < int(df_stock[\"Adj Close\"][day - 1]):\n",
        "        if df_combined[\"Label\"][day] != 0:\n",
        "            difference.append(str(df_stock.index[day]))\n",
        "            print(\"Problem at day \" + str(df_stock.index[day]))\n",
        "            print(\"Today: \" + str(df_stock[\"Adj Close\"][day]) +\"\\t\\tYesterday: \" + str(df_stock[\"Adj Close\"][day - 1]) + \"\\t\\tLabel: \" + str(df_combined[\"Label\"][day]) + \"\\n\")\n",
        "\n",
        "print(\"All differences: \" + str(len(difference))) \n",
        "\n",
        "# correct the wrong labels\n",
        "for row in difference:\n",
        "    if df_combined.loc[row, \"Label\"] == 0:\n",
        "        df_combined.loc[row, \"Label\"] = 1\n",
        "    else:\n",
        "        df_combined.loc[row, \"Label\"] = 0\n",
        "\n",
        "# check them\n",
        "for row in difference:\n",
        "    print(str(row) + \"\\t\\t\" + str(df_combined.loc[row, \"Label\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The lengths are the same!\n",
            "The dates matched!\n",
            "Problem at day 2010-10-14\n",
            "Today: 11096.919921875\t\tYesterday: 11096.080078125\t\tLabel: 0\n",
            "\n",
            "Problem at day 2012-11-12\n",
            "Today: 12815.080078125\t\tYesterday: 12815.3896484375\t\tLabel: 0\n",
            "\n",
            "Problem at day 2012-11-15\n",
            "Today: 12570.9501953125\t\tYesterday: 12570.9501953125\t\tLabel: 0\n",
            "\n",
            "Problem at day 2013-04-12\n",
            "Today: 14865.0595703125\t\tYesterday: 14865.1396484375\t\tLabel: 0\n",
            "\n",
            "Problem at day 2014-04-24\n",
            "Today: 16501.650390625\t\tYesterday: 16501.650390625\t\tLabel: 0\n",
            "\n",
            "Problem at day 2015-08-12\n",
            "Today: 17402.509765625\t\tYesterday: 17402.83984375\t\tLabel: 0\n",
            "\n",
            "Problem at day 2015-11-27\n",
            "Today: 17813.390625\t\tYesterday: 17813.390625\t\tLabel: 0\n",
            "\n",
            "All differences: 7\n",
            "2010-10-14\t\t1\n",
            "2012-11-12\t\t1\n",
            "2012-11-15\t\t1\n",
            "2013-04-12\t\t1\n",
            "2014-04-24\t\t1\n",
            "2015-08-12\t\t1\n",
            "2015-11-27\t\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECRy_XVEyEkg",
        "outputId": "fc09eae1-54ae-4fe9-a407-1519353218f1"
      },
      "source": [
        "# combine the news and remove the 'b' char at the beginning\n",
        "# no other preprocess, the tokenizer will take care of it\n",
        "\n",
        "# Get column names\n",
        "combined_column_names = []\n",
        "for column in df_combined.columns:\n",
        "  combined_column_names.append(column)\n",
        "\n",
        "# 2D array creation for the news based on macros\n",
        "COLUMNS = len(df_combined)\n",
        "news_sum = [[0 for i in range(COLUMNS)] for j in range(int((len(combined_column_names) - 1) / ROWS))]  \n",
        "\n",
        "# Merge the news\n",
        "for row in range(len(df_combined)):\n",
        "  for column in range(int((len(combined_column_names) - 1) / ROWS)):\n",
        "    temp = \"\"\n",
        "    news = \"\"\n",
        "    for word in range(ROWS):\n",
        "      news = df_combined[combined_column_names[(column * ROWS) + (word + 1)]][row]\n",
        "      # Remove the b character at the begining of the string\n",
        "      if news[0] is \"b\":\n",
        "        news = \" \" + news[1:]\n",
        "      temp = temp + news\n",
        "    news_sum[column][row] = temp\n",
        "\n",
        "# Drop the old columns\n",
        "for column in range(len(combined_column_names) - 1):\n",
        "  df_combined.drop(combined_column_names[column + 1], axis = 1, inplace = True)\n",
        "\n",
        "# Create the new columns with the merged news\n",
        "for column in range(int((len(combined_column_names) - 1) / ROWS)):\n",
        "  colum_name = \"News_\" + str(column + 1)\n",
        "  df_combined[colum_name] = news_sum[column]\n",
        "\n",
        "# Show the DataFrame\n",
        "df_combined.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News_1</th>\n",
              "      <th>News_2</th>\n",
              "      <th>News_3</th>\n",
              "      <th>News_4</th>\n",
              "      <th>News_5</th>\n",
              "      <th>News_6</th>\n",
              "      <th>News_7</th>\n",
              "      <th>News_8</th>\n",
              "      <th>News_9</th>\n",
              "      <th>News_10</th>\n",
              "      <th>News_11</th>\n",
              "      <th>News_12</th>\n",
              "      <th>News_13</th>\n",
              "      <th>News_14</th>\n",
              "      <th>News_15</th>\n",
              "      <th>News_16</th>\n",
              "      <th>News_17</th>\n",
              "      <th>News_18</th>\n",
              "      <th>News_19</th>\n",
              "      <th>News_20</th>\n",
              "      <th>News_21</th>\n",
              "      <th>News_22</th>\n",
              "      <th>News_23</th>\n",
              "      <th>News_24</th>\n",
              "      <th>News_25</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-08-08</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "      <td>'BREAKING: Musharraf to be impeached.'</td>\n",
              "      <td>'Russia Today: Columns of troops roll into So...</td>\n",
              "      <td>'Russian tanks are moving towards the capital...</td>\n",
              "      <td>\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
              "      <td>'150 Russian tanks have entered South Ossetia...</td>\n",
              "      <td>\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
              "      <td>\"The 'enemy combatent' trials are nothing but...</td>\n",
              "      <td>'Georgian troops retreat from S. Osettain cap...</td>\n",
              "      <td>'Did the U.S. Prep Georgia for War with Russia?'</td>\n",
              "      <td>'Rice Gives Green Light for Israel to Attack ...</td>\n",
              "      <td>'Announcing:Class Action Lawsuit on Behalf of...</td>\n",
              "      <td>\"So---Russia and Georgia are at war and the N...</td>\n",
              "      <td>\"China tells Bush to stay out of other countr...</td>\n",
              "      <td>'Did World War III start today?'</td>\n",
              "      <td>'Georgia Invades South Ossetia - if Russia ge...</td>\n",
              "      <td>'Al-Qaeda Faces Islamist Backlash'</td>\n",
              "      <td>'Condoleezza Rice: \"The US would not act to p...</td>\n",
              "      <td>'This is a busy day:  The European Union has ...</td>\n",
              "      <td>\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
              "      <td>'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
              "      <td>'Caucasus in crisis: Georgia invades South Os...</td>\n",
              "      <td>'Indian shoe manufactory  - And again in a se...</td>\n",
              "      <td>'Visitors Suffering from Mental Illnesses Ban...</td>\n",
              "      <td>\"No Help for Mexico's Kidnapping Surge\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-11</th>\n",
              "      <td>1</td>\n",
              "      <td>'Why wont America and Nato help us? If they w...</td>\n",
              "      <td>'Bush puts foot down on Georgian conflict'</td>\n",
              "      <td>\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
              "      <td>'Georgian army flees in disarray as Russians ...</td>\n",
              "      <td>\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
              "      <td>'What were the Mossad with fraudulent New Zea...</td>\n",
              "      <td>'Russia angered by Israeli military sale to G...</td>\n",
              "      <td>'An American citizen living in S.Ossetia blam...</td>\n",
              "      <td>'Welcome To World War IV! Now In High Definit...</td>\n",
              "      <td>\"Georgia's move, a mistake of monumental prop...</td>\n",
              "      <td>'Russia presses deeper into Georgia; U.S. say...</td>\n",
              "      <td>'Abhinav Bindra wins first ever Individual Ol...</td>\n",
              "      <td>' U.S. ship heads for Arctic to define territ...</td>\n",
              "      <td>'Drivers in a Jerusalem taxi station threaten...</td>\n",
              "      <td>'The French Team is Stunned by Phelps and the...</td>\n",
              "      <td>'Israel and the US behind the Georgian aggres...</td>\n",
              "      <td>'\"Do not believe TV, neither Russian nor Geor...</td>\n",
              "      <td>'Riots are still going on in Montreal (Canada...</td>\n",
              "      <td>'China to overtake US as largest manufacturer'</td>\n",
              "      <td>'War in South Ossetia [PICS]'</td>\n",
              "      <td>'Israeli Physicians Group Condemns State Tort...</td>\n",
              "      <td>' Russia has just beaten the United States ov...</td>\n",
              "      <td>'Perhaps *the* question about the Georgia - R...</td>\n",
              "      <td>'Russia is so much better at war'</td>\n",
              "      <td>\"So this is what it's come to: trading sex fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-12</th>\n",
              "      <td>0</td>\n",
              "      <td>'Remember that adorable 9-year-old who sang a...</td>\n",
              "      <td>\"Russia 'ends Georgia operation'\"</td>\n",
              "      <td>'\"If we had no sexual harassment we would hav...</td>\n",
              "      <td>\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
              "      <td>'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
              "      <td>'Why Microsoft and Intel tried to kill the XO...</td>\n",
              "      <td>'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
              "      <td>\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
              "      <td>\"The US military was surprised by the timing ...</td>\n",
              "      <td>'U.S. Beats War Drum as Iran Dumps the Dollar'</td>\n",
              "      <td>'Gorbachev: \"Georgian military attacked the S...</td>\n",
              "      <td>'CNN use footage of Tskhinvali ruins to cover...</td>\n",
              "      <td>'Beginning a war as the Olympics were opening...</td>\n",
              "      <td>'55 pyramids as large as the Luxor stacked in...</td>\n",
              "      <td>'The 11 Top Party Cities in the World'</td>\n",
              "      <td>'U.S. troops still in Georgia (did you know t...</td>\n",
              "      <td>'Why Russias response to Georgia was right'</td>\n",
              "      <td>'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
              "      <td>'Russia, Georgia, and NATO: Cold War Two'</td>\n",
              "      <td>'Remember that adorable 62-year-old who led y...</td>\n",
              "      <td>'War in Georgia: The Israeli connection'</td>\n",
              "      <td>'All signs point to the US encouraging Georgi...</td>\n",
              "      <td>'Christopher King argues that the US and NATO...</td>\n",
              "      <td>'America: The New Mexico?'</td>\n",
              "      <td>\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-13</th>\n",
              "      <td>0</td>\n",
              "      <td>' U.S. refuses Israel weapons to attack Iran:...</td>\n",
              "      <td>\"When the president ordered to attack Tskhinv...</td>\n",
              "      <td>' Israel clears troops who killed Reuters cam...</td>\n",
              "      <td>'Britain\\'s policy of being tough on drugs is...</td>\n",
              "      <td>'Body of 14 year old found in trunk; Latest (...</td>\n",
              "      <td>'China has moved 10 *million* quake survivors...</td>\n",
              "      <td>\"Bush announces Operation Get All Up In Russi...</td>\n",
              "      <td>'Russian forces sink Georgian ships '</td>\n",
              "      <td>\"The commander of a Navy air reconnaissance s...</td>\n",
              "      <td>\"92% of CNN readers: Russia's actions in Geor...</td>\n",
              "      <td>'USA to send fleet into Black Sea to help Geo...</td>\n",
              "      <td>\"US warns against Israeli plan to strike agai...</td>\n",
              "      <td>\"In an intriguing cyberalliance, two Estonian...</td>\n",
              "      <td>'The CNN Effect: Georgia Schools Russia in In...</td>\n",
              "      <td>'Why Russias response to Georgia was right'</td>\n",
              "      <td>'Elephants extinct by 2020?'</td>\n",
              "      <td>'US humanitarian missions soon in Georgia - i...</td>\n",
              "      <td>\"Georgia's DDOS came from US sources\"</td>\n",
              "      <td>'Russian convoy heads into Georgia, violating...</td>\n",
              "      <td>'Israeli defence minister: US against strike ...</td>\n",
              "      <td>'Gorbachev: We Had No Choice'</td>\n",
              "      <td>'Witness: Russian forces head towards Tbilisi...</td>\n",
              "      <td>' Quarter of Russians blame U.S. for conflict...</td>\n",
              "      <td>'Georgian president  says US military will ta...</td>\n",
              "      <td>'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-08-14</th>\n",
              "      <td>1</td>\n",
              "      <td>'All the experts admit that we should legalis...</td>\n",
              "      <td>'War in South Osetia - 89 pictures made by a ...</td>\n",
              "      <td>'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
              "      <td>'Russia exaggerated the death toll in South O...</td>\n",
              "      <td>'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
              "      <td>\"Rushdie Condemns Random House's Refusal to P...</td>\n",
              "      <td>'Poland and US agree to missle defense deal. ...</td>\n",
              "      <td>'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
              "      <td>'Russia exaggerating South Ossetian death tol...</td>\n",
              "      <td>' Musharraf expected to resign rather than fa...</td>\n",
              "      <td>'Moscow Made Plans Months Ago to Invade Georgia'</td>\n",
              "      <td>'Why Russias response to Georgia was right'</td>\n",
              "      <td>'Nigeria has handed over the potentially oil-...</td>\n",
              "      <td>'The US and Poland have agreed a preliminary ...</td>\n",
              "      <td>'Russia apparently is sabotaging infrastructu...</td>\n",
              "      <td>'Bank analyst forecast Georgian crisis 2 days...</td>\n",
              "      <td>\"Georgia confict could set back Russia's US r...</td>\n",
              "      <td>'War in the Caucasus is as much the product o...</td>\n",
              "      <td>'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
              "      <td>'Georgian TV reporter shot by Russian sniper ...</td>\n",
              "      <td>'Saudi Arabia: Mother moves to block child ma...</td>\n",
              "      <td>'Taliban wages war on humanitarian aid workers'</td>\n",
              "      <td>'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
              "      <td>'Darfur rebels accuse Sudan of mounting major...</td>\n",
              "      <td>'Philippines : Peace Advocate say Muslims nee...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Label  ...                                            News_25\n",
              "Date               ...                                                   \n",
              "2008-08-08      0  ...            \"No Help for Mexico's Kidnapping Surge\"\n",
              "2008-08-11      1  ...   \"So this is what it's come to: trading sex fo...\n",
              "2008-08-12      0  ...   \"BBC NEWS | Asia-Pacific | Extinction 'by man...\n",
              "2008-08-13      0  ...   '2006: Nobel laureate Aleksander Solzhenitsyn...\n",
              "2008-08-14      1  ...   'Philippines : Peace Advocate say Muslims nee...\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX8yMe4_0gfC",
        "outputId": "3e57b9d2-e6b0-4bfd-cff8-651d8287cc52"
      },
      "source": [
        "# create new dataset without the dates\n",
        "news_sum = []\n",
        "label_sum = []\n",
        "\n",
        "# Get the column names\n",
        "combined_column_names = []\n",
        "for column in df_combined.columns:\n",
        "  combined_column_names.append(column)\n",
        "\n",
        "# Connect the merged news with the labels\n",
        "for column in range(len(df_combined)):\n",
        "  for row in range(len(combined_column_names) - 1):\n",
        "    news_sum.append(df_combined[combined_column_names[row + 1]][column])\n",
        "    label_sum.append(df_combined[combined_column_names[0]][column])\n",
        "\n",
        "# Create the new DataFrame\n",
        "df_sum_news_labels = pd.DataFrame(data = label_sum, index = None, columns = [\"Label\"])\n",
        "df_sum_news_labels[\"News\"] = news_sum\n",
        "\n",
        "# Show it\n",
        "df_sum_news_labels.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>'BREAKING: Musharraf to be impeached.'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>'Russia Today: Columns of troops roll into So...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>'Russian tanks are moving towards the capital...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label                                               News\n",
              "0      0   \"Georgia 'downs two Russian warplanes' as cou...\n",
              "1      0             'BREAKING: Musharraf to be impeached.'\n",
              "2      0   'Russia Today: Columns of troops roll into So...\n",
              "3      0   'Russian tanks are moving towards the capital...\n",
              "4      0   \"Afghan children raped with 'impunity,' U.N. ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "187XLRNF03nv",
        "outputId": "25f1a265-a497-422f-b349-a974bdf66fc7"
      },
      "source": [
        "# check and delete the null length cells\n",
        "news_sum = df_sum_news_labels[\"News\"]\n",
        "null_indexes = []\n",
        "index = 0\n",
        "\n",
        "for line in news_sum:\n",
        "  if line is \"\":\n",
        "    null_indexes.append(index)\n",
        "  index = index + 1\n",
        "\n",
        "print(null_indexes)\n",
        "\n",
        "for row in null_indexes:\n",
        "  df_sum_news_labels = df_sum_news_labels.drop(row)\n",
        "\n",
        "news_sum = df_sum_news_labels[\"News\"]\n",
        "null_indexes = []\n",
        "index = 0\n",
        "\n",
        "for line in news_sum:\n",
        "  if line is \"\":\n",
        "    null_indexes.append(index)\n",
        "  index = index + 1\n",
        "  \n",
        "assert len(null_indexes) is 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYpGXMN6173B"
      },
      "source": [
        "# shuffle the dataset\n",
        "# Do the shuffle\n",
        "for i in range(SHUFFLE_CYCLE):\n",
        "  df_sum_news_labels = shuffle(df_sum_news_labels, random_state = NP_SEED)\n",
        "\n",
        "# Reset the index\n",
        "df_sum_news_labels.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVadHIQm6dvH",
        "outputId": "39a1d5ba-274d-4e72-9e1e-312d4a114458"
      },
      "source": [
        "# check max length for bert tokenizer\n",
        "# Get the column names\n",
        "combined_column_names = []\n",
        "for column in df_combined.columns:\n",
        "  combined_column_names.append(column)\n",
        "\n",
        "max_length = 0\n",
        "# Connect the merged news with the labels\n",
        "for column in range(len(df_combined)):\n",
        "  for row in range(len(combined_column_names) - 1):\n",
        "    if len(df_combined[combined_column_names[row + 1]][column]) > max_length:\n",
        "        max_length = len(df_combined[combined_column_names[row + 1]][column])\n",
        "\n",
        "max_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUjhHDbW1Vf1"
      },
      "source": [
        "# split the dataset for train and validation and test \n",
        "INPUT_SIZE = len(df_sum_news_labels)\n",
        "# 75% train -> 60% train, 15% valid, 25% test\n",
        "TRAIN_SIZE = int(TRAIN_SPLIT * INPUT_SIZE) \n",
        "VALID_SIZE = int(VALIDATION_SPLIT * TRAIN_SIZE)\n",
        "\n",
        "# Create the train data set\n",
        "train_dataset = df_sum_news_labels[:TRAIN_SIZE - VALID_SIZE] \n",
        "\n",
        "# Create the validation data set\n",
        "valid_dataset = df_sum_news_labels[TRAIN_SIZE - VALID_SIZE:TRAIN_SIZE] \n",
        "\n",
        "# Create the test data set\n",
        "test_dataset = df_sum_news_labels[TRAIN_SIZE:]\n",
        "\n",
        "# Save them without the indexes\n",
        "train_dataset.to_csv('drive/MyDrive/train.tsv', sep = '\\t', index=False)\n",
        "valid_dataset.to_csv('drive/MyDrive/valid.tsv', sep = '\\t', index=False)\n",
        "test_dataset.to_csv('drive/MyDrive/test.tsv', sep = '\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltMaYxlDe1x1",
        "outputId": "2d30e9b6-b3f9-4e06-8736-603e5bf8765f"
      },
      "source": [
        "# check label percentage\n",
        "# TRAIN\n",
        "# Groupby by label\n",
        "labels = train_dataset.groupby(\"Label\")\n",
        "\n",
        "# Summary statistic of all countries\n",
        "labels.describe().head()\n",
        "# Get the counts for labels\n",
        "label_0_count = len(labels.get_group(0))\n",
        "label_1_count = len(labels.get_group(1))\n",
        "\n",
        "# Get the summary\n",
        "label_sum = label_0_count + label_1_count\n",
        "\n",
        "# The percentages\n",
        "percentage_0 = label_0_count / label_sum\n",
        "percentage_1 = label_1_count / label_sum\n",
        "\n",
        "# Show\n",
        "print(\"TRAIN\\n\")\n",
        "print(f\"0 Labels percentage: {percentage_0*100:.2f}%\\n\")\n",
        "print(f\"1 Labels percentage: {percentage_1*100:.2f}%\")\n",
        "\n",
        "# VALID\n",
        "# Groupby by label\n",
        "labels = valid_dataset.groupby(\"Label\")\n",
        "\n",
        "# Summary statistic of all countries\n",
        "labels.describe().head()\n",
        "# Get the counts for labels\n",
        "label_0_count = len(labels.get_group(0))\n",
        "label_1_count = len(labels.get_group(1))\n",
        "\n",
        "# Get the summary\n",
        "label_sum = label_0_count + label_1_count\n",
        "\n",
        "# The percentages\n",
        "percentage_0 = label_0_count / label_sum\n",
        "percentage_1 = label_1_count / label_sum\n",
        "\n",
        "# Show\n",
        "print(\"\\n\\nVALID\\n\")\n",
        "print(f\"0 Labels percentage: {percentage_0*100:.2f}%\\n\")\n",
        "print(f\"1 Labels percentage: {percentage_1*100:.2f}%\")\n",
        "\n",
        "# TEST\n",
        "# Groupby by label\n",
        "labels = test_dataset.groupby(\"Label\")\n",
        "\n",
        "# Summary statistic of all countries\n",
        "labels.describe().head()\n",
        "# Get the counts for labels\n",
        "label_0_count = len(labels.get_group(0))\n",
        "label_1_count = len(labels.get_group(1))\n",
        "\n",
        "# Get the summary\n",
        "label_sum = label_0_count + label_1_count\n",
        "\n",
        "# The percentages\n",
        "percentage_0 = label_0_count / label_sum\n",
        "percentage_1 = label_1_count / label_sum\n",
        "\n",
        "# Show\n",
        "print(\"\\n\\nTEST\\n\")\n",
        "print(f\"0 Labels percentage: {percentage_0*100:.2f}%\\n\")\n",
        "print(f\"1 Labels percentage: {percentage_1*100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN\n",
            "\n",
            "0 Labels percentage: 46.45%\n",
            "\n",
            "1 Labels percentage: 53.55%\n",
            "\n",
            "\n",
            "VALID\n",
            "\n",
            "0 Labels percentage: 46.10%\n",
            "\n",
            "1 Labels percentage: 53.90%\n",
            "\n",
            "\n",
            "TEST\n",
            "\n",
            "0 Labels percentage: 45.28%\n",
            "\n",
            "1 Labels percentage: 54.72%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJP-ds168ohJ",
        "outputId": "8965dc91-2b86-4766-ae5b-2d333e36fd23"
      },
      "source": [
        "train_dataset[\"News\"][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" 'Report in US undercuts Georgian claim of how war started'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqcydDkP2YgF"
      },
      "source": [
        "## **Szótárak létrehozása a szöveg kódolásához**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu81X6qR5WZo"
      },
      "source": [
        "# define max input length for bert\n",
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjTpVh_A2e1q"
      },
      "source": [
        "# preprocess function with tokenizer\n",
        "def tokenize_and_cut(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM36Q80e4L4P"
      },
      "source": [
        "# special tokens\n",
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPB3sPLC2uxZ"
      },
      "source": [
        "# fields define\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB9u7uAW5EqN"
      },
      "source": [
        "fields = [('labels', LABEL), ('news', TEXT)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc-F1gFt47dg"
      },
      "source": [
        "# load datasets\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "                                        path = \"drive/MyDrive\",\n",
        "                                        train = \"train.tsv\",\n",
        "                                        validation = \"valid.tsv\",\n",
        "                                        test = \"test.tsv\",\n",
        "                                        format = \"tsv\",\n",
        "                                        fields = fields,\n",
        "                                        skip_header = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8WvP2-Y7p6H",
        "outputId": "48f28bc2-1c96-42e9-d2b8-3a32792a650c"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 29835\n",
            "Number of validation examples: 7458\n",
            "Number of testing examples: 12432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yIW2Sv08L2f"
      },
      "source": [
        "Az első elem ellenőrzése."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtJadJX48NpS",
        "outputId": "60bafa58-2dd1-424d-c308-0480b799a809"
      },
      "source": [
        "print(vars(train_data[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'labels': '1', 'news': [1005, 3189, 1999, 2149, 2104, 12690, 2015, 9166, 4366, 1997, 2129, 2162, 2318, 1005]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQmyaQdd8QLf",
        "outputId": "77084838-58ca-49e2-e697-4a1fa90fda53"
      },
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(vars(train_data[0])['news'])\n",
        "\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"'\", 'report', 'in', 'us', 'under', '##cut', '##s', 'georgian', 'claim', 'of', 'how', 'war', 'started', \"'\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHE1SqNYEosV",
        "outputId": "c772913d-3950-4c5b-8137-1a819d198743"
      },
      "source": [
        "# build vocab\n",
        "LABEL.build_vocab(train_data)\n",
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(None, {'1': 0, '0': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3HOTzpoEtKz"
      },
      "source": [
        "# define batch and iterator\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    sort_key = lambda x: x.news, #sort by n attribute (quote)\n",
        "    batch_size = BATCH_SIZE, \n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqJLL3ZOEzTl"
      },
      "source": [
        "## **Modell létrehozása**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPFpGXiHE3gL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "aa897b2b8f414db093b3979e8d03ed31",
            "414d313b0d824e27977ec04790cafd37",
            "91d39dac9e514e8192d28de4b0c48dc8",
            "8626dddb2a5c4da7b2dd9075a22263fe",
            "6dfc1670e5ca441293223a4f08eef651",
            "227fc556f9cb4bdcb395aa8374aaaefb",
            "4e87eb43db5c401ea61093b1639c36c1",
            "79e5a832913b4123853e87d527fb35b4",
            "ca7c14fa4e524ec49b994c0f7a2f5584",
            "af77a3965d794323b41385e078827777",
            "5f68d761aa7e459e96618f4e52146d02",
            "c91315d717094746a891404acadda1d8",
            "a44b995cc085493bb47b5f614dbe3a25",
            "d5d53a08b69f40a48cdf00adad19a090",
            "3b2d7902dab345cca810cb8817b0095c",
            "7ef7c4fd4b4247ef8d5d13f6ca40eeaf"
          ]
        },
        "outputId": "6772fa16-b433-483c-b438-d49f59cf4230"
      },
      "source": [
        "# load pretrained bert\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa897b2b8f414db093b3979e8d03ed31",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca7c14fa4e524ec49b994c0f7a2f5584",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw56YAtuFE9v"
      },
      "source": [
        "# define model\n",
        "import torch.nn as nn\n",
        "\n",
        "class BERTGRUSentiment(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert # bert layer\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        \n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout) # gru layer\n",
        "        \n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim) # linear out\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            embedded = self.bert(text)[0] # do not teach the bert layer parameters\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        \n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "                \n",
        "        #hidden = [batch size, hid dim]\n",
        "        \n",
        "        output = self.out(hidden)\n",
        "        \n",
        "        #output = [batch size, out dim]\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyWd1hiaFZEb"
      },
      "source": [
        "# create the model with parameters\n",
        "HIDDEN_DIM = 64\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.2\n",
        "\n",
        "model = BERTGRUSentiment(bert,\n",
        "                         HIDDEN_DIM,\n",
        "                         OUTPUT_DIM,\n",
        "                         N_LAYERS,\n",
        "                         BIDIRECTIONAL,\n",
        "                         DROPOUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtdwhrAeFekS",
        "outputId": "83482d78-6758-4707-99fe-792aa93c7ba9"
      },
      "source": [
        "# check all and teachable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} parameters')\n",
        "\n",
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 109,877,121 parameters\n",
            "The model has 394,881 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOuAj85VFswd"
      },
      "source": [
        "## **A modell tanítása**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeQCs8lkFsVK"
      },
      "source": [
        "# optimizier and cost function\n",
        "import torch.optim as optim\n",
        "LR = 0.1\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', cooldown=10, \n",
        "                                                       patience=5, verbose=True)\n",
        "\n",
        "# place them to gpu\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVzLVhWKF5gk"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i9Twg21F7sH"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    index = 0\n",
        "    log_interval = 100\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        if index == 0:\n",
        "            all = str(len(iterator))\n",
        "            print(f'Epoch: {epoch+1:02} started | {all} batches will be done')\n",
        "\n",
        "        if index % log_interval == 0 and index > 0:\n",
        "            all = str(len(iterator))\n",
        "            temp_end_time = time.time()\n",
        "            epoch_mins, epoch_secs = epoch_time(start_time, temp_end_time)\n",
        "            print(f'Epoch: {epoch+1:02} | {index} / {all} batches done | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.news).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.labels)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "        index += 1\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guze1HVWF9UP"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.news).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ra0zIu0F-jC"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipnFGhOIGArt",
        "outputId": "b5bd9999-c2ac-418e-8616-857028061c7d"
      },
      "source": [
        "# train the model\n",
        "# save the results for plotting\n",
        "N_EPOCHS = 500\n",
        "\n",
        "train_loss_array = []\n",
        "train_acc_array = []\n",
        "valid_loss_array = []\n",
        "valid_acc_array = []\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    scheduler.step(valid_loss)\n",
        "\n",
        "    train_loss_array.append(train_loss)\n",
        "    train_acc_array.append(train_acc)\n",
        "    valid_loss_array.append(valid_loss)\n",
        "    valid_acc_array.append(valid_acc)\n",
        "        \n",
        "    end_time = time.time()\n",
        "        \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'drive/MyDrive/bert_best_model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 started | 467 batches will be done\n",
            "Epoch: 01 | 100 / 467 batches done | Epoch Time: 0m 25s\n",
            "Epoch: 01 | 200 / 467 batches done | Epoch Time: 0m 52s\n",
            "Epoch: 01 | 300 / 467 batches done | Epoch Time: 1m 20s\n",
            "Epoch: 01 | 400 / 467 batches done | Epoch Time: 1m 47s\n",
            "Epoch: 01 | Epoch Time: 2m 35s\n",
            "\tTrain Loss: 0.782 | Train Acc: 50.46%\n",
            "\t Val. Loss: 0.701 |  Val. Acc: 46.09%\n",
            "\n",
            "Epoch: 02 started | 467 batches will be done\n",
            "Epoch: 02 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 02 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 02 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 02 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 02 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.766 | Train Acc: 50.33%\n",
            "\t Val. Loss: 0.757 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 03 started | 467 batches will be done\n",
            "Epoch: 03 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 03 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 03 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 03 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 03 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.777 | Train Acc: 50.41%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 04 started | 467 batches will be done\n",
            "Epoch: 04 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 04 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 04 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 04 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 04 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.782 | Train Acc: 50.54%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 46.09%\n",
            "\n",
            "Epoch: 05 started | 467 batches will be done\n",
            "Epoch: 05 | 100 / 467 batches done | Epoch Time: 0m 26s\n",
            "Epoch: 05 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 05 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 05 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 05 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.784 | Train Acc: 50.28%\n",
            "\t Val. Loss: 0.700 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 06 started | 467 batches will be done\n",
            "Epoch: 06 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 06 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 06 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 06 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 06 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.755 | Train Acc: 50.71%\n",
            "\t Val. Loss: 0.802 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 07 started | 467 batches will be done\n",
            "Epoch: 07 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 07 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 07 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 07 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 07 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.774 | Train Acc: 50.39%\n",
            "\t Val. Loss: 0.704 |  Val. Acc: 46.09%\n",
            "\n",
            "Epoch: 08 started | 467 batches will be done\n",
            "Epoch: 08 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 08 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 08 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 08 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 08 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.770 | Train Acc: 50.38%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 09 started | 467 batches will be done\n",
            "Epoch: 09 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 09 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 09 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 09 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 09 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.751 | Train Acc: 50.76%\n",
            "\t Val. Loss: 0.732 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 10 started | 467 batches will be done\n",
            "Epoch: 10 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 10 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 10 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 10 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 10 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.781 | Train Acc: 50.98%\n",
            "\t Val. Loss: 0.990 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 11 started | 467 batches will be done\n",
            "Epoch: 11 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 11 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 11 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 11 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 11 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.794 | Train Acc: 50.33%\n",
            "\t Val. Loss: 0.711 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 12 started | 467 batches will be done\n",
            "Epoch: 12 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 12 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 12 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 12 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 12 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.803 | Train Acc: 50.49%\n",
            "\t Val. Loss: 0.709 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 13 started | 467 batches will be done\n",
            "Epoch: 13 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 13 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 13 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 13 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 13 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.769 | Train Acc: 50.55%\n",
            "\t Val. Loss: 0.776 |  Val. Acc: 46.09%\n",
            "\n",
            "Epoch: 14 started | 467 batches will be done\n",
            "Epoch: 14 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 14 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 14 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 14 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch    14: reducing learning rate of group 0 to 1.0000e-02.\n",
            "Epoch: 14 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.764 | Train Acc: 50.99%\n",
            "\t Val. Loss: 0.735 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 15 started | 467 batches will be done\n",
            "Epoch: 15 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 15 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 15 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 15 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 15 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.702 | Train Acc: 51.36%\n",
            "\t Val. Loss: 0.710 |  Val. Acc: 46.09%\n",
            "\n",
            "Epoch: 16 started | 467 batches will be done\n",
            "Epoch: 16 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 16 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 16 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 16 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 16 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.699 | Train Acc: 51.36%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 17 started | 467 batches will be done\n",
            "Epoch: 17 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 17 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 17 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 17 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 17 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.699 | Train Acc: 51.63%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 18 started | 467 batches will be done\n",
            "Epoch: 18 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 18 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 18 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 18 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 18 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.699 | Train Acc: 51.33%\n",
            "\t Val. Loss: 0.708 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 19 started | 467 batches will be done\n",
            "Epoch: 19 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 19 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 19 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 19 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 19 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.705 | Train Acc: 50.95%\n",
            "\t Val. Loss: 0.697 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 20 started | 467 batches will be done\n",
            "Epoch: 20 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 20 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 20 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 20 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 20 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.702 | Train Acc: 51.21%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 21 started | 467 batches will be done\n",
            "Epoch: 21 | 100 / 467 batches done | Epoch Time: 0m 26s\n",
            "Epoch: 21 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 21 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 21 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 21 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.703 | Train Acc: 50.88%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 22 started | 467 batches will be done\n",
            "Epoch: 22 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 22 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 22 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 22 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 22 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.707 | Train Acc: 51.04%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 23 started | 467 batches will be done\n",
            "Epoch: 23 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 23 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 23 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 23 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 23 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.701 | Train Acc: 51.17%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 46.09%\n",
            "\n",
            "Epoch: 24 started | 467 batches will be done\n",
            "Epoch: 24 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 24 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 24 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 24 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 24 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.701 | Train Acc: 51.18%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 25 started | 467 batches will be done\n",
            "Epoch: 25 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 25 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 25 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 25 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 25 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.704 | Train Acc: 51.05%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 26 started | 467 batches will be done\n",
            "Epoch: 26 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 26 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 26 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 26 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 26 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.704 | Train Acc: 51.25%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 27 started | 467 batches will be done\n",
            "Epoch: 27 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 27 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 27 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 27 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 27 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.701 | Train Acc: 51.20%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 28 started | 467 batches will be done\n",
            "Epoch: 28 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 28 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 28 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 28 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 28 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.705 | Train Acc: 51.25%\n",
            "\t Val. Loss: 0.704 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 29 started | 467 batches will be done\n",
            "Epoch: 29 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 29 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 29 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 29 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 29 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.700 | Train Acc: 50.71%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 30 started | 467 batches will be done\n",
            "Epoch: 30 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 30 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 30 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 30 | 400 / 467 batches done | Epoch Time: 1m 50s\n",
            "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch: 30 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.701 | Train Acc: 51.33%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 31 started | 467 batches will be done\n",
            "Epoch: 31 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 31 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 31 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 31 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 31 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.694 | Train Acc: 52.37%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 32 started | 467 batches will be done\n",
            "Epoch: 32 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 32 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 32 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 32 | 400 / 467 batches done | Epoch Time: 1m 50s\n",
            "Epoch: 32 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.693 | Train Acc: 52.42%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 33 started | 467 batches will be done\n",
            "Epoch: 33 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 33 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 33 | 300 / 467 batches done | Epoch Time: 1m 23s\n",
            "Epoch: 33 | 400 / 467 batches done | Epoch Time: 1m 50s\n",
            "Epoch: 33 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.693 | Train Acc: 52.81%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 34 started | 467 batches will be done\n",
            "Epoch: 34 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 34 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 34 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 34 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 34 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.692 | Train Acc: 52.66%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 35 started | 467 batches will be done\n",
            "Epoch: 35 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 35 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 35 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 35 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 35 | Epoch Time: 2m 36s\n",
            "\tTrain Loss: 0.692 | Train Acc: 53.20%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 36 started | 467 batches will be done\n",
            "Epoch: 36 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 36 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 36 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 36 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 36 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.693 | Train Acc: 52.61%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 37 started | 467 batches will be done\n",
            "Epoch: 37 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 37 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 37 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 37 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 37 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.692 | Train Acc: 53.15%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 38 started | 467 batches will be done\n",
            "Epoch: 38 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 38 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 38 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 38 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 38 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.692 | Train Acc: 53.14%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 39 started | 467 batches will be done\n",
            "Epoch: 39 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 39 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 39 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 39 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 39 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.692 | Train Acc: 53.01%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 40 started | 467 batches will be done\n",
            "Epoch: 40 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 40 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 40 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 40 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 40 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.692 | Train Acc: 53.09%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 41 started | 467 batches will be done\n",
            "Epoch: 41 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 41 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 41 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 41 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 41 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.692 | Train Acc: 53.00%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 42 started | 467 batches will be done\n",
            "Epoch: 42 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 42 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 42 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 42 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 42 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.692 | Train Acc: 53.27%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 43 started | 467 batches will be done\n",
            "Epoch: 43 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 43 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 43 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 43 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 43 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.692 | Train Acc: 53.22%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 44 started | 467 batches will be done\n",
            "Epoch: 44 | 100 / 467 batches done | Epoch Time: 0m 26s\n",
            "Epoch: 44 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 44 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 44 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 44 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.692 | Train Acc: 52.72%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 45 started | 467 batches will be done\n",
            "Epoch: 45 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 45 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 45 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 45 | 400 / 467 batches done | Epoch Time: 1m 50s\n",
            "Epoch: 45 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.693 | Train Acc: 52.64%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 46 started | 467 batches will be done\n",
            "Epoch: 46 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 46 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 46 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 46 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch: 46 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.693 | Train Acc: 52.54%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 47 started | 467 batches will be done\n",
            "Epoch: 47 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 47 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 47 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 47 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 47 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.56%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 48 started | 467 batches will be done\n",
            "Epoch: 48 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 48 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 48 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 48 | 400 / 467 batches done | Epoch Time: 1m 50s\n",
            "Epoch: 48 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.58%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 49 started | 467 batches will be done\n",
            "Epoch: 49 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 49 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 49 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 49 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 49 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.58%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 50 started | 467 batches will be done\n",
            "Epoch: 50 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 50 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 50 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 50 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 50 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.53%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 51 started | 467 batches will be done\n",
            "Epoch: 51 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 51 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 51 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 51 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 51 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.58%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 52 started | 467 batches will be done\n",
            "Epoch: 52 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 52 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 52 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 52 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 52 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.58%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 53 started | 467 batches will be done\n",
            "Epoch: 53 | 100 / 467 batches done | Epoch Time: 0m 26s\n",
            "Epoch: 53 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 53 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 53 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 53 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.56%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 54 started | 467 batches will be done\n",
            "Epoch: 54 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 54 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 54 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 54 | 400 / 467 batches done | Epoch Time: 1m 50s\n",
            "Epoch: 54 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.62%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 55 started | 467 batches will be done\n",
            "Epoch: 55 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 55 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 55 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 55 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 55 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.43%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 56 started | 467 batches will be done\n",
            "Epoch: 56 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 56 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 56 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 56 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 56 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.56%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 57 started | 467 batches will be done\n",
            "Epoch: 57 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 57 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 57 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 57 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 57 | Epoch Time: 2m 36s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.55%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 58 started | 467 batches will be done\n",
            "Epoch: 58 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 58 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 58 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 58 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 58 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.57%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 59 started | 467 batches will be done\n",
            "Epoch: 59 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 59 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 59 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 59 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 59 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.53%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 60 started | 467 batches will be done\n",
            "Epoch: 60 | 100 / 467 batches done | Epoch Time: 0m 26s\n",
            "Epoch: 60 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 60 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 60 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 60 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.55%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 61 started | 467 batches will be done\n",
            "Epoch: 61 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 61 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 61 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 61 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 61 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.54%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 62 started | 467 batches will be done\n",
            "Epoch: 62 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 62 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 62 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 62 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch    62: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch: 62 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.56%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 63 started | 467 batches will be done\n",
            "Epoch: 63 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 63 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 63 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 63 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 63 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.54%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 64 started | 467 batches will be done\n",
            "Epoch: 64 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 64 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 64 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 64 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 64 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.59%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 65 started | 467 batches will be done\n",
            "Epoch: 65 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 65 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 65 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 65 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 65 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.57%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 66 started | 467 batches will be done\n",
            "Epoch: 66 | 100 / 467 batches done | Epoch Time: 0m 26s\n",
            "Epoch: 66 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 66 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 66 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 66 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.55%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 67 started | 467 batches will be done\n",
            "Epoch: 67 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 67 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 67 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 67 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 67 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.57%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 68 started | 467 batches will be done\n",
            "Epoch: 68 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 68 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 68 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 68 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 68 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.54%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 69 started | 467 batches will be done\n",
            "Epoch: 69 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 69 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 69 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 69 | 400 / 467 batches done | Epoch Time: 1m 50s\n",
            "Epoch: 69 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.57%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 70 started | 467 batches will be done\n",
            "Epoch: 70 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 70 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 70 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 70 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 70 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.57%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 71 started | 467 batches will be done\n",
            "Epoch: 71 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 71 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 71 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 71 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 71 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.63%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 72 started | 467 batches will be done\n",
            "Epoch: 72 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 72 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 72 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 72 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 72 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.60%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 73 started | 467 batches will be done\n",
            "Epoch: 73 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 73 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 73 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 73 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 73 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.54%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 74 started | 467 batches will be done\n",
            "Epoch: 74 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 74 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 74 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 74 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 74 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.54%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 75 started | 467 batches will be done\n",
            "Epoch: 75 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 75 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 75 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 75 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 75 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.59%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 76 started | 467 batches will be done\n",
            "Epoch: 76 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 76 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 76 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 76 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 76 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.59%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 77 started | 467 batches will be done\n",
            "Epoch: 77 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 77 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 77 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 77 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 77 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.57%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 78 started | 467 batches will be done\n",
            "Epoch: 78 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 78 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 78 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 78 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch    78: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch: 78 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.57%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 79 started | 467 batches will be done\n",
            "Epoch: 79 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 79 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 79 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 79 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 79 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.57%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 80 started | 467 batches will be done\n",
            "Epoch: 80 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 80 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 80 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 80 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 80 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.60%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 81 started | 467 batches will be done\n",
            "Epoch: 81 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 81 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 81 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 81 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 81 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.59%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 82 started | 467 batches will be done\n",
            "Epoch: 82 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 82 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 82 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 82 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 82 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.55%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 83 started | 467 batches will be done\n",
            "Epoch: 83 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 83 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 83 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 83 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 83 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.55%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 84 started | 467 batches will be done\n",
            "Epoch: 84 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 84 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 84 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 84 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 84 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.54%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 85 started | 467 batches will be done\n",
            "Epoch: 85 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 85 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 85 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 85 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 85 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.54%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 86 started | 467 batches will be done\n",
            "Epoch: 86 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 86 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 86 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 86 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 86 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.55%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 87 started | 467 batches will be done\n",
            "Epoch: 87 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 87 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 87 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 87 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 87 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.59%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 88 started | 467 batches will be done\n",
            "Epoch: 88 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 88 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 88 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 88 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 88 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.57%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 89 started | 467 batches will be done\n",
            "Epoch: 89 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 89 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 89 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 89 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 89 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.57%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 90 started | 467 batches will be done\n",
            "Epoch: 90 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 90 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 90 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 90 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 90 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.57%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 91 started | 467 batches will be done\n",
            "Epoch: 91 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 91 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 91 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 91 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 91 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.55%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 92 started | 467 batches will be done\n",
            "Epoch: 92 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 92 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 92 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 92 | 400 / 467 batches done | Epoch Time: 1m 48s\n",
            "Epoch: 92 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.62%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 93 started | 467 batches will be done\n",
            "Epoch: 93 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 93 | 200 / 467 batches done | Epoch Time: 0m 55s\n",
            "Epoch: 93 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 93 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 93 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.60%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 94 started | 467 batches will be done\n",
            "Epoch: 94 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 94 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 94 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 94 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch    94: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch: 94 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.59%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 95 started | 467 batches will be done\n",
            "Epoch: 95 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 95 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 95 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 95 | 400 / 467 batches done | Epoch Time: 1m 50s\n",
            "Epoch: 95 | Epoch Time: 2m 38s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.60%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 96 started | 467 batches will be done\n",
            "Epoch: 96 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 96 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 96 | 300 / 467 batches done | Epoch Time: 1m 22s\n",
            "Epoch: 96 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 96 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.59%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 97 started | 467 batches will be done\n",
            "Epoch: 97 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 97 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 97 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 97 | 400 / 467 batches done | Epoch Time: 1m 49s\n",
            "Epoch: 97 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.691 | Train Acc: 53.59%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 53.91%\n",
            "\n",
            "Epoch: 98 started | 467 batches will be done\n",
            "Epoch: 98 | 100 / 467 batches done | Epoch Time: 0m 27s\n",
            "Epoch: 98 | 200 / 467 batches done | Epoch Time: 0m 54s\n",
            "Epoch: 98 | 300 / 467 batches done | Epoch Time: 1m 21s\n",
            "Epoch: 98 | 400 / 467 batches done | Epoch Time: 1m 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNHiFfSaGZZq"
      },
      "source": [
        "# Visualize the training\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.title('Train and validation loss')\n",
        "plt.plot(train_loss_array, color = \"green\", label = \"Train loss\")\n",
        "plt.plot(valid_loss_array, color = \"blue\", label = \"Valid loss\")\n",
        "plt.xlabel('Epoch',fontsize=18)\n",
        "plt.ylabel('Loss',fontsize=18)\n",
        "plt.legend(fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzCuSDl_GamX"
      },
      "source": [
        "# Visualize the training\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.title('Train and validation accuraccy')\n",
        "plt.plot(train_acc_array, color = \"green\", label = \"Train accuracy\")\n",
        "plt.plot(valid_acc_array, color = \"blue\", label = \"Valid accuracy\")\n",
        "plt.xlabel('Epoch',fontsize=18)\n",
        "plt.ylabel('Accuracy (%)',fontsize=18)\n",
        "plt.legend(fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps-4oNBWGc0y"
      },
      "source": [
        "## **A modell tesztelése**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNDIoqEBGf_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f66ccf6-e977-40c7-b0fb-ae43fc816f97"
      },
      "source": [
        "model.load_state_dict(torch.load('drive/MyDrive/bert_best_model.pt', map_location=torch.device('cpu')))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.689 | Test Acc: 54.80%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}